{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "outputs": [],
   "source": [
    "train = pd.read_csv('../datasets/train.csv')\n",
    "test = pd.read_csv('../datasets/test.csv', index_col=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "outputs": [],
   "source": [
    "def process_df(df: pd.DataFrame, is_train: bool) -> pd.DataFrame:\n",
    "    df = df.drop('Color', axis=1)\n",
    "    df['Rating'] = df['Rating'].str.replace(',', '.')\n",
    "    df['Rating'] = df['Rating'].astype(float)\n",
    "\n",
    "    # if is_train:\n",
    "    #     df['Brand weight'] = \"\"\n",
    "    #     for category in df['Brand'].unique():\n",
    "    #         total_rating = df.loc[df['Brand'] == category].count() / df.shape[0]\n",
    "    #         df.loc[df['Brand'] == category, 'Brand weight'] = total_rating\n",
    "\n",
    "    df = df.drop([\n",
    "        'Name',\n",
    "        'Category',\n",
    "        # 'Min price',\n",
    "        # 'Max price',\n",
    "        # 'Average price',\n",
    "        'full_category',\n",
    "        'Seller',\n",
    "        'Base price'\n",
    "    ], axis=1)\n",
    "    df['Days in stock/sales'] = df['Days with sales'].div(df['Days in stock'], axis=0).apply(\n",
    "        lambda x: 1.0 if x >= 1.0 else x)\n",
    "    df['Comments-Rating'] = df['Comments'] * df['Rating']\n",
    "    df['Rating-Days-Comments'] = np.exp(df['Days with sales']) * df['Rating'] * df['Comments']\n",
    "    df['Price difference'] = np.exp(df['Average price'].fillna(0).div(df['Final price'], axis=0)) ** 3\n",
    "    df['Min max price diff'] = np.log10((df['Max price'] - df['Final price']).apply(lambda x: 1 if x == 0 else x)) ** 3\n",
    "    df = df.drop(['Average price', 'Max price', 'Min price'], axis=1)\n",
    "\n",
    "    return df.dropna() if is_train else df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "outputs": [
    {
     "data": {
      "text/plain": "            Brand  Comments  Final price  Days in stock  Days with sales  \\\n0          Majava       2.0        277.0           16.0               14   \n1            Beon       5.0       2211.0            7.0                8   \n2          NEOLUX      19.0        490.0           31.0               22   \n3          CENTEK       2.0        807.0           31.0                0   \n4           HUAYU       3.0        426.0           31.0                5   \n...           ...       ...          ...            ...              ...   \n10736     INDESIT       0.0      17803.0           31.0                3   \n10737     Gelberk       8.0        897.0           12.0                9   \n10738     Rowenta      15.0       1565.0           31.0               29   \n10739      EREMON       0.0       2752.0           11.0                2   \n10740  Electrolux       0.0      16566.0           24.0                9   \n\n       Rating  Basic Sale  Basic Sale Price  Days in stock/sales  \\\n0         0.0        50.0             360.0             0.875000   \n1         3.0        40.0            2664.0             1.000000   \n2         5.0        30.0             490.0             0.709677   \n3         4.0        15.0             807.0             0.000000   \n4         5.0         3.0             426.0             0.161290   \n...       ...         ...               ...                  ...   \n10736     0.0        23.0           19781.0             0.096774   \n10737     4.0        54.0            1150.0             0.750000   \n10738     3.0        46.0            1565.0             0.935484   \n10739     0.0        20.0            3440.0             0.181818   \n10740     0.0         0.0           19490.0             0.375000   \n\n       Comments-Rating  Rating-Days-Comments  Price difference  \\\n0                  0.0          0.000000e+00         17.885865   \n1                 15.0          4.471437e+04         20.085537   \n2                 95.0          3.405667e+11         18.535758   \n3                  8.0          8.000000e+00          1.000000   \n4                 15.0          2.226197e+03         20.085537   \n...                ...                   ...               ...   \n10736              0.0          0.000000e+00         20.085537   \n10737             32.0          2.592987e+05         20.085537   \n10738             45.0          1.769100e+14         27.715964   \n10739              0.0          0.000000e+00         20.085537   \n10740              0.0          0.000000e+00         20.085537   \n\n       Min max price diff  \n0                0.000000  \n1                0.000000  \n2                0.000000  \n3                0.000000  \n4                1.505565  \n...                   ...  \n10736           42.065928  \n10737            0.000000  \n10738           30.522144  \n10739            0.000000  \n10740            0.000000  \n\n[10741 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Brand</th>\n      <th>Comments</th>\n      <th>Final price</th>\n      <th>Days in stock</th>\n      <th>Days with sales</th>\n      <th>Rating</th>\n      <th>Basic Sale</th>\n      <th>Basic Sale Price</th>\n      <th>Days in stock/sales</th>\n      <th>Comments-Rating</th>\n      <th>Rating-Days-Comments</th>\n      <th>Price difference</th>\n      <th>Min max price diff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Majava</td>\n      <td>2.0</td>\n      <td>277.0</td>\n      <td>16.0</td>\n      <td>14</td>\n      <td>0.0</td>\n      <td>50.0</td>\n      <td>360.0</td>\n      <td>0.875000</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>17.885865</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Beon</td>\n      <td>5.0</td>\n      <td>2211.0</td>\n      <td>7.0</td>\n      <td>8</td>\n      <td>3.0</td>\n      <td>40.0</td>\n      <td>2664.0</td>\n      <td>1.000000</td>\n      <td>15.0</td>\n      <td>4.471437e+04</td>\n      <td>20.085537</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NEOLUX</td>\n      <td>19.0</td>\n      <td>490.0</td>\n      <td>31.0</td>\n      <td>22</td>\n      <td>5.0</td>\n      <td>30.0</td>\n      <td>490.0</td>\n      <td>0.709677</td>\n      <td>95.0</td>\n      <td>3.405667e+11</td>\n      <td>18.535758</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CENTEK</td>\n      <td>2.0</td>\n      <td>807.0</td>\n      <td>31.0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>15.0</td>\n      <td>807.0</td>\n      <td>0.000000</td>\n      <td>8.0</td>\n      <td>8.000000e+00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HUAYU</td>\n      <td>3.0</td>\n      <td>426.0</td>\n      <td>31.0</td>\n      <td>5</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>426.0</td>\n      <td>0.161290</td>\n      <td>15.0</td>\n      <td>2.226197e+03</td>\n      <td>20.085537</td>\n      <td>1.505565</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10736</th>\n      <td>INDESIT</td>\n      <td>0.0</td>\n      <td>17803.0</td>\n      <td>31.0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>23.0</td>\n      <td>19781.0</td>\n      <td>0.096774</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>20.085537</td>\n      <td>42.065928</td>\n    </tr>\n    <tr>\n      <th>10737</th>\n      <td>Gelberk</td>\n      <td>8.0</td>\n      <td>897.0</td>\n      <td>12.0</td>\n      <td>9</td>\n      <td>4.0</td>\n      <td>54.0</td>\n      <td>1150.0</td>\n      <td>0.750000</td>\n      <td>32.0</td>\n      <td>2.592987e+05</td>\n      <td>20.085537</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>10738</th>\n      <td>Rowenta</td>\n      <td>15.0</td>\n      <td>1565.0</td>\n      <td>31.0</td>\n      <td>29</td>\n      <td>3.0</td>\n      <td>46.0</td>\n      <td>1565.0</td>\n      <td>0.935484</td>\n      <td>45.0</td>\n      <td>1.769100e+14</td>\n      <td>27.715964</td>\n      <td>30.522144</td>\n    </tr>\n    <tr>\n      <th>10739</th>\n      <td>EREMON</td>\n      <td>0.0</td>\n      <td>2752.0</td>\n      <td>11.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>3440.0</td>\n      <td>0.181818</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>20.085537</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>10740</th>\n      <td>Electrolux</td>\n      <td>0.0</td>\n      <td>16566.0</td>\n      <td>24.0</td>\n      <td>9</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>19490.0</td>\n      <td>0.375000</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>20.085537</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>10741 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_train = process_df(train, True)\n",
    "origin_test = process_df(test, False)\n",
    "origin_test.drop('Id', axis=1, inplace=True)\n",
    "\n",
    "origin_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "outputs": [
    {
     "data": {
      "text/plain": "(10741, 13)"
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_test.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "outputs": [
    {
     "data": {
      "text/plain": "(23338, 14)"
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "outputs": [],
   "source": [
    "def get_histogram(df: pd.DataFrame, name: str):\n",
    "    vals = sorted(df[name].unique())\n",
    "\n",
    "    bins = 1 + log(len(vals), 2)\n",
    "    min = vals[0]\n",
    "    max = vals[len(vals) - 1]\n",
    "    length = (max - min) / bins\n",
    "\n",
    "    intervals = [min + length * i for i in range(int(bins) + 1)]\n",
    "    plt.hist(vals, histtype='stepfilled', bins=intervals)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_histogram(origin_train, 'Final price')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "outputs": [],
   "source": [
    "features = origin_train.drop(['Sales'], axis=1)\n",
    "target = origin_train['Sales']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "outputs": [],
   "source": [
    "# def clear_column_from_extremes(data_frame: pd.DataFrame, col_name: str):\n",
    "#     column = data_frame[col_name]\n",
    "#     q = np.nanquantile(column, q=[0.25, 0.75])\n",
    "#     low = q[0] - 1.5 * (q[1] - q[0])\n",
    "#     high = q[1] + 1.5 * (q[1] - q[0])\n",
    "#\n",
    "#     for index, row in data_frame.iterrows():\n",
    "#         aux = data_frame[col_name].loc[index]\n",
    "#         if not (low <= aux < high) and np.isnan(data_frame[\"G_total\"].loc[index]):\n",
    "#            data_frame.drop(index, inplace=True)\n",
    "#     return data_frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "outputs": [],
   "source": [
    "def delete_nan_cols(df: pd.DataFrame):\n",
    "    new_df = df\n",
    "    nan_count_series = new_df.isna().sum()\n",
    "    column_size = new_df.shape[0]\n",
    "\n",
    "    for i, v in nan_count_series.items():\n",
    "        if (v / column_size) * 100 > 45:\n",
    "            print(f'Deleted {i}')\n",
    "            new_df = new_df.drop(i, axis=1)\n",
    "\n",
    "    return new_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(list(delete_nan_cols(X_train).columns.values)))\n",
    "print(len(list(X_train.columns.values)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "outputs": [],
   "source": [
    "def categorize_columns(data: pd.DataFrame):\n",
    "    categorical_columns = data.columns[data.dtypes == 'object']\n",
    "    print(categorical_columns)\n",
    "\n",
    "    for column in categorical_columns:\n",
    "        data[column] = label_encoder.fit_transform(data[column])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Brand'], dtype='object')\n",
      "Index(['Brand'], dtype='object')\n",
      "Index(['Brand'], dtype='object')\n",
      "Index(['Brand'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "categorize_columns(X_train)\n",
    "categorize_columns(X_test)\n",
    "categorize_columns(origin_test)\n",
    "categorize_columns(origin_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot: >"
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cor = X_train.corr()\n",
    "plt.clf()\n",
    "sns.heatmap(cor, xticklabels=range(X_train.shape[1]), yticklabels=1, linewidths=.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "building tree 1 of 100\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "building tree 2 of 100\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "building tree 3 of 100\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s remaining:    0.0s\n",
      "building tree 4 of 100\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "building tree 5 of 100\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s remaining:    0.0s\n",
      "building tree 6 of 100\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "building tree 7 of 100\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.6s remaining:    0.0s\n",
      "building tree 8 of 100\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.7s remaining:    0.0s\n",
      "building tree 9 of 100\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.7s remaining:    0.0s\n",
      "building tree 10 of 100\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.8s remaining:    0.0s\n",
      "building tree 11 of 100\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.9s remaining:    0.0s\n",
      "building tree 12 of 100\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    1.0s remaining:    0.0s\n",
      "building tree 13 of 100\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    1.0s remaining:    0.0s\n",
      "building tree 14 of 100\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    1.1s remaining:    0.0s\n",
      "building tree 15 of 100\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    1.2s remaining:    0.0s\n",
      "building tree 16 of 100\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    1.3s remaining:    0.0s\n",
      "building tree 17 of 100\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    1.4s remaining:    0.0s\n",
      "building tree 18 of 100\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    1.4s remaining:    0.0s\n",
      "building tree 19 of 100\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    1.5s remaining:    0.0s\n",
      "building tree 20 of 100\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    1.6s remaining:    0.0s\n",
      "building tree 21 of 100\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    1.7s remaining:    0.0s\n",
      "building tree 22 of 100\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    1.7s remaining:    0.0s\n",
      "building tree 23 of 100\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:    1.8s remaining:    0.0s\n",
      "building tree 24 of 100\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    1.9s remaining:    0.0s\n",
      "building tree 25 of 100\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    2.0s remaining:    0.0s\n",
      "building tree 26 of 100\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:    2.1s remaining:    0.0s\n",
      "building tree 27 of 100\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    2.1s remaining:    0.0s\n",
      "building tree 28 of 100\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:    2.2s remaining:    0.0s\n",
      "building tree 29 of 100\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:    2.3s remaining:    0.0s\n",
      "building tree 30 of 100\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.4s remaining:    0.0s\n",
      "building tree 31 of 100\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:    2.5s remaining:    0.0s\n",
      "building tree 32 of 100\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:    2.5s remaining:    0.0s\n",
      "building tree 33 of 100\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:    2.6s remaining:    0.0s\n",
      "building tree 34 of 100\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:    2.7s remaining:    0.0s\n",
      "building tree 35 of 100\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:    2.8s remaining:    0.0s\n",
      "building tree 36 of 100\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    2.9s remaining:    0.0s\n",
      "building tree 37 of 100\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:    2.9s remaining:    0.0s\n",
      "building tree 38 of 100\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:    3.0s remaining:    0.0s\n",
      "building tree 39 of 100\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:    3.1s remaining:    0.0s\n",
      "building tree 40 of 100\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    3.2s remaining:    0.0s\n",
      "building tree 41 of 100\n",
      "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed:    3.2s remaining:    0.0s\n",
      "building tree 42 of 100\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:    3.3s remaining:    0.0s\n",
      "building tree 43 of 100\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:    3.4s remaining:    0.0s\n",
      "building tree 44 of 100\n",
      "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed:    3.5s remaining:    0.0s\n",
      "building tree 45 of 100\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    3.5s remaining:    0.0s\n",
      "building tree 46 of 100\n",
      "[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed:    3.6s remaining:    0.0s\n",
      "building tree 47 of 100\n",
      "[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed:    3.7s remaining:    0.0s\n",
      "building tree 48 of 100\n",
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:    3.8s remaining:    0.0s\n",
      "building tree 49 of 100\n",
      "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:    3.9s remaining:    0.0s\n",
      "building tree 50 of 100\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    3.9s remaining:    0.0s\n",
      "building tree 51 of 100\n",
      "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed:    4.0s remaining:    0.0s\n",
      "building tree 52 of 100\n",
      "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:    4.1s remaining:    0.0s\n",
      "building tree 53 of 100\n",
      "[Parallel(n_jobs=1)]: Done  53 out of  53 | elapsed:    4.2s remaining:    0.0s\n",
      "building tree 54 of 100\n",
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:    4.2s remaining:    0.0s\n",
      "building tree 55 of 100\n",
      "[Parallel(n_jobs=1)]: Done  55 out of  55 | elapsed:    4.3s remaining:    0.0s\n",
      "building tree 56 of 100\n",
      "[Parallel(n_jobs=1)]: Done  56 out of  56 | elapsed:    4.4s remaining:    0.0s\n",
      "building tree 57 of 100\n",
      "[Parallel(n_jobs=1)]: Done  57 out of  57 | elapsed:    4.5s remaining:    0.0s\n",
      "building tree 58 of 100\n",
      "[Parallel(n_jobs=1)]: Done  58 out of  58 | elapsed:    4.6s remaining:    0.0s\n",
      "building tree 59 of 100\n",
      "[Parallel(n_jobs=1)]: Done  59 out of  59 | elapsed:    4.6s remaining:    0.0s\n",
      "building tree 60 of 100\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    4.7s remaining:    0.0s\n",
      "building tree 61 of 100\n",
      "[Parallel(n_jobs=1)]: Done  61 out of  61 | elapsed:    4.8s remaining:    0.0s\n",
      "building tree 62 of 100\n",
      "[Parallel(n_jobs=1)]: Done  62 out of  62 | elapsed:    4.9s remaining:    0.0s\n",
      "building tree 63 of 100\n",
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:    5.0s remaining:    0.0s\n",
      "building tree 64 of 100\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    5.0s remaining:    0.0s\n",
      "building tree 65 of 100\n",
      "[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:    5.1s remaining:    0.0s\n",
      "building tree 66 of 100\n",
      "[Parallel(n_jobs=1)]: Done  66 out of  66 | elapsed:    5.2s remaining:    0.0s\n",
      "building tree 67 of 100\n",
      "[Parallel(n_jobs=1)]: Done  67 out of  67 | elapsed:    5.3s remaining:    0.0s\n",
      "building tree 68 of 100\n",
      "[Parallel(n_jobs=1)]: Done  68 out of  68 | elapsed:    5.3s remaining:    0.0s\n",
      "building tree 69 of 100\n",
      "[Parallel(n_jobs=1)]: Done  69 out of  69 | elapsed:    5.4s remaining:    0.0s\n",
      "building tree 70 of 100\n",
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:    5.5s remaining:    0.0s\n",
      "building tree 71 of 100\n",
      "[Parallel(n_jobs=1)]: Done  71 out of  71 | elapsed:    5.6s remaining:    0.0s\n",
      "building tree 72 of 100\n",
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:    5.7s remaining:    0.0s\n",
      "building tree 73 of 100\n",
      "[Parallel(n_jobs=1)]: Done  73 out of  73 | elapsed:    5.7s remaining:    0.0s\n",
      "building tree 74 of 100\n",
      "[Parallel(n_jobs=1)]: Done  74 out of  74 | elapsed:    5.8s remaining:    0.0s\n",
      "building tree 75 of 100\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    5.9s remaining:    0.0s\n",
      "building tree 76 of 100\n",
      "[Parallel(n_jobs=1)]: Done  76 out of  76 | elapsed:    6.0s remaining:    0.0s\n",
      "building tree 77 of 100\n",
      "[Parallel(n_jobs=1)]: Done  77 out of  77 | elapsed:    6.0s remaining:    0.0s\n",
      "building tree 78 of 100\n",
      "[Parallel(n_jobs=1)]: Done  78 out of  78 | elapsed:    6.1s remaining:    0.0s\n",
      "building tree 79 of 100\n",
      "[Parallel(n_jobs=1)]: Done  79 out of  79 | elapsed:    6.2s remaining:    0.0s\n",
      "building tree 80 of 100\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    6.3s remaining:    0.0s\n",
      "building tree 81 of 100\n",
      "[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed:    6.4s remaining:    0.0s\n",
      "building tree 82 of 100\n",
      "[Parallel(n_jobs=1)]: Done  82 out of  82 | elapsed:    6.4s remaining:    0.0s\n",
      "building tree 83 of 100\n",
      "[Parallel(n_jobs=1)]: Done  83 out of  83 | elapsed:    6.5s remaining:    0.0s\n",
      "building tree 84 of 100\n",
      "[Parallel(n_jobs=1)]: Done  84 out of  84 | elapsed:    6.6s remaining:    0.0s\n",
      "building tree 85 of 100\n",
      "[Parallel(n_jobs=1)]: Done  85 out of  85 | elapsed:    6.7s remaining:    0.0s\n",
      "building tree 86 of 100\n",
      "[Parallel(n_jobs=1)]: Done  86 out of  86 | elapsed:    6.8s remaining:    0.0s\n",
      "building tree 87 of 100\n",
      "[Parallel(n_jobs=1)]: Done  87 out of  87 | elapsed:    6.8s remaining:    0.0s\n",
      "building tree 88 of 100\n",
      "[Parallel(n_jobs=1)]: Done  88 out of  88 | elapsed:    6.9s remaining:    0.0s\n",
      "building tree 89 of 100\n",
      "[Parallel(n_jobs=1)]: Done  89 out of  89 | elapsed:    7.0s remaining:    0.0s\n",
      "building tree 90 of 100\n",
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:    7.1s remaining:    0.0s\n",
      "building tree 91 of 100\n",
      "[Parallel(n_jobs=1)]: Done  91 out of  91 | elapsed:    7.2s remaining:    0.0s\n",
      "building tree 92 of 100\n",
      "[Parallel(n_jobs=1)]: Done  92 out of  92 | elapsed:    7.2s remaining:    0.0s\n",
      "building tree 93 of 100\n",
      "[Parallel(n_jobs=1)]: Done  93 out of  93 | elapsed:    7.3s remaining:    0.0s\n",
      "building tree 94 of 100\n",
      "[Parallel(n_jobs=1)]: Done  94 out of  94 | elapsed:    7.4s remaining:    0.0s\n",
      "building tree 95 of 100\n",
      "[Parallel(n_jobs=1)]: Done  95 out of  95 | elapsed:    7.5s remaining:    0.0s\n",
      "building tree 96 of 100\n",
      "[Parallel(n_jobs=1)]: Done  96 out of  96 | elapsed:    7.5s remaining:    0.0s\n",
      "building tree 97 of 100\n",
      "[Parallel(n_jobs=1)]: Done  97 out of  97 | elapsed:    7.6s remaining:    0.0s\n",
      "building tree 98 of 100\n",
      "[Parallel(n_jobs=1)]: Done  98 out of  98 | elapsed:    7.7s remaining:    0.0s\n",
      "building tree 99 of 100\n",
      "[Parallel(n_jobs=1)]: Done  99 out of  99 | elapsed:    7.8s remaining:    0.0s\n",
      "building tree 100 of 100\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  53 out of  53 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  55 out of  55 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  56 out of  56 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  57 out of  57 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  58 out of  58 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  59 out of  59 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  61 out of  61 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  62 out of  62 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  66 out of  66 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  67 out of  67 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  68 out of  68 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  69 out of  69 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 out of  71 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  73 out of  73 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  74 out of  74 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  76 out of  76 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  77 out of  77 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  78 out of  78 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  79 out of  79 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  82 out of  82 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  83 out of  83 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  84 out of  84 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  85 out of  85 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  86 out of  86 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  87 out of  87 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  88 out of  88 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  89 out of  89 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  91 out of  91 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  92 out of  92 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  93 out of  93 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  94 out of  94 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  95 out of  95 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  96 out of  96 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  97 out of  97 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  98 out of  98 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  99 out of  99 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[0.03361813 0.06868209 0.04199679 0.03115431 0.01844562 0.0063606\n",
      " 0.07602767 0.05185178 0.02373922 0.20601236 0.39613987 0.02563149\n",
      " 0.02034007] ['Brand' 'Comments' 'Final price' 'Days in stock' 'Days with sales'\n",
      " 'Rating' 'Basic Sale' 'Basic Sale Price' 'Days in stock/sales'\n",
      " 'Comments-Rating' 'Rating-Days-Comments' 'Price difference'\n",
      " 'Min max price diff'] 0.5969049685754105\n"
     ]
    }
   ],
   "source": [
    "feature_model = RandomForestRegressor(verbose=999, max_depth=None, random_state=42)\n",
    "\n",
    "feature_model.fit(X_train, y_train)\n",
    "print(feature_model.feature_importances_, feature_model.feature_names_in_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'learning_rate': [0.01, 0.1, 0.2, 0.5, 0.1],\n",
    "#     'min_samples_leaf': [4, 5, 6],\n",
    "#     'loss': ['absolute_error'],\n",
    "#     'l2_regularization': [0.1, 0.2, 0.05],\n",
    "#     'max_bins': [50, 100, 150],\n",
    "#     'max_depth': [None],\n",
    "#     'max_leaf_nodes': [None, 5, 6, 8],\n",
    "#     'validation_fraction': [0.01, 0.1, 0.2]\n",
    "# }\n",
    "#\n",
    "# boost_model = GridSearchCV(\n",
    "#     HistGradientBoostingRegressor(max_iter=1000, max_bins=100, random_state=42),\n",
    "#     params, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=999\n",
    "# )\n",
    "#\n",
    "# boost_model.fit(X_train, y_train)\n",
    "# # learning_rate=0.01, verbose=999, max_depth=None, min_samples_leaf=30, max_iter=1000, loss='absolute_error', l2_regularization=0.02, max_bins=100, validation_fraction=0.02, random_state=42\n",
    "#\n",
    "# # learning_rate=0.01, verbose=999, max_depth=None, min_samples_leaf=4, max_iter=1000, loss='absolute_error', l2_regularization=0.2, max_bins=100, validation_fraction=0.01, random_state=42\n",
    "#\n",
    "# # 'l2_regularization': 0.05,\n",
    "# #  'learning_rate': 0.01,\n",
    "# #  'loss': 'absolute_error',\n",
    "# #  'max_bins': 150,\n",
    "# #  'max_depth': None,\n",
    "# #  'max_leaf_nodes': None,\n",
    "# #  'min_samples_leaf': 6,\n",
    "# #  'validation_fraction': 0.2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "outputs": [],
   "source": [
    "# boost_model.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "#\n",
    "# pipeline = make_pipeline(\n",
    "#     PolynomialFeatures(degree=3),\n",
    "#     SelectKBest(mutual_info_regression, k=10)\n",
    "# )\n",
    "#\n",
    "# poly_features = pipeline.fit_transform(X_train, y_train)\n",
    "# poly_features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    4.7s\n",
      "building tree 34 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.8s\n",
      "building tree 35 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    4.9s\n",
      "building tree 36 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    5.0s\n",
      "building tree 37 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    5.1s\n",
      "building tree 38 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    5.2s\n",
      "building tree 39 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    5.2s\n",
      "building tree 40 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    5.2s\n",
      "building tree 41 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    5.2s\n",
      "building tree 42 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    5.2s\n",
      "building tree 43 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    5.2s\n",
      "building tree 44 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    5.2s\n",
      "building tree 45 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    5.2s\n",
      "building tree 46 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    5.2s\n",
      "building tree 47 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    5.3s\n",
      "building tree 48 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    5.3s\n",
      "building tree 49 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    5.3s\n",
      "building tree 50 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    5.3s\n",
      "building tree 51 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    5.3s\n",
      "building tree 52 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    5.3s\n",
      "building tree 53 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    5.3s\n",
      "building tree 54 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    5.3s\n",
      "building tree 55 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    5.3s\n",
      "building tree 56 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    5.4s\n",
      "building tree 57 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.4s\n",
      "building tree 58 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.4s\n",
      "building tree 59 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    5.4s\n",
      "building tree 60 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    5.4s\n",
      "building tree 61 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    5.4s\n",
      "building tree 62 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    5.5s\n",
      "building tree 63 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:    5.5s\n",
      "building tree 64 of 100[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    5.8s\n",
      "\n",
      "building tree 65 of 100[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    9.6s\n",
      "\n",
      "building tree 66 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    9.8s\n",
      "building tree 67 of 100[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:    9.9s\n",
      "\n",
      "building tree 68 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:   10.0s\n",
      "building tree 69 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.1s\n",
      "building tree 70 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of 100 | elapsed:   10.1s remaining:   16.5s\n",
      "building tree 71 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of 100 | elapsed:   10.2s remaining:   15.9s\n",
      "building tree 72 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of 100 | elapsed:   10.2s remaining:   15.3s\n",
      "building tree 73 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of 100 | elapsed:   10.2s remaining:   14.7s\n",
      "building tree 74 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of 100 | elapsed:   10.2s remaining:   14.1s\n",
      "building tree 75 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of 100 | elapsed:   10.2s remaining:   13.6s\n",
      "building tree 76 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of 100 | elapsed:   10.2s remaining:   13.0s\n",
      "building tree 77 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of 100 | elapsed:   10.3s remaining:   12.6s\n",
      "building tree 78 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of 100 | elapsed:   10.3s remaining:   12.1s\n",
      "building tree 79 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of 100 | elapsed:   10.3s remaining:   11.6s\n",
      "building tree 80 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of 100 | elapsed:   10.3s remaining:   11.2s\n",
      "building tree 81 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of 100 | elapsed:   10.3s remaining:   10.7s\n",
      "building tree 82 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of 100 | elapsed:   10.3s remaining:   10.3s\n",
      "building tree 83 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of 100 | elapsed:   10.3s remaining:    9.9s\n",
      "building tree 84 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of 100 | elapsed:   10.3s remaining:    9.5s\n",
      "building tree 85 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of 100 | elapsed:   10.4s remaining:    9.2s\n",
      "building tree 86 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of 100 | elapsed:   10.4s remaining:    8.9s\n",
      "building tree 87 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of 100 | elapsed:   10.4s remaining:    8.5s\n",
      "building tree 88 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of 100 | elapsed:   10.4s remaining:    8.2s\n",
      "building tree 89 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of 100 | elapsed:   10.5s remaining:    7.9s\n",
      "building tree 90 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of 100 | elapsed:   10.5s remaining:    7.6s\n",
      "building tree 91 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of 100 | elapsed:   10.5s remaining:    7.3s\n",
      "building tree 92 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of 100 | elapsed:   10.5s remaining:    7.0s\n",
      "building tree 93 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of 100 | elapsed:   10.5s remaining:    6.7s\n",
      "building tree 94 of 100[Parallel(n_jobs=-1)]: Done  62 out of 100 | elapsed:   10.6s remaining:    6.5s\n",
      "\n",
      "building tree 95 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  63 out of 100 | elapsed:   10.6s remaining:    6.2s\n",
      "building tree 96 of 100[Parallel(n_jobs=-1)]: Done  64 out of 100 | elapsed:   11.0s remaining:    6.2s\n",
      "\n",
      "building tree 97 of 100[Parallel(n_jobs=-1)]: Done  65 out of 100 | elapsed:   14.0s remaining:    7.5s\n",
      "\n",
      "building tree 98 of 100[Parallel(n_jobs=-1)]: Done  66 out of 100 | elapsed:   14.8s remaining:    7.6s\n",
      "\n",
      "building tree 99 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  67 out of 100 | elapsed:   14.9s remaining:    7.3s\n",
      "building tree 100 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of 100 | elapsed:   14.9s remaining:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of 100 | elapsed:   14.9s remaining:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of 100 | elapsed:   15.0s remaining:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  71 out of 100 | elapsed:   15.1s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of 100 | elapsed:   15.1s remaining:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  73 out of 100 | elapsed:   15.1s remaining:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of 100 | elapsed:   15.2s remaining:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of 100 | elapsed:   15.2s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of 100 | elapsed:   15.2s remaining:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  77 out of 100 | elapsed:   15.2s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  78 out of 100 | elapsed:   15.2s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  79 out of 100 | elapsed:   15.3s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of 100 | elapsed:   15.3s remaining:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of 100 | elapsed:   15.3s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  82 out of 100 | elapsed:   15.3s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  83 out of 100 | elapsed:   15.3s remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of 100 | elapsed:   15.3s remaining:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of 100 | elapsed:   15.4s remaining:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  86 out of 100 | elapsed:   15.4s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  87 out of 100 | elapsed:   15.4s remaining:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  88 out of 100 | elapsed:   15.4s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  89 out of 100 | elapsed:   15.5s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of 100 | elapsed:   15.5s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  91 out of 100 | elapsed:   15.5s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  92 out of 100 | elapsed:   15.5s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:   15.6s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  94 out of 100 | elapsed:   15.6s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  95 out of 100 | elapsed:   15.7s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of 100 | elapsed:   15.7s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  97 out of 100 | elapsed:   17.6s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  98 out of 100 | elapsed:   18.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   18.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   18.1s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   7 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  11 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  13 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  14 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  15 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  19 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  20 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  22 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  23 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  24 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  25 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  31 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  32 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  33 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  35 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  36 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  37 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  38 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  39 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  40 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  41 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  42 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  43 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  44 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  45 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  46 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  47 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  48 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  49 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  50 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  51 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  52 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  53 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  54 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  55 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  56 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  57 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  58 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  59 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  60 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  61 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  62 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  63 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  64 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  65 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  66 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  67 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  68 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  69 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  70 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  71 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  72 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  73 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  75 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  76 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  77 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  78 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  79 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  80 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  81 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  82 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  83 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  84 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  85 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  86 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  87 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  88 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  89 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  90 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  91 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  92 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  93 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  94 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  95 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  96 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  97 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  98 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    6.6s\n",
      "building tree 34 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    6.6s\n",
      "building tree 35 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    7.1s\n",
      "building tree 36 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    7.1s\n",
      "building tree 37 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    7.1s\n",
      "building tree 38 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    7.2s\n",
      "building tree 39 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    7.2s\n",
      "building tree 40 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    7.3s\n",
      "building tree 41 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    7.3s\n",
      "building tree 42 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    7.3s\n",
      "building tree 43 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    7.3s\n",
      "building tree 44 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    7.3s\n",
      "building tree 45 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    7.3s\n",
      "building tree 46 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    7.4s\n",
      "building tree 47 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    7.4s\n",
      "building tree 48 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.4s\n",
      "building tree 49 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    7.4s\n",
      "building tree 50 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    7.4s\n",
      "building tree 51 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    7.5s\n",
      "building tree 52 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    7.5s\n",
      "building tree 53 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    7.5s\n",
      "building tree 54 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    7.5s\n",
      "building tree 55 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    7.5s\n",
      "building tree 56 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    7.5s\n",
      "building tree 57 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    7.6s\n",
      "building tree 58 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    7.6s\n",
      "building tree 59 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    7.6s\n",
      "building tree 60 of 100[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    7.8s\n",
      "\n",
      "building tree 61 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    7.8s\n",
      "building tree 62 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    7.9s\n",
      "building tree 63 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:    8.0s\n",
      "building tree 64 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    8.1s\n",
      "building tree 65 of 100[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   14.1s\n",
      "\n",
      "building tree 66 of 100[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.4s\n",
      "\n",
      "building tree 67 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:   14.5s\n",
      "building tree 68 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:   14.5s\n",
      "building tree 69 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   14.6s\n",
      "building tree 70 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of 100 | elapsed:   14.6s remaining:   23.8s\n",
      "building tree 71 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of 100 | elapsed:   14.6s remaining:   22.8s\n",
      "building tree 72 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of 100 | elapsed:   14.6s remaining:   21.9s\n",
      "building tree 73 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of 100 | elapsed:   14.6s remaining:   21.0s\n",
      "building tree 74 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of 100 | elapsed:   14.7s remaining:   20.2s\n",
      "building tree 75 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of 100 | elapsed:   14.7s remaining:   19.5s\n",
      "building tree 76 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of 100 | elapsed:   14.8s remaining:   18.8s\n",
      "building tree 77 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of 100 | elapsed:   14.8s remaining:   18.1s\n",
      "building tree 78 of 100[Parallel(n_jobs=-1)]: Done  46 out of 100 | elapsed:   14.8s remaining:   17.4s\n",
      "\n",
      "building tree 79 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of 100 | elapsed:   14.9s remaining:   16.8s\n",
      "building tree 80 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of 100 | elapsed:   14.9s remaining:   16.2s\n",
      "building tree 81 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of 100 | elapsed:   14.9s remaining:   15.5s\n",
      "building tree 82 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of 100 | elapsed:   15.0s remaining:   15.0s\n",
      "building tree 83 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of 100 | elapsed:   15.0s remaining:   14.4s\n",
      "building tree 84 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of 100 | elapsed:   15.0s remaining:   13.8s\n",
      "building tree 85 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of 100 | elapsed:   15.0s remaining:   13.3s\n",
      "building tree 86 of 100[Parallel(n_jobs=-1)]: Done  54 out of 100 | elapsed:   15.1s remaining:   12.8s\n",
      "\n",
      "building tree 87 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of 100 | elapsed:   15.1s remaining:   12.4s\n",
      "building tree 88 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of 100 | elapsed:   15.2s remaining:   11.9s\n",
      "building tree 89 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of 100 | elapsed:   15.2s remaining:   11.5s\n",
      "building tree 90 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of 100 | elapsed:   15.2s remaining:   11.0s\n",
      "building tree 91 of 100[Parallel(n_jobs=-1)]: Done  59 out of 100 | elapsed:   15.5s remaining:   10.8s\n",
      "\n",
      "building tree 92 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of 100 | elapsed:   15.5s remaining:   10.3s\n",
      "building tree 93 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of 100 | elapsed:   15.6s remaining:   10.0s\n",
      "building tree 94 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of 100 | elapsed:   15.6s remaining:    9.6s\n",
      "building tree 95 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  63 out of 100 | elapsed:   15.6s remaining:    9.2s\n",
      "building tree 96 of 100[Parallel(n_jobs=-1)]: Done  64 out of 100 | elapsed:   16.7s remaining:    9.4s\n",
      "\n",
      "building tree 97 of 100[Parallel(n_jobs=-1)]: Done  65 out of 100 | elapsed:   21.3s remaining:   11.5s\n",
      "\n",
      "building tree 98 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of 100 | elapsed:   21.5s remaining:   11.1s\n",
      "building tree 99 of 100[Parallel(n_jobs=-1)]: Done  67 out of 100 | elapsed:   21.6s remaining:   10.6s\n",
      "\n",
      "building tree 100 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of 100 | elapsed:   21.6s remaining:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of 100 | elapsed:   21.7s remaining:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of 100 | elapsed:   21.7s remaining:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done  71 out of 100 | elapsed:   22.0s remaining:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of 100 | elapsed:   22.0s remaining:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done  73 out of 100 | elapsed:   22.0s remaining:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of 100 | elapsed:   22.0s remaining:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of 100 | elapsed:   22.1s remaining:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of 100 | elapsed:   22.1s remaining:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done  77 out of 100 | elapsed:   22.1s remaining:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  78 out of 100 | elapsed:   22.1s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  79 out of 100 | elapsed:   22.1s remaining:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of 100 | elapsed:   22.2s remaining:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of 100 | elapsed:   22.3s remaining:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  82 out of 100 | elapsed:   22.3s remaining:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  83 out of 100 | elapsed:   22.3s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of 100 | elapsed:   22.3s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of 100 | elapsed:   22.3s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  86 out of 100 | elapsed:   22.4s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  87 out of 100 | elapsed:   22.4s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  88 out of 100 | elapsed:   22.4s remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  89 out of 100 | elapsed:   22.5s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of 100 | elapsed:   22.6s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  91 out of 100 | elapsed:   22.7s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  92 out of 100 | elapsed:   22.8s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:   22.9s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  94 out of 100 | elapsed:   22.9s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  95 out of 100 | elapsed:   23.0s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of 100 | elapsed:   23.3s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  97 out of 100 | elapsed:   26.3s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  98 out of 100 | elapsed:   26.4s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   26.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   26.7s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   7 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  11 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  13 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  14 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  15 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  19 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  20 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  22 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  23 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  24 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  25 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  31 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  32 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  33 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  35 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  36 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  37 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  38 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  39 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  40 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  41 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  42 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  43 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  44 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  45 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  46 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  47 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  48 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  49 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  50 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  51 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  52 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  53 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  54 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  55 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  56 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  57 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  58 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  59 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  60 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  61 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  62 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  63 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  64 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  65 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  66 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  67 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  68 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  69 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  70 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  71 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  72 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  73 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  75 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  76 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  77 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  78 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  79 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  80 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  81 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  82 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  83 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  84 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  85 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  86 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  87 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  88 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  89 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  90 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  91 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  92 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  93 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  94 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  95 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  96 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  97 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  98 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    6.4s\n",
      "building tree 34 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    6.5s\n",
      "building tree 35 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    6.5s\n",
      "building tree 36 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    6.6s\n",
      "building tree 37 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    6.6s\n",
      "building tree 38 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    6.6s\n",
      "building tree 39 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    6.7s\n",
      "building tree 40 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    6.8s\n",
      "building tree 41 of 100\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    6.8s\n",
      "building tree 42 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    6.8s\n",
      "building tree 43 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    6.8s\n",
      "building tree 44 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    6.8s\n",
      "building tree 45 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    6.9s\n",
      "building tree 46 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    6.9s\n",
      "building tree 47 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    6.9s\n",
      "building tree 48 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    6.9s\n",
      "building tree 49 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.9s\n",
      "building tree 50 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    6.9s\n",
      "building tree 51 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    6.9s\n",
      "building tree 52 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    6.9s\n",
      "building tree 53 of 100[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    7.0s\n",
      "\n",
      "building tree 54 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    7.0s\n",
      "building tree 55 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    7.1s\n",
      "building tree 56 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    7.1s\n",
      "building tree 57 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    7.1s\n",
      "building tree 58 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    7.1s\n",
      "building tree 59 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    7.2s\n",
      "building tree 60 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    7.2s\n",
      "building tree 61 of 100[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    7.6s\n",
      "\n",
      "building tree 62 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    7.6s\n",
      "building tree 63 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:    7.7s\n",
      "building tree 64 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    7.7s\n",
      "building tree 65 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   13.1s\n",
      "building tree 66 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   13.3s\n",
      "building tree 67 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:   13.4s\n",
      "building tree 68 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:   13.4s\n",
      "building tree 69 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   13.4s\n",
      "building tree 70 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of 100 | elapsed:   13.5s remaining:   22.0s\n",
      "building tree 71 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of 100 | elapsed:   13.5s remaining:   21.1s\n",
      "building tree 72 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of 100 | elapsed:   13.5s remaining:   20.3s\n",
      "building tree 73 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of 100 | elapsed:   13.5s remaining:   19.5s\n",
      "building tree 74 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of 100 | elapsed:   13.5s remaining:   18.7s\n",
      "building tree 75 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of 100 | elapsed:   13.6s remaining:   18.0s\n",
      "building tree 76 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of 100 | elapsed:   13.6s remaining:   17.3s\n",
      "building tree 77 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of 100 | elapsed:   13.6s remaining:   16.6s\n",
      "building tree 78 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of 100 | elapsed:   13.6s remaining:   16.0s\n",
      "building tree 79 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of 100 | elapsed:   13.6s remaining:   15.4s\n",
      "building tree 80 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of 100 | elapsed:   13.7s remaining:   14.9s\n",
      "building tree 81 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of 100 | elapsed:   13.7s remaining:   14.3s\n",
      "building tree 82 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of 100 | elapsed:   13.8s remaining:   13.8s\n",
      "building tree 83 of 100[Parallel(n_jobs=-1)]: Done  51 out of 100 | elapsed:   13.8s remaining:   13.3s\n",
      "\n",
      "building tree 84 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of 100 | elapsed:   13.8s remaining:   12.8s\n",
      "building tree 85 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of 100 | elapsed:   13.8s remaining:   12.3s\n",
      "building tree 86 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of 100 | elapsed:   13.8s remaining:   11.8s\n",
      "building tree 87 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of 100 | elapsed:   13.9s remaining:   11.4s\n",
      "building tree 88 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of 100 | elapsed:   13.9s remaining:   11.0s\n",
      "building tree 89 of 100[Parallel(n_jobs=-1)]: Done  57 out of 100 | elapsed:   14.0s remaining:   10.6s\n",
      "\n",
      "building tree 90 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of 100 | elapsed:   14.1s remaining:   10.2s\n",
      "building tree 91 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of 100 | elapsed:   14.1s remaining:    9.8s\n",
      "building tree 92 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of 100 | elapsed:   14.2s remaining:    9.5s\n",
      "building tree 93 of 100[Parallel(n_jobs=-1)]: Done  61 out of 100 | elapsed:   14.3s remaining:    9.1s\n",
      "\n",
      "building tree 94 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of 100 | elapsed:   14.4s remaining:    8.8s\n",
      "building tree 95 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  63 out of 100 | elapsed:   14.6s remaining:    8.6s\n",
      "building tree 96 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of 100 | elapsed:   14.8s remaining:    8.3s\n",
      "building tree 97 of 100[Parallel(n_jobs=-1)]: Done  65 out of 100 | elapsed:   19.8s remaining:   10.7s\n",
      "\n",
      "building tree 98 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of 100 | elapsed:   20.0s remaining:   10.3s\n",
      "building tree 99 of 100[Parallel(n_jobs=-1)]: Done  67 out of 100 | elapsed:   20.1s remaining:    9.9s\n",
      "\n",
      "building tree 100 of 100\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of 100 | elapsed:   20.2s remaining:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of 100 | elapsed:   20.2s remaining:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of 100 | elapsed:   20.2s remaining:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done  71 out of 100 | elapsed:   20.3s remaining:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of 100 | elapsed:   20.3s remaining:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done  73 out of 100 | elapsed:   20.3s remaining:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of 100 | elapsed:   20.3s remaining:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of 100 | elapsed:   20.4s remaining:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of 100 | elapsed:   20.4s remaining:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  77 out of 100 | elapsed:   20.5s remaining:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  78 out of 100 | elapsed:   20.5s remaining:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done  79 out of 100 | elapsed:   20.5s remaining:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of 100 | elapsed:   20.5s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of 100 | elapsed:   20.5s remaining:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  82 out of 100 | elapsed:   20.6s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  83 out of 100 | elapsed:   20.6s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of 100 | elapsed:   20.6s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of 100 | elapsed:   20.7s remaining:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  86 out of 100 | elapsed:   20.8s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  87 out of 100 | elapsed:   20.8s remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  88 out of 100 | elapsed:   20.8s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  89 out of 100 | elapsed:   20.9s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of 100 | elapsed:   21.0s remaining:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  91 out of 100 | elapsed:   21.1s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  92 out of 100 | elapsed:   21.1s remaining:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:   21.1s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  94 out of 100 | elapsed:   21.2s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  95 out of 100 | elapsed:   21.2s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of 100 | elapsed:   21.3s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  97 out of 100 | elapsed:   24.1s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  98 out of 100 | elapsed:   24.4s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   24.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   24.6s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   7 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  11 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  13 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  14 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  15 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  19 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  20 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  22 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  23 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  24 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  25 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  31 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  32 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  33 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  35 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  36 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  37 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  38 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  39 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  40 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  41 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  42 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  43 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  44 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  45 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  46 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  47 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  48 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  49 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  50 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  51 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  52 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  53 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  54 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  55 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  56 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  57 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  58 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  59 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  60 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  61 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  62 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  63 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  64 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  65 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  66 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  67 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  68 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  69 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  70 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  71 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  72 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  73 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  75 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  76 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  77 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  78 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  79 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  80 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  81 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  82 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  83 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  84 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  85 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  86 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  87 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  88 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  89 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  90 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  91 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  92 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  93 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  94 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  95 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  96 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  97 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  98 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": "AdaBoostRegressor(estimator=RandomForestRegressor(criterion='absolute_error',\n                                                  min_samples_leaf=20,\n                                                  min_samples_split=20,\n                                                  n_jobs=-1, random_state=42,\n                                                  verbose=999),\n                  n_estimators=3, random_state=42)",
      "text/html": "<style>#sk-container-id-97 {color: black;background-color: white;}#sk-container-id-97 pre{padding: 0;}#sk-container-id-97 div.sk-toggleable {background-color: white;}#sk-container-id-97 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-97 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-97 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-97 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-97 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-97 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-97 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-97 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-97 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-97 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-97 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-97 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-97 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-97 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-97 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-97 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-97 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-97 div.sk-item {position: relative;z-index: 1;}#sk-container-id-97 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-97 div.sk-item::before, #sk-container-id-97 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-97 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-97 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-97 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-97 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-97 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-97 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-97 div.sk-label-container {text-align: center;}#sk-container-id-97 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-97 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-97\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostRegressor(estimator=RandomForestRegressor(criterion=&#x27;absolute_error&#x27;,\n                                                  min_samples_leaf=20,\n                                                  min_samples_split=20,\n                                                  n_jobs=-1, random_state=42,\n                                                  verbose=999),\n                  n_estimators=3, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-117\" type=\"checkbox\" ><label for=\"sk-estimator-id-117\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor(estimator=RandomForestRegressor(criterion=&#x27;absolute_error&#x27;,\n                                                  min_samples_leaf=20,\n                                                  min_samples_split=20,\n                                                  n_jobs=-1, random_state=42,\n                                                  verbose=999),\n                  n_estimators=3, random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-118\" type=\"checkbox\" ><label for=\"sk-estimator-id-118\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(criterion=&#x27;absolute_error&#x27;, min_samples_leaf=20,\n                      min_samples_split=20, n_jobs=-1, random_state=42,\n                      verbose=999)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-119\" type=\"checkbox\" ><label for=\"sk-estimator-id-119\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(criterion=&#x27;absolute_error&#x27;, min_samples_leaf=20,\n                      min_samples_split=20, n_jobs=-1, random_state=42,\n                      verbose=999)</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "forest_model = RandomForestRegressor(n_estimators=100, criterion='absolute_error', verbose=999, min_samples_leaf=20,\n",
    "                                     min_samples_split=20,\n",
    "                                     random_state=42, n_jobs=-1)\n",
    "boost_model = AdaBoostRegressor(estimator=forest_model, n_estimators=3, loss=\"linear\", random_state=42)\n",
    "\n",
    "# boost_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.002 GB of training data: 0.060 s\n",
      "Binning 0.000 GB of validation data: 0.001 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/10000] 1 tree, 31 leaves, max depth = 9, train loss: 42.16146, val loss: 34.38025, in 0.005s\n",
      "[2/10000] 1 tree, 31 leaves, max depth = 8, train loss: 42.07029, val loss: 34.29773, in 0.029s\n",
      "[3/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.97906, val loss: 34.21458, in 0.045s\n",
      "[4/10000] 1 tree, 31 leaves, max depth = 9, train loss: 41.88960, val loss: 34.13339, in 0.017s\n",
      "[5/10000] 1 tree, 31 leaves, max depth = 10, train loss: 41.80104, val loss: 34.05314, in 0.016s\n",
      "[6/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.71412, val loss: 33.97356, in 0.006s\n",
      "[7/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.61907, val loss: 33.88538, in 0.008s\n",
      "[8/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.52499, val loss: 33.79814, in 0.006s\n",
      "[9/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.43185, val loss: 33.71182, in 0.006s\n",
      "[10/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.33964, val loss: 33.62637, in 0.016s\n",
      "[11/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.24931, val loss: 33.54177, in 0.006s\n",
      "[12/10000] 1 tree, 31 leaves, max depth = 9, train loss: 41.14952, val loss: 33.44920, in 0.009s\n",
      "[13/10000] 1 tree, 31 leaves, max depth = 9, train loss: 41.05073, val loss: 33.35755, in 0.006s\n",
      "[14/10000] 1 tree, 31 leaves, max depth = 9, train loss: 40.95293, val loss: 33.26682, in 0.013s\n",
      "[15/10000] 1 tree, 31 leaves, max depth = 9, train loss: 40.85645, val loss: 33.17791, in 0.006s\n",
      "[16/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.75568, val loss: 33.08339, in 0.013s\n",
      "[17/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.65602, val loss: 32.99015, in 0.006s\n",
      "[18/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.55710, val loss: 32.89788, in 0.005s\n",
      "[19/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.45992, val loss: 32.81005, in 0.007s\n",
      "[20/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.35666, val loss: 32.72126, in 0.005s\n",
      "[21/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.25443, val loss: 32.63337, in 0.005s\n",
      "[22/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.15348, val loss: 32.54635, in 0.070s\n",
      "[23/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.04745, val loss: 32.45090, in 0.109s\n",
      "[24/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.94250, val loss: 32.35641, in 0.007s\n",
      "[25/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.83887, val loss: 32.26281, in 0.028s\n",
      "[26/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.73659, val loss: 32.17015, in 0.005s\n",
      "[27/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.63537, val loss: 32.07876, in 0.006s\n",
      "[28/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.53616, val loss: 31.98828, in 0.008s\n",
      "[29/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.44216, val loss: 31.90761, in 0.005s\n",
      "[30/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.33782, val loss: 31.81666, in 0.011s\n",
      "[31/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.23538, val loss: 31.72691, in 0.005s\n",
      "[32/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.12870, val loss: 31.62813, in 0.006s\n",
      "[33/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.02341, val loss: 31.53034, in 0.009s\n",
      "[34/10000] 1 tree, 31 leaves, max depth = 7, train loss: 38.91831, val loss: 31.43191, in 0.005s\n",
      "[35/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.82442, val loss: 31.34950, in 0.006s\n",
      "[36/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.72023, val loss: 31.25497, in 0.012s\n",
      "[37/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.61825, val loss: 31.15774, in 0.005s\n",
      "[38/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.51253, val loss: 31.05699, in 0.005s\n",
      "[39/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.40059, val loss: 30.95300, in 0.011s\n",
      "[40/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.28994, val loss: 30.85726, in 0.006s\n",
      "[41/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.18780, val loss: 30.76466, in 0.005s\n",
      "[42/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.07899, val loss: 30.66931, in 0.014s\n",
      "[43/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.96904, val loss: 30.57179, in 0.005s\n",
      "[44/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.86279, val loss: 30.47909, in 0.008s\n",
      "[45/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.75025, val loss: 30.37437, in 0.007s\n",
      "[46/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.63927, val loss: 30.27042, in 0.005s\n",
      "[47/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.52917, val loss: 30.16713, in 0.008s\n",
      "[48/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.41293, val loss: 30.06432, in 0.011s\n",
      "[49/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.30257, val loss: 29.96360, in 0.008s\n",
      "[50/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.19342, val loss: 29.86013, in 0.005s\n",
      "[51/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.07565, val loss: 29.75833, in 0.005s\n",
      "[52/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.96059, val loss: 29.65761, in 0.008s\n",
      "[53/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.84317, val loss: 29.55397, in 0.006s\n",
      "[54/10000] 1 tree, 31 leaves, max depth = 10, train loss: 36.73443, val loss: 29.45724, in 0.020s\n",
      "[55/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.61696, val loss: 29.34884, in 0.006s\n",
      "[56/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.50144, val loss: 29.24200, in 0.008s\n",
      "[57/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.38797, val loss: 29.13627, in 0.006s\n",
      "[58/10000] 1 tree, 31 leaves, max depth = 9, train loss: 36.26749, val loss: 29.02476, in 0.005s\n",
      "[59/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.14790, val loss: 28.91417, in 0.109s\n",
      "[60/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.03219, val loss: 28.80687, in 0.033s\n",
      "[61/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.90365, val loss: 28.69197, in 0.007s\n",
      "[62/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.78034, val loss: 28.58186, in 0.068s\n",
      "[63/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.66514, val loss: 28.48009, in 0.006s\n",
      "[64/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.55191, val loss: 28.37900, in 0.006s\n",
      "[65/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.44572, val loss: 28.29404, in 0.052s\n",
      "[66/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.32605, val loss: 28.18700, in 0.007s\n",
      "[67/10000] 1 tree, 31 leaves, max depth = 10, train loss: 35.19939, val loss: 28.07671, in 0.023s\n",
      "[68/10000] 1 tree, 31 leaves, max depth = 7, train loss: 35.08153, val loss: 27.97777, in 0.009s\n",
      "[69/10000] 1 tree, 31 leaves, max depth = 7, train loss: 34.95140, val loss: 27.85479, in 0.006s\n",
      "[70/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.82475, val loss: 27.73410, in 0.005s\n",
      "[71/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.70802, val loss: 27.62872, in 0.005s\n",
      "[72/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.58898, val loss: 27.51832, in 0.009s\n",
      "[73/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.46919, val loss: 27.41880, in 0.009s\n",
      "[74/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.34615, val loss: 27.31238, in 0.005s\n",
      "[75/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.22022, val loss: 27.19500, in 0.008s\n",
      "[76/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.10064, val loss: 27.08844, in 0.005s\n",
      "[77/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.97912, val loss: 26.97046, in 0.006s\n",
      "[78/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.85932, val loss: 26.85337, in 0.005s\n",
      "[79/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.73546, val loss: 26.72629, in 0.005s\n",
      "[80/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.61338, val loss: 26.59824, in 0.013s\n",
      "[81/10000] 1 tree, 31 leaves, max depth = 11, train loss: 33.48882, val loss: 26.48234, in 0.005s\n",
      "[82/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.36576, val loss: 26.36910, in 0.008s\n",
      "[83/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.24334, val loss: 26.25541, in 0.006s\n",
      "[84/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.12373, val loss: 26.14412, in 0.006s\n",
      "[85/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.99736, val loss: 26.02474, in 0.016s\n",
      "[86/10000] 1 tree, 31 leaves, max depth = 11, train loss: 32.87356, val loss: 25.90539, in 0.009s\n",
      "[87/10000] 1 tree, 31 leaves, max depth = 11, train loss: 32.77904, val loss: 25.81038, in 0.005s\n",
      "[88/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.66444, val loss: 25.67825, in 0.005s\n",
      "[89/10000] 1 tree, 31 leaves, max depth = 10, train loss: 32.54734, val loss: 25.55578, in 0.005s\n",
      "[90/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.42167, val loss: 25.43807, in 0.005s\n",
      "[91/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.29720, val loss: 25.33046, in 0.006s\n",
      "[92/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.19084, val loss: 25.22157, in 0.005s\n",
      "[93/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.09596, val loss: 25.13481, in 0.014s\n",
      "[94/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.00330, val loss: 25.06040, in 0.026s\n",
      "[95/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.89028, val loss: 24.96046, in 0.006s\n",
      "[96/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.77882, val loss: 24.85948, in 0.015s\n",
      "[97/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.66762, val loss: 24.75819, in 0.005s\n",
      "[98/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.55827, val loss: 24.65901, in 0.010s\n",
      "[99/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.43770, val loss: 24.56529, in 0.029s\n",
      "[100/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.31476, val loss: 24.46888, in 0.070s\n",
      "[101/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.17950, val loss: 24.36995, in 0.007s\n",
      "[102/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.04763, val loss: 24.27524, in 0.011s\n",
      "[103/10000] 1 tree, 31 leaves, max depth = 9, train loss: 30.91809, val loss: 24.18552, in 0.014s\n",
      "[104/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.79034, val loss: 24.08973, in 0.009s\n",
      "[105/10000] 1 tree, 31 leaves, max depth = 9, train loss: 30.68200, val loss: 24.00378, in 0.008s\n",
      "[106/10000] 1 tree, 31 leaves, max depth = 9, train loss: 30.56579, val loss: 23.91111, in 0.009s\n",
      "[107/10000] 1 tree, 31 leaves, max depth = 9, train loss: 30.45975, val loss: 23.82370, in 0.006s\n",
      "[108/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.36657, val loss: 23.73042, in 0.013s\n",
      "[109/10000] 1 tree, 31 leaves, max depth = 7, train loss: 30.24218, val loss: 23.61847, in 0.046s\n",
      "[110/10000] 1 tree, 31 leaves, max depth = 10, train loss: 30.14439, val loss: 23.53350, in 0.007s\n",
      "[111/10000] 1 tree, 31 leaves, max depth = 9, train loss: 30.02478, val loss: 23.43232, in 0.012s\n",
      "[112/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.91578, val loss: 23.35688, in 0.019s\n",
      "[113/10000] 1 tree, 31 leaves, max depth = 7, train loss: 29.82647, val loss: 23.28993, in 0.009s\n",
      "[114/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.72084, val loss: 23.21428, in 0.010s\n",
      "[115/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.61660, val loss: 23.13933, in 0.015s\n",
      "[116/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.50463, val loss: 23.04387, in 0.008s\n",
      "[117/10000] 1 tree, 31 leaves, max depth = 11, train loss: 29.39697, val loss: 22.95574, in 0.007s\n",
      "[118/10000] 1 tree, 31 leaves, max depth = 7, train loss: 29.28786, val loss: 22.85856, in 0.011s\n",
      "[119/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.18115, val loss: 22.76616, in 0.016s\n",
      "[120/10000] 1 tree, 31 leaves, max depth = 7, train loss: 29.08389, val loss: 22.69753, in 0.018s\n",
      "[121/10000] 1 tree, 31 leaves, max depth = 7, train loss: 29.00420, val loss: 22.64306, in 0.006s\n",
      "[122/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.92497, val loss: 22.59313, in 0.014s\n",
      "[123/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.84220, val loss: 22.52817, in 0.006s\n",
      "[124/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.76796, val loss: 22.47669, in 0.005s\n",
      "[125/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.66768, val loss: 22.38069, in 0.008s\n",
      "[126/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.57071, val loss: 22.28628, in 0.035s\n",
      "[127/10000] 1 tree, 31 leaves, max depth = 7, train loss: 28.47343, val loss: 22.21305, in 0.010s\n",
      "[128/10000] 1 tree, 31 leaves, max depth = 7, train loss: 28.37425, val loss: 22.19913, in 0.008s\n",
      "[129/10000] 1 tree, 31 leaves, max depth = 11, train loss: 28.30402, val loss: 22.14980, in 0.018s\n",
      "[130/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.22082, val loss: 22.09701, in 0.006s\n",
      "[131/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.15331, val loss: 22.04652, in 0.009s\n",
      "[132/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.08749, val loss: 21.99596, in 0.005s\n",
      "[133/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.99935, val loss: 21.91821, in 0.007s\n",
      "[134/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.92537, val loss: 21.85383, in 0.007s\n",
      "[135/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.83837, val loss: 21.84983, in 0.005s\n",
      "[136/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.75243, val loss: 21.83921, in 0.006s\n",
      "[137/10000] 1 tree, 31 leaves, max depth = 7, train loss: 27.68114, val loss: 21.79090, in 0.020s\n",
      "[138/10000] 1 tree, 31 leaves, max depth = 7, train loss: 27.60713, val loss: 21.75495, in 0.008s\n",
      "[139/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.53626, val loss: 21.70933, in 0.007s\n",
      "[140/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.46013, val loss: 21.66357, in 0.007s\n",
      "[141/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.38252, val loss: 21.64736, in 0.008s\n",
      "[142/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.30158, val loss: 21.58294, in 0.008s\n",
      "[143/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.23284, val loss: 21.53167, in 0.010s\n",
      "[144/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.15533, val loss: 21.46767, in 0.019s\n",
      "[145/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.08905, val loss: 21.45044, in 0.006s\n",
      "[146/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.01093, val loss: 21.38690, in 0.021s\n",
      "[147/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.93352, val loss: 21.32477, in 0.009s\n",
      "[148/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.85228, val loss: 21.22604, in 0.006s\n",
      "[149/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.76887, val loss: 21.12631, in 0.021s\n",
      "[150/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.69681, val loss: 21.07942, in 0.006s\n",
      "[151/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.62074, val loss: 21.01054, in 0.009s\n",
      "[152/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.55587, val loss: 20.95414, in 0.006s\n",
      "[153/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.48650, val loss: 20.90530, in 0.005s\n",
      "[154/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.42040, val loss: 20.85818, in 0.007s\n",
      "[155/10000] 1 tree, 31 leaves, max depth = 11, train loss: 26.35957, val loss: 20.82511, in 0.005s\n",
      "[156/10000] 1 tree, 31 leaves, max depth = 10, train loss: 26.30460, val loss: 20.77938, in 0.005s\n",
      "[157/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.23626, val loss: 20.68946, in 0.021s\n",
      "[158/10000] 1 tree, 31 leaves, max depth = 10, train loss: 26.16986, val loss: 20.60158, in 0.009s\n",
      "[159/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.10399, val loss: 20.51137, in 0.006s\n",
      "[160/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.05774, val loss: 20.45351, in 0.005s\n",
      "[161/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.00332, val loss: 20.43308, in 0.007s\n",
      "[162/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.93930, val loss: 20.41375, in 0.012s\n",
      "[163/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.86555, val loss: 20.36568, in 0.009s\n",
      "[164/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.81254, val loss: 20.31040, in 0.006s\n",
      "[165/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.75782, val loss: 20.28108, in 0.005s\n",
      "[166/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.69986, val loss: 20.24872, in 0.009s\n",
      "[167/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.64952, val loss: 20.22780, in 0.009s\n",
      "[168/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.59409, val loss: 20.18176, in 0.009s\n",
      "[169/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.54471, val loss: 20.15574, in 0.005s\n",
      "[170/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.47896, val loss: 20.12275, in 0.007s\n",
      "[171/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.42512, val loss: 20.04695, in 0.010s\n",
      "[172/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.38335, val loss: 19.99458, in 0.006s\n",
      "[173/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.33979, val loss: 19.93124, in 0.005s\n",
      "[174/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.28951, val loss: 19.88581, in 0.013s\n",
      "[175/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.24624, val loss: 19.85039, in 0.013s\n",
      "[176/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.19250, val loss: 19.83347, in 0.007s\n",
      "[177/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.13225, val loss: 19.81015, in 0.008s\n",
      "[178/10000] 1 tree, 31 leaves, max depth = 11, train loss: 25.08771, val loss: 19.79637, in 0.012s\n",
      "[179/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.04885, val loss: 19.78275, in 0.006s\n",
      "[180/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.01792, val loss: 19.76322, in 0.008s\n",
      "[181/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.99445, val loss: 19.74302, in 0.025s\n",
      "[182/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.95098, val loss: 19.67163, in 0.006s\n",
      "[183/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.91234, val loss: 19.64087, in 0.008s\n",
      "[184/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.89325, val loss: 19.61975, in 0.016s\n",
      "[185/10000] 1 tree, 31 leaves, max depth = 11, train loss: 24.86899, val loss: 19.59558, in 0.006s\n",
      "[186/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.83883, val loss: 19.56344, in 0.015s\n",
      "[187/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.81654, val loss: 19.54146, in 0.006s\n",
      "[188/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.77575, val loss: 19.45672, in 0.013s\n",
      "[189/10000] 1 tree, 31 leaves, max depth = 11, train loss: 24.75316, val loss: 19.43349, in 0.005s\n",
      "[190/10000] 1 tree, 31 leaves, max depth = 11, train loss: 24.70476, val loss: 19.40822, in 0.011s\n",
      "[191/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.66243, val loss: 19.36894, in 0.006s\n",
      "[192/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.62097, val loss: 19.33031, in 0.006s\n",
      "[193/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.57842, val loss: 19.29401, in 0.019s\n",
      "[194/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.53630, val loss: 19.25777, in 0.009s\n",
      "[195/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.51577, val loss: 19.24191, in 0.006s\n",
      "[196/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.47980, val loss: 19.19178, in 0.055s\n",
      "[197/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.44405, val loss: 19.14166, in 0.006s\n",
      "[198/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.40811, val loss: 19.07701, in 0.008s\n",
      "[199/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.36937, val loss: 19.03108, in 0.005s\n",
      "[200/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.34262, val loss: 19.00839, in 0.005s\n",
      "[201/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.30308, val loss: 18.97422, in 0.006s\n",
      "[202/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.26420, val loss: 18.94099, in 0.019s\n",
      "[203/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.22956, val loss: 18.90367, in 0.008s\n",
      "[204/10000] 1 tree, 31 leaves, max depth = 12, train loss: 24.19107, val loss: 18.87043, in 0.005s\n",
      "[205/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.15876, val loss: 18.82455, in 0.012s\n",
      "[206/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.12724, val loss: 18.77935, in 0.005s\n",
      "[207/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.09685, val loss: 18.73371, in 0.005s\n",
      "[208/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.06192, val loss: 18.72684, in 0.009s\n",
      "[209/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.04684, val loss: 18.70630, in 0.005s\n",
      "[210/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.00670, val loss: 18.70269, in 0.006s\n",
      "[211/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.97297, val loss: 18.69641, in 0.019s\n",
      "[212/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.93897, val loss: 18.69062, in 0.008s\n",
      "[213/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.90389, val loss: 18.68137, in 0.006s\n",
      "[214/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.86410, val loss: 18.67499, in 0.006s\n",
      "[215/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.85207, val loss: 18.66822, in 0.009s\n",
      "[216/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.82756, val loss: 18.65463, in 0.013s\n",
      "[217/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.80534, val loss: 18.64040, in 0.009s\n",
      "[218/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.77988, val loss: 18.63470, in 0.007s\n",
      "[219/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.76905, val loss: 18.62263, in 0.014s\n",
      "[220/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.74501, val loss: 18.61643, in 0.006s\n",
      "[221/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.71611, val loss: 18.57838, in 0.008s\n",
      "[222/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.70593, val loss: 18.57053, in 0.006s\n",
      "[223/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.68992, val loss: 18.56105, in 0.005s\n",
      "[224/10000] 1 tree, 31 leaves, max depth = 12, train loss: 23.67618, val loss: 18.55583, in 0.021s\n",
      "[225/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.65924, val loss: 18.54954, in 0.009s\n",
      "[226/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.63460, val loss: 18.52917, in 0.008s\n",
      "[227/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.60882, val loss: 18.52427, in 0.005s\n",
      "[228/10000] 1 tree, 31 leaves, max depth = 12, train loss: 23.58825, val loss: 18.50601, in 0.009s\n",
      "[229/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.56056, val loss: 18.47485, in 0.010s\n",
      "[230/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.53813, val loss: 18.46235, in 0.010s\n",
      "[231/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.51448, val loss: 18.44842, in 0.021s\n",
      "[232/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.48611, val loss: 18.42297, in 0.006s\n",
      "[233/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.46346, val loss: 18.41183, in 0.013s\n",
      "[234/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.44103, val loss: 18.40065, in 0.008s\n",
      "[235/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.42359, val loss: 18.38587, in 0.009s\n",
      "[236/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.40167, val loss: 18.37080, in 0.012s\n",
      "[237/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.38004, val loss: 18.35967, in 0.008s\n",
      "[238/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.35866, val loss: 18.34338, in 0.005s\n",
      "[239/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.34102, val loss: 18.32586, in 0.005s\n",
      "[240/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.32191, val loss: 18.30197, in 0.008s\n",
      "[241/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.29639, val loss: 18.27286, in 0.005s\n",
      "[242/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.27643, val loss: 18.26033, in 0.005s\n",
      "[243/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.25446, val loss: 18.25363, in 0.054s\n",
      "[244/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.22837, val loss: 18.24085, in 0.009s\n",
      "[245/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.20333, val loss: 18.21248, in 0.070s\n",
      "[246/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.16272, val loss: 18.20378, in 0.008s\n",
      "[247/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.13845, val loss: 18.19956, in 0.011s\n",
      "[248/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.12167, val loss: 18.19491, in 0.012s\n",
      "[249/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.09784, val loss: 18.18752, in 0.010s\n",
      "[250/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.07763, val loss: 18.17094, in 0.006s\n",
      "[251/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.05699, val loss: 18.15520, in 0.008s\n",
      "[252/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.04218, val loss: 18.14282, in 0.032s\n",
      "[253/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.02294, val loss: 18.12739, in 0.008s\n",
      "[254/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.00061, val loss: 18.10181, in 0.005s\n",
      "[255/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.97904, val loss: 18.08042, in 0.007s\n",
      "[256/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.95456, val loss: 18.07676, in 0.009s\n",
      "[257/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.94141, val loss: 18.06119, in 0.015s\n",
      "[258/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.92845, val loss: 18.04580, in 0.009s\n",
      "[259/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.91304, val loss: 18.02507, in 0.005s\n",
      "[260/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.89786, val loss: 18.01854, in 0.005s\n",
      "[261/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.87353, val loss: 18.01195, in 0.008s\n",
      "[262/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.85921, val loss: 17.99475, in 0.005s\n",
      "[263/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.83560, val loss: 17.99086, in 0.005s\n",
      "[264/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.82007, val loss: 17.97275, in 0.014s\n",
      "[265/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.79814, val loss: 17.95849, in 0.005s\n",
      "[266/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.76107, val loss: 17.95113, in 0.015s\n",
      "[267/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.72322, val loss: 17.94437, in 0.006s\n",
      "[268/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.70917, val loss: 17.92467, in 0.016s\n",
      "[269/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.69533, val loss: 17.90521, in 0.008s\n",
      "[270/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.68005, val loss: 17.88454, in 0.006s\n",
      "[271/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.66926, val loss: 17.86308, in 0.005s\n",
      "[272/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.65576, val loss: 17.84400, in 0.005s\n",
      "[273/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.64022, val loss: 17.82145, in 0.008s\n",
      "[274/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.62641, val loss: 17.80775, in 0.005s\n",
      "[275/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.61146, val loss: 17.78607, in 0.017s\n",
      "[276/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.59831, val loss: 17.77246, in 0.006s\n",
      "[277/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.58460, val loss: 17.75905, in 0.008s\n",
      "[278/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.57325, val loss: 17.73819, in 0.005s\n",
      "[279/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.56704, val loss: 17.72577, in 0.007s\n",
      "[280/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.55776, val loss: 17.71532, in 0.009s\n",
      "[281/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.54622, val loss: 17.69420, in 0.006s\n",
      "[282/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.53246, val loss: 17.67530, in 0.021s\n",
      "[283/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.51870, val loss: 17.65614, in 0.011s\n",
      "[284/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.50461, val loss: 17.63657, in 0.006s\n",
      "[285/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.49090, val loss: 17.61280, in 0.012s\n",
      "[286/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.47908, val loss: 17.59597, in 0.006s\n",
      "[287/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.46662, val loss: 17.57747, in 0.006s\n",
      "[288/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.45310, val loss: 17.55263, in 0.008s\n",
      "[289/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.43967, val loss: 17.52795, in 0.005s\n",
      "[290/10000] 1 tree, 31 leaves, max depth = 13, train loss: 22.42651, val loss: 17.50399, in 0.006s\n",
      "[291/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.41274, val loss: 17.47996, in 0.032s\n",
      "[292/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.40035, val loss: 17.45792, in 0.006s\n",
      "[293/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.38809, val loss: 17.43609, in 0.069s\n",
      "[294/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.37631, val loss: 17.41445, in 0.076s\n",
      "[295/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.36896, val loss: 17.40699, in 0.006s\n",
      "[296/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.35585, val loss: 17.38457, in 0.008s\n",
      "[297/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.34948, val loss: 17.38155, in 0.006s\n",
      "[298/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34125, val loss: 17.37556, in 0.014s\n",
      "[299/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.33399, val loss: 17.36809, in 0.005s\n",
      "[300/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.32622, val loss: 17.36450, in 0.005s\n",
      "[301/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31735, val loss: 17.34532, in 0.006s\n",
      "[302/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.30074, val loss: 17.34357, in 0.005s\n",
      "[303/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.27103, val loss: 17.33881, in 0.005s\n",
      "[304/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.25357, val loss: 17.33309, in 0.009s\n",
      "[305/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.24084, val loss: 17.32843, in 0.005s\n",
      "[306/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.22814, val loss: 17.32370, in 0.005s\n",
      "[307/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.22006, val loss: 17.31666, in 0.014s\n",
      "[308/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.21029, val loss: 17.31289, in 0.006s\n",
      "[309/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.20208, val loss: 17.30427, in 0.009s\n",
      "[310/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.17414, val loss: 17.29954, in 0.007s\n",
      "[311/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.16393, val loss: 17.29671, in 0.006s\n",
      "[312/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.14243, val loss: 17.29337, in 0.016s\n",
      "[313/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.13216, val loss: 17.27598, in 0.008s\n",
      "[314/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.12332, val loss: 17.27481, in 0.005s\n",
      "[315/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.09870, val loss: 17.27374, in 0.005s\n",
      "[316/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.07771, val loss: 17.27299, in 0.009s\n",
      "[317/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.06003, val loss: 17.26903, in 0.005s\n",
      "[318/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.04356, val loss: 17.26763, in 0.005s\n",
      "[319/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.03104, val loss: 17.24639, in 0.015s\n",
      "[320/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.01934, val loss: 17.22521, in 0.006s\n",
      "[321/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.01289, val loss: 17.21671, in 0.013s\n",
      "[322/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.00784, val loss: 17.20936, in 0.007s\n",
      "[323/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.00153, val loss: 17.20538, in 0.005s\n",
      "[324/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.99448, val loss: 17.19452, in 0.014s\n",
      "[325/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.97827, val loss: 17.19382, in 0.006s\n",
      "[326/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.97143, val loss: 17.18328, in 0.010s\n",
      "[327/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.96467, val loss: 17.17284, in 0.006s\n",
      "[328/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.96062, val loss: 17.16941, in 0.007s\n",
      "[329/10000] 1 tree, 31 leaves, max depth = 12, train loss: 21.95712, val loss: 17.16551, in 0.017s\n",
      "[330/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.94923, val loss: 17.15643, in 0.010s\n",
      "[331/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.94355, val loss: 17.15521, in 0.007s\n",
      "[332/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.93658, val loss: 17.15450, in 0.008s\n",
      "[333/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.91846, val loss: 17.15376, in 0.013s\n",
      "[334/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.90010, val loss: 17.15181, in 0.038s\n",
      "[335/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.88193, val loss: 17.14988, in 0.011s\n",
      "[336/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.87086, val loss: 17.13129, in 0.006s\n",
      "[337/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.86366, val loss: 17.11873, in 0.011s\n",
      "[338/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.85325, val loss: 17.10062, in 0.006s\n",
      "[339/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.84225, val loss: 17.09654, in 0.006s\n",
      "[340/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.83138, val loss: 17.09250, in 0.005s\n",
      "[341/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.81878, val loss: 17.08904, in 0.008s\n",
      "[342/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.80770, val loss: 17.08753, in 0.006s\n",
      "[343/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.79679, val loss: 17.08603, in 0.015s\n",
      "[344/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.78768, val loss: 17.08465, in 0.006s\n",
      "[345/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77707, val loss: 17.06961, in 0.009s\n",
      "[346/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.76590, val loss: 17.08357, in 0.008s\n",
      "[347/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.75566, val loss: 17.10046, in 0.006s\n",
      "[348/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.75268, val loss: 17.09862, in 0.015s\n",
      "[349/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.75020, val loss: 17.09548, in 0.019s\n",
      "[350/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.74207, val loss: 17.09288, in 0.029s\n",
      "[351/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.73986, val loss: 17.08951, in 0.007s\n",
      "[352/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.72981, val loss: 17.10635, in 0.008s\n",
      "[353/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.72566, val loss: 17.09792, in 0.012s\n",
      "[354/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.72324, val loss: 17.09802, in 0.008s\n",
      "[355/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.71920, val loss: 17.08954, in 0.007s\n",
      "Fit 355 trees in 4.167 s, (11005 total leaves)\n",
      "Time spent computing histograms: 0.906s\n",
      "Time spent finding best splits:  0.463s\n",
      "Time spent applying splits:      0.632s\n",
      "Time spent predicting:           0.219s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of 100 | elapsed:   11.1s remaining:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of 100 | elapsed:   11.1s remaining:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of 100 | elapsed:   11.2s remaining:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of 100 | elapsed:   11.2s remaining:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of 100 | elapsed:   11.2s remaining:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of 100 | elapsed:   11.3s remaining:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of 100 | elapsed:   11.3s remaining:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of 100 | elapsed:   11.3s remaining:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of 100 | elapsed:   11.3s remaining:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of 100 | elapsed:   11.3s remaining:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of 100 | elapsed:   11.4s remaining:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of 100 | elapsed:   11.4s remaining:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of 100 | elapsed:   11.4s remaining:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of 100 | elapsed:   11.5s remaining:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of 100 | elapsed:   11.5s remaining:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of 100 | elapsed:   11.5s remaining:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of 100 | elapsed:   11.6s remaining:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of 100 | elapsed:   11.6s remaining:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of 100 | elapsed:   11.6s remaining:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of 100 | elapsed:   11.6s remaining:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of 100 | elapsed:   11.7s remaining:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of 100 | elapsed:   11.8s remaining:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of 100 | elapsed:   11.8s remaining:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of 100 | elapsed:   11.8s remaining:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of 100 | elapsed:   11.8s remaining:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  63 out of 100 | elapsed:   11.9s remaining:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of 100 | elapsed:   12.1s remaining:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  65 out of 100 | elapsed:   15.0s remaining:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of 100 | elapsed:   15.8s remaining:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  67 out of 100 | elapsed:   15.8s remaining:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of 100 | elapsed:   15.9s remaining:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of 100 | elapsed:   16.0s remaining:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of 100 | elapsed:   16.0s remaining:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  71 out of 100 | elapsed:   16.2s remaining:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of 100 | elapsed:   16.3s remaining:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  73 out of 100 | elapsed:   16.3s remaining:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of 100 | elapsed:   16.3s remaining:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of 100 | elapsed:   16.3s remaining:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of 100 | elapsed:   16.4s remaining:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  77 out of 100 | elapsed:   16.4s remaining:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  78 out of 100 | elapsed:   16.4s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  79 out of 100 | elapsed:   16.5s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of 100 | elapsed:   16.5s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of 100 | elapsed:   16.6s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  82 out of 100 | elapsed:   16.6s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  83 out of 100 | elapsed:   16.6s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of 100 | elapsed:   16.6s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of 100 | elapsed:   16.6s remaining:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  86 out of 100 | elapsed:   16.6s remaining:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  87 out of 100 | elapsed:   16.6s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  88 out of 100 | elapsed:   16.6s remaining:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  89 out of 100 | elapsed:   16.6s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of 100 | elapsed:   16.7s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  91 out of 100 | elapsed:   16.7s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  92 out of 100 | elapsed:   16.8s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:   16.8s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  94 out of 100 | elapsed:   16.9s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  95 out of 100 | elapsed:   16.9s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of 100 | elapsed:   16.9s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  97 out of 100 | elapsed:   18.5s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  98 out of 100 | elapsed:   19.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   19.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   19.3s finished\n",
      "Binning 0.001 GB of training data: 0.027 s\n",
      "Binning 0.000 GB of validation data: 0.001 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/10000] 1 tree, 31 leaves, max depth = 10, train loss: 42.71203, val loss: 45.43754, in 0.006s\n",
      "[2/10000] 1 tree, 31 leaves, max depth = 7, train loss: 42.62072, val loss: 45.35016, in 0.005s\n",
      "[3/10000] 1 tree, 31 leaves, max depth = 7, train loss: 42.52949, val loss: 45.26334, in 0.006s\n",
      "[4/10000] 1 tree, 31 leaves, max depth = 7, train loss: 42.44000, val loss: 45.17770, in 0.009s\n",
      "[5/10000] 1 tree, 31 leaves, max depth = 7, train loss: 42.35060, val loss: 45.09246, in 0.006s\n",
      "[6/10000] 1 tree, 31 leaves, max depth = 7, train loss: 42.26331, val loss: 45.01021, in 0.006s\n",
      "[7/10000] 1 tree, 31 leaves, max depth = 8, train loss: 42.17179, val loss: 44.93175, in 0.013s\n",
      "[8/10000] 1 tree, 31 leaves, max depth = 8, train loss: 42.08116, val loss: 44.85414, in 0.006s\n",
      "[9/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.99146, val loss: 44.77716, in 0.007s\n",
      "[10/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.90263, val loss: 44.70102, in 0.020s\n",
      "[11/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.81471, val loss: 44.62557, in 0.013s\n",
      "[12/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.73110, val loss: 44.55388, in 0.007s\n",
      "[13/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.63572, val loss: 44.47707, in 0.012s\n",
      "[14/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.54128, val loss: 44.40102, in 0.014s\n",
      "[15/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.44780, val loss: 44.32573, in 0.006s\n",
      "[16/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.35651, val loss: 44.25120, in 0.007s\n",
      "[17/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.25911, val loss: 44.18051, in 0.005s\n",
      "[18/10000] 1 tree, 31 leaves, max depth = 9, train loss: 41.16258, val loss: 44.10963, in 0.018s\n",
      "[19/10000] 1 tree, 31 leaves, max depth = 9, train loss: 41.06704, val loss: 44.03945, in 0.005s\n",
      "[20/10000] 1 tree, 31 leaves, max depth = 9, train loss: 40.97324, val loss: 43.97288, in 0.005s\n",
      "[21/10000] 1 tree, 31 leaves, max depth = 9, train loss: 40.87255, val loss: 43.90050, in 0.006s\n",
      "[22/10000] 1 tree, 31 leaves, max depth = 9, train loss: 40.77298, val loss: 43.82877, in 0.006s\n",
      "[23/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.67495, val loss: 43.75863, in 0.020s\n",
      "[24/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.57197, val loss: 43.67968, in 0.005s\n",
      "[25/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.47004, val loss: 43.60151, in 0.005s\n",
      "[26/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.36934, val loss: 43.52413, in 0.008s\n",
      "[27/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.27006, val loss: 43.44751, in 0.013s\n",
      "[28/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.17615, val loss: 43.37946, in 0.014s\n",
      "[29/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.08346, val loss: 43.31209, in 0.006s\n",
      "[30/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.98048, val loss: 43.22751, in 0.007s\n",
      "[31/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.87854, val loss: 43.14378, in 0.016s\n",
      "[32/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.77849, val loss: 43.06089, in 0.008s\n",
      "[33/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.67212, val loss: 42.96857, in 0.005s\n",
      "[34/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.56714, val loss: 42.87731, in 0.007s\n",
      "[35/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.45787, val loss: 42.78665, in 0.007s\n",
      "[36/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.34980, val loss: 42.69691, in 0.005s\n",
      "[37/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.25113, val loss: 42.61822, in 0.005s\n",
      "[38/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.14678, val loss: 42.53017, in 0.017s\n",
      "[39/10000] 1 tree, 31 leaves, max depth = 9, train loss: 39.04335, val loss: 42.44217, in 0.005s\n",
      "[40/10000] 1 tree, 31 leaves, max depth = 9, train loss: 38.94163, val loss: 42.35568, in 0.009s\n",
      "[41/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.83943, val loss: 42.26763, in 0.005s\n",
      "[42/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.73172, val loss: 42.17465, in 0.005s\n",
      "[43/10000] 1 tree, 31 leaves, max depth = 11, train loss: 38.62729, val loss: 42.08180, in 0.014s\n",
      "[44/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.52309, val loss: 41.99055, in 0.005s\n",
      "[45/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.42191, val loss: 41.90672, in 0.005s\n",
      "[46/10000] 1 tree, 31 leaves, max depth = 7, train loss: 38.31284, val loss: 41.82646, in 0.008s\n",
      "[47/10000] 1 tree, 31 leaves, max depth = 7, train loss: 38.20557, val loss: 41.74700, in 0.006s\n",
      "[48/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.10062, val loss: 41.66732, in 0.079s\n",
      "[49/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.98943, val loss: 41.58703, in 0.007s\n",
      "[50/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.88575, val loss: 41.51049, in 0.009s\n",
      "[51/10000] 1 tree, 31 leaves, max depth = 10, train loss: 37.78236, val loss: 41.43451, in 0.015s\n",
      "[52/10000] 1 tree, 31 leaves, max depth = 7, train loss: 37.67550, val loss: 41.36058, in 0.006s\n",
      "[53/10000] 1 tree, 31 leaves, max depth = 10, train loss: 37.56213, val loss: 41.27179, in 0.005s\n",
      "[54/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.45385, val loss: 41.18979, in 0.005s\n",
      "[55/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.34717, val loss: 41.10680, in 0.009s\n",
      "[56/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.23447, val loss: 41.01664, in 0.006s\n",
      "[57/10000] 1 tree, 31 leaves, max depth = 9, train loss: 37.12365, val loss: 40.93638, in 0.005s\n",
      "[58/10000] 1 tree, 31 leaves, max depth = 9, train loss: 37.01459, val loss: 40.85679, in 0.014s\n",
      "[59/10000] 1 tree, 31 leaves, max depth = 9, train loss: 36.91760, val loss: 40.78731, in 0.005s\n",
      "[60/10000] 1 tree, 31 leaves, max depth = 9, train loss: 36.81350, val loss: 40.71371, in 0.007s\n",
      "[61/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.69884, val loss: 40.63326, in 0.007s\n",
      "[62/10000] 1 tree, 31 leaves, max depth = 9, train loss: 36.58136, val loss: 40.55131, in 0.005s\n",
      "[63/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.47541, val loss: 40.47175, in 0.007s\n",
      "[64/10000] 1 tree, 31 leaves, max depth = 9, train loss: 36.37173, val loss: 40.39388, in 0.016s\n",
      "[65/10000] 1 tree, 31 leaves, max depth = 9, train loss: 36.26875, val loss: 40.30567, in 0.005s\n",
      "[66/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.15923, val loss: 40.22523, in 0.051s\n",
      "[67/10000] 1 tree, 31 leaves, max depth = 9, train loss: 36.04840, val loss: 40.14404, in 0.009s\n",
      "[68/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.93115, val loss: 40.04552, in 0.006s\n",
      "[69/10000] 1 tree, 31 leaves, max depth = 9, train loss: 35.81455, val loss: 39.95668, in 0.005s\n",
      "[70/10000] 1 tree, 31 leaves, max depth = 9, train loss: 35.69311, val loss: 39.85572, in 0.015s\n",
      "[71/10000] 1 tree, 31 leaves, max depth = 9, train loss: 35.57359, val loss: 39.75638, in 0.005s\n",
      "[72/10000] 1 tree, 31 leaves, max depth = 9, train loss: 35.46473, val loss: 39.66739, in 0.008s\n",
      "[73/10000] 1 tree, 31 leaves, max depth = 9, train loss: 35.34871, val loss: 39.56962, in 0.005s\n",
      "[74/10000] 1 tree, 31 leaves, max depth = 9, train loss: 35.23310, val loss: 39.46811, in 0.006s\n",
      "[75/10000] 1 tree, 31 leaves, max depth = 9, train loss: 35.12654, val loss: 39.37283, in 0.005s\n",
      "[76/10000] 1 tree, 31 leaves, max depth = 9, train loss: 35.00983, val loss: 39.28217, in 0.005s\n",
      "[77/10000] 1 tree, 31 leaves, max depth = 9, train loss: 34.89275, val loss: 39.19213, in 0.005s\n",
      "[78/10000] 1 tree, 31 leaves, max depth = 9, train loss: 34.78012, val loss: 39.08234, in 0.016s\n",
      "[79/10000] 1 tree, 31 leaves, max depth = 9, train loss: 34.67022, val loss: 38.97620, in 0.005s\n",
      "[80/10000] 1 tree, 31 leaves, max depth = 9, train loss: 34.56358, val loss: 38.87052, in 0.005s\n",
      "[81/10000] 1 tree, 31 leaves, max depth = 9, train loss: 34.45289, val loss: 38.77503, in 0.013s\n",
      "[82/10000] 1 tree, 31 leaves, max depth = 9, train loss: 34.34309, val loss: 38.68132, in 0.005s\n",
      "[83/10000] 1 tree, 31 leaves, max depth = 9, train loss: 34.23705, val loss: 38.59560, in 0.015s\n",
      "[84/10000] 1 tree, 31 leaves, max depth = 9, train loss: 34.13057, val loss: 38.51016, in 0.005s\n",
      "[85/10000] 1 tree, 31 leaves, max depth = 9, train loss: 34.02028, val loss: 38.41620, in 0.008s\n",
      "[86/10000] 1 tree, 31 leaves, max depth = 9, train loss: 33.91081, val loss: 38.32071, in 0.006s\n",
      "[87/10000] 1 tree, 31 leaves, max depth = 9, train loss: 33.80151, val loss: 38.22239, in 0.006s\n",
      "[88/10000] 1 tree, 31 leaves, max depth = 9, train loss: 33.69055, val loss: 38.10795, in 0.015s\n",
      "[89/10000] 1 tree, 31 leaves, max depth = 11, train loss: 33.58119, val loss: 37.99440, in 0.014s\n",
      "[90/10000] 1 tree, 31 leaves, max depth = 10, train loss: 33.47281, val loss: 37.88215, in 0.005s\n",
      "[91/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.36340, val loss: 37.76965, in 0.005s\n",
      "[92/10000] 1 tree, 31 leaves, max depth = 10, train loss: 33.25180, val loss: 37.64774, in 0.007s\n",
      "[93/10000] 1 tree, 31 leaves, max depth = 10, train loss: 33.15179, val loss: 37.55774, in 0.005s\n",
      "[94/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.04754, val loss: 37.45599, in 0.005s\n",
      "[95/10000] 1 tree, 31 leaves, max depth = 9, train loss: 32.92606, val loss: 37.34773, in 0.016s\n",
      "[96/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.81361, val loss: 37.24861, in 0.005s\n",
      "[97/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.69878, val loss: 37.14285, in 0.034s\n",
      "[98/10000] 1 tree, 31 leaves, max depth = 9, train loss: 32.58161, val loss: 37.03544, in 0.005s\n",
      "[99/10000] 1 tree, 31 leaves, max depth = 10, train loss: 32.47032, val loss: 36.92739, in 0.010s\n",
      "[100/10000] 1 tree, 31 leaves, max depth = 9, train loss: 32.36249, val loss: 36.82597, in 0.006s\n",
      "[101/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.23077, val loss: 36.69049, in 0.006s\n",
      "[102/10000] 1 tree, 31 leaves, max depth = 9, train loss: 32.10322, val loss: 36.55909, in 0.008s\n",
      "[103/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.99190, val loss: 36.44317, in 0.018s\n",
      "[104/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.88018, val loss: 36.32568, in 0.006s\n",
      "[105/10000] 1 tree, 31 leaves, max depth = 7, train loss: 31.75183, val loss: 36.19252, in 0.005s\n",
      "[106/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.63803, val loss: 36.06511, in 0.008s\n",
      "[107/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.52364, val loss: 35.95854, in 0.006s\n",
      "[108/10000] 1 tree, 31 leaves, max depth = 7, train loss: 31.41069, val loss: 35.84661, in 0.005s\n",
      "[109/10000] 1 tree, 31 leaves, max depth = 7, train loss: 31.30292, val loss: 35.72295, in 0.005s\n",
      "[110/10000] 1 tree, 31 leaves, max depth = 12, train loss: 31.21427, val loss: 35.62899, in 0.015s\n",
      "[111/10000] 1 tree, 31 leaves, max depth = 10, train loss: 31.10494, val loss: 35.51991, in 0.016s\n",
      "[112/10000] 1 tree, 31 leaves, max depth = 11, train loss: 30.99661, val loss: 35.41187, in 0.009s\n",
      "[113/10000] 1 tree, 31 leaves, max depth = 9, train loss: 30.89537, val loss: 35.30184, in 0.005s\n",
      "[114/10000] 1 tree, 31 leaves, max depth = 12, train loss: 30.77823, val loss: 35.18761, in 0.005s\n",
      "[115/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.65920, val loss: 35.07269, in 0.016s\n",
      "[116/10000] 1 tree, 31 leaves, max depth = 12, train loss: 30.56787, val loss: 34.97258, in 0.005s\n",
      "[117/10000] 1 tree, 31 leaves, max depth = 10, train loss: 30.45695, val loss: 34.86433, in 0.006s\n",
      "[118/10000] 1 tree, 31 leaves, max depth = 10, train loss: 30.34761, val loss: 34.75500, in 0.008s\n",
      "[119/10000] 1 tree, 31 leaves, max depth = 10, train loss: 30.23734, val loss: 34.63291, in 0.005s\n",
      "[120/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.13188, val loss: 34.51489, in 0.015s\n",
      "[121/10000] 1 tree, 31 leaves, max depth = 9, train loss: 30.02820, val loss: 34.39987, in 0.005s\n",
      "[122/10000] 1 tree, 31 leaves, max depth = 7, train loss: 29.93067, val loss: 34.30709, in 0.005s\n",
      "[123/10000] 1 tree, 31 leaves, max depth = 7, train loss: 29.83419, val loss: 34.24098, in 0.009s\n",
      "[124/10000] 1 tree, 31 leaves, max depth = 9, train loss: 29.73959, val loss: 34.17512, in 0.006s\n",
      "[125/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.64698, val loss: 34.11176, in 0.016s\n",
      "[126/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.54588, val loss: 33.99915, in 0.005s\n",
      "[127/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.44783, val loss: 33.88650, in 0.007s\n",
      "[128/10000] 1 tree, 31 leaves, max depth = 9, train loss: 29.35467, val loss: 33.76925, in 0.012s\n",
      "[129/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.28419, val loss: 33.70975, in 0.008s\n",
      "[130/10000] 1 tree, 31 leaves, max depth = 9, train loss: 29.21238, val loss: 33.65487, in 0.005s\n",
      "[131/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.12035, val loss: 33.48458, in 0.005s\n",
      "[132/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.03986, val loss: 33.40198, in 0.015s\n",
      "[133/10000] 1 tree, 31 leaves, max depth = 7, train loss: 28.95910, val loss: 33.32934, in 0.005s\n",
      "[134/10000] 1 tree, 31 leaves, max depth = 10, train loss: 28.87865, val loss: 33.24239, in 0.008s\n",
      "[135/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.80051, val loss: 33.15613, in 0.006s\n",
      "[136/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.72918, val loss: 33.08166, in 0.005s\n",
      "[137/10000] 1 tree, 31 leaves, max depth = 7, train loss: 28.65271, val loss: 33.01498, in 0.005s\n",
      "[138/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.58863, val loss: 32.95562, in 0.015s\n",
      "[139/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.51373, val loss: 32.85565, in 0.005s\n",
      "[140/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.43561, val loss: 32.77153, in 0.005s\n",
      "[141/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.36032, val loss: 32.67563, in 0.006s\n",
      "[142/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.28721, val loss: 32.58208, in 0.009s\n",
      "[143/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.21301, val loss: 32.48828, in 0.007s\n",
      "[144/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.13824, val loss: 32.39610, in 0.015s\n",
      "[145/10000] 1 tree, 31 leaves, max depth = 10, train loss: 28.06518, val loss: 32.26299, in 0.006s\n",
      "[146/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.99644, val loss: 32.13232, in 0.008s\n",
      "[147/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.92326, val loss: 31.98318, in 0.015s\n",
      "[148/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.83733, val loss: 31.84032, in 0.008s\n",
      "[149/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.75142, val loss: 31.69330, in 0.005s\n",
      "[150/10000] 1 tree, 31 leaves, max depth = 10, train loss: 27.66938, val loss: 31.55138, in 0.005s\n",
      "[151/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.58288, val loss: 31.39596, in 0.005s\n",
      "[152/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.49757, val loss: 31.24174, in 0.005s\n",
      "[153/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.41279, val loss: 31.08330, in 0.016s\n",
      "[154/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.33003, val loss: 30.92645, in 0.032s\n",
      "[155/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.26507, val loss: 30.77252, in 0.005s\n",
      "[156/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.18756, val loss: 30.61394, in 0.005s\n",
      "[157/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.12278, val loss: 30.52294, in 0.015s\n",
      "[158/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.07068, val loss: 30.44147, in 0.007s\n",
      "[159/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.01233, val loss: 30.31370, in 0.009s\n",
      "[160/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.96004, val loss: 30.18847, in 0.018s\n",
      "[161/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.90103, val loss: 30.07405, in 0.005s\n",
      "[162/10000] 1 tree, 31 leaves, max depth = 10, train loss: 26.84480, val loss: 29.98276, in 0.005s\n",
      "[163/10000] 1 tree, 31 leaves, max depth = 10, train loss: 26.78887, val loss: 29.85089, in 0.008s\n",
      "[164/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.73510, val loss: 29.72128, in 0.005s\n",
      "[165/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.67868, val loss: 29.63836, in 0.007s\n",
      "[166/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.61734, val loss: 29.54361, in 0.007s\n",
      "[167/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.55875, val loss: 29.44483, in 0.005s\n",
      "[168/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.49997, val loss: 29.33915, in 0.017s\n",
      "[169/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.45302, val loss: 29.28915, in 0.014s\n",
      "[170/10000] 1 tree, 31 leaves, max depth = 11, train loss: 26.39560, val loss: 29.19295, in 0.007s\n",
      "[171/10000] 1 tree, 31 leaves, max depth = 10, train loss: 26.33936, val loss: 29.09848, in 0.006s\n",
      "[172/10000] 1 tree, 31 leaves, max depth = 10, train loss: 26.27319, val loss: 28.98454, in 0.017s\n",
      "[173/10000] 1 tree, 31 leaves, max depth = 11, train loss: 26.20109, val loss: 28.87305, in 0.006s\n",
      "[174/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.17265, val loss: 28.83142, in 0.007s\n",
      "[175/10000] 1 tree, 31 leaves, max depth = 11, train loss: 26.12768, val loss: 28.66027, in 0.005s\n",
      "[176/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.08069, val loss: 28.54670, in 0.017s\n",
      "[177/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.03485, val loss: 28.43440, in 0.007s\n",
      "[178/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.00392, val loss: 28.40398, in 0.005s\n",
      "[179/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.97356, val loss: 28.37423, in 0.008s\n",
      "[180/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.92894, val loss: 28.29425, in 0.005s\n",
      "[181/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.88573, val loss: 28.21506, in 0.015s\n",
      "[182/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.84881, val loss: 28.08431, in 0.005s\n",
      "[183/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.80409, val loss: 27.93108, in 0.005s\n",
      "[184/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.76970, val loss: 27.81437, in 0.010s\n",
      "[185/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.73655, val loss: 27.69883, in 0.012s\n",
      "[186/10000] 1 tree, 31 leaves, max depth = 13, train loss: 25.70872, val loss: 27.65811, in 0.015s\n",
      "[187/10000] 1 tree, 31 leaves, max depth = 11, train loss: 25.69572, val loss: 27.64045, in 0.005s\n",
      "[188/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.65168, val loss: 27.54207, in 0.008s\n",
      "[189/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.62043, val loss: 27.42852, in 0.007s\n",
      "[190/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.60268, val loss: 27.40370, in 0.009s\n",
      "[191/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.57272, val loss: 27.34923, in 0.021s\n",
      "[192/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.53123, val loss: 27.25996, in 0.006s\n",
      "[193/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.51118, val loss: 27.24780, in 0.006s\n",
      "[194/10000] 1 tree, 31 leaves, max depth = 11, train loss: 25.47764, val loss: 27.18054, in 0.016s\n",
      "[195/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.43732, val loss: 27.09134, in 0.071s\n",
      "[196/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.41748, val loss: 27.07857, in 0.008s\n",
      "[197/10000] 1 tree, 31 leaves, max depth = 11, train loss: 25.38464, val loss: 26.93577, in 0.006s\n",
      "[198/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.34254, val loss: 26.78836, in 0.006s\n",
      "[199/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.30144, val loss: 26.64291, in 0.044s\n",
      "[200/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.25454, val loss: 26.57040, in 0.010s\n",
      "[201/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.22157, val loss: 26.50357, in 0.017s\n",
      "[202/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.18554, val loss: 26.35957, in 0.005s\n",
      "[203/10000] 1 tree, 31 leaves, max depth = 12, train loss: 25.15795, val loss: 26.21956, in 0.009s\n",
      "[204/10000] 1 tree, 31 leaves, max depth = 11, train loss: 25.10500, val loss: 26.11567, in 0.005s\n",
      "[205/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.08881, val loss: 26.09271, in 0.024s\n",
      "[206/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.05426, val loss: 26.04343, in 0.005s\n",
      "[207/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.03142, val loss: 26.00722, in 0.008s\n",
      "[208/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.99541, val loss: 25.94586, in 0.006s\n",
      "[209/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.96070, val loss: 25.88489, in 0.006s\n",
      "[210/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.93898, val loss: 25.83661, in 0.033s\n",
      "[211/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.90436, val loss: 25.77641, in 0.005s\n",
      "[212/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.86597, val loss: 25.69881, in 0.006s\n",
      "[213/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.82954, val loss: 25.56253, in 0.005s\n",
      "[214/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.79650, val loss: 25.50475, in 0.005s\n",
      "[215/10000] 1 tree, 31 leaves, max depth = 13, train loss: 24.74528, val loss: 25.40419, in 0.061s\n",
      "[216/10000] 1 tree, 31 leaves, max depth = 11, train loss: 24.69731, val loss: 25.30521, in 0.005s\n",
      "[217/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.68210, val loss: 25.29036, in 0.008s\n",
      "[218/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.66895, val loss: 25.28119, in 0.006s\n",
      "[219/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.65822, val loss: 25.26350, in 0.006s\n",
      "[220/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.63556, val loss: 25.20657, in 0.008s\n",
      "[221/10000] 1 tree, 31 leaves, max depth = 13, train loss: 24.62168, val loss: 25.19735, in 0.023s\n",
      "[222/10000] 1 tree, 31 leaves, max depth = 12, train loss: 24.58281, val loss: 25.08411, in 0.005s\n",
      "[223/10000] 1 tree, 31 leaves, max depth = 7, train loss: 24.57184, val loss: 25.07054, in 0.005s\n",
      "[224/10000] 1 tree, 31 leaves, max depth = 12, train loss: 24.56033, val loss: 25.06539, in 0.006s\n",
      "[225/10000] 1 tree, 31 leaves, max depth = 12, train loss: 24.54441, val loss: 25.04242, in 0.012s\n",
      "[226/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.51626, val loss: 24.97459, in 0.027s\n",
      "[227/10000] 1 tree, 31 leaves, max depth = 11, train loss: 24.49972, val loss: 24.94081, in 0.008s\n",
      "[228/10000] 1 tree, 31 leaves, max depth = 13, train loss: 24.48639, val loss: 24.93019, in 0.006s\n",
      "[229/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.43791, val loss: 24.82835, in 0.005s\n",
      "[230/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.41822, val loss: 24.79758, in 0.042s\n",
      "[231/10000] 1 tree, 31 leaves, max depth = 11, train loss: 24.40136, val loss: 24.76738, in 0.005s\n",
      "[232/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.37396, val loss: 24.73111, in 0.005s\n",
      "[233/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.34462, val loss: 24.68481, in 0.015s\n",
      "[234/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.31511, val loss: 24.62375, in 0.005s\n",
      "[235/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.28542, val loss: 24.57641, in 0.016s\n",
      "[236/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.26211, val loss: 24.52330, in 0.005s\n",
      "[237/10000] 1 tree, 31 leaves, max depth = 7, train loss: 24.25009, val loss: 24.50515, in 0.017s\n",
      "[238/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.22711, val loss: 24.45967, in 0.008s\n",
      "[239/10000] 1 tree, 31 leaves, max depth = 11, train loss: 24.20076, val loss: 24.41720, in 0.061s\n",
      "[240/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.17916, val loss: 24.39337, in 0.089s\n",
      "[241/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.15305, val loss: 24.34814, in 0.007s\n",
      "[242/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.12764, val loss: 24.30342, in 0.011s\n",
      "[243/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.10201, val loss: 24.25338, in 0.020s\n",
      "[244/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.08428, val loss: 24.21350, in 0.006s\n",
      "[245/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.06080, val loss: 24.18869, in 0.005s\n",
      "[246/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.03617, val loss: 24.16397, in 0.009s\n",
      "[247/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.01653, val loss: 24.12100, in 0.005s\n",
      "[248/10000] 1 tree, 31 leaves, max depth = 7, train loss: 23.99049, val loss: 24.07446, in 0.023s\n",
      "[249/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.97390, val loss: 24.03651, in 0.006s\n",
      "[250/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.95752, val loss: 23.99909, in 0.010s\n",
      "[251/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.94467, val loss: 23.98529, in 0.005s\n",
      "[252/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.93168, val loss: 23.96178, in 0.059s\n",
      "[253/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.91046, val loss: 23.90589, in 0.016s\n",
      "[254/10000] 1 tree, 31 leaves, max depth = 7, train loss: 23.88343, val loss: 23.85140, in 0.018s\n",
      "[255/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.85886, val loss: 23.80859, in 0.005s\n",
      "[256/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.83383, val loss: 23.75306, in 0.005s\n",
      "[257/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.82246, val loss: 23.74913, in 0.005s\n",
      "[258/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.81135, val loss: 23.74526, in 0.005s\n",
      "[259/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.78653, val loss: 23.68980, in 0.008s\n",
      "[260/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.74504, val loss: 23.59916, in 0.005s\n",
      "[261/10000] 1 tree, 31 leaves, max depth = 7, train loss: 23.72080, val loss: 23.54700, in 0.006s\n",
      "[262/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.68138, val loss: 23.46266, in 0.015s\n",
      "[263/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.64288, val loss: 23.37888, in 0.005s\n",
      "[264/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.63214, val loss: 23.37329, in 0.005s\n",
      "[265/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.58775, val loss: 23.28894, in 0.008s\n",
      "[266/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.54389, val loss: 23.20544, in 0.005s\n",
      "[267/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.50059, val loss: 23.12278, in 0.005s\n",
      "[268/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.48401, val loss: 23.11105, in 0.006s\n",
      "[269/10000] 1 tree, 31 leaves, max depth = 7, train loss: 23.46765, val loss: 23.09951, in 0.035s\n",
      "[270/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.45005, val loss: 23.08672, in 0.006s\n",
      "[271/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.43363, val loss: 23.07625, in 0.018s\n",
      "[272/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.41789, val loss: 23.06558, in 0.067s\n",
      "[273/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.40000, val loss: 23.05369, in 0.007s\n",
      "[274/10000] 1 tree, 31 leaves, max depth = 7, train loss: 23.38364, val loss: 23.04128, in 0.006s\n",
      "[275/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.36812, val loss: 23.03130, in 0.005s\n",
      "[276/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.35304, val loss: 23.02122, in 0.017s\n",
      "[277/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.32602, val loss: 22.93913, in 0.009s\n",
      "[278/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.30254, val loss: 22.89036, in 0.005s\n",
      "[279/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.29068, val loss: 22.85824, in 0.017s\n",
      "[280/10000] 1 tree, 31 leaves, max depth = 12, train loss: 23.26895, val loss: 22.84630, in 0.018s\n",
      "[281/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.25276, val loss: 22.83936, in 0.008s\n",
      "[282/10000] 1 tree, 31 leaves, max depth = 12, train loss: 23.23280, val loss: 22.83018, in 0.006s\n",
      "[283/10000] 1 tree, 31 leaves, max depth = 12, train loss: 23.21904, val loss: 22.82201, in 0.006s\n",
      "[284/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.20654, val loss: 22.81581, in 0.008s\n",
      "[285/10000] 1 tree, 31 leaves, max depth = 7, train loss: 23.18543, val loss: 22.76926, in 0.015s\n",
      "[286/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.17433, val loss: 22.74028, in 0.008s\n",
      "[287/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.14733, val loss: 22.67426, in 0.005s\n",
      "[288/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.14199, val loss: 22.66643, in 0.006s\n",
      "[289/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.13735, val loss: 22.65818, in 0.005s\n",
      "[290/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.11654, val loss: 22.60169, in 0.005s\n",
      "[291/10000] 1 tree, 31 leaves, max depth = 14, train loss: 23.10308, val loss: 22.59678, in 0.005s\n",
      "[292/10000] 1 tree, 31 leaves, max depth = 13, train loss: 23.08811, val loss: 22.59427, in 0.016s\n",
      "[293/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.07711, val loss: 22.57673, in 0.005s\n",
      "[294/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.06628, val loss: 22.55936, in 0.005s\n",
      "[295/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.05573, val loss: 22.55708, in 0.008s\n",
      "[296/10000] 1 tree, 31 leaves, max depth = 14, train loss: 23.04386, val loss: 22.55314, in 0.096s\n",
      "[297/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.03359, val loss: 22.55086, in 0.007s\n",
      "[298/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.02074, val loss: 22.54806, in 0.006s\n",
      "[299/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.00771, val loss: 22.54545, in 0.019s\n",
      "[300/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.99342, val loss: 22.53425, in 0.010s\n",
      "[301/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.98176, val loss: 22.53145, in 0.005s\n",
      "[302/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.97012, val loss: 22.52897, in 0.009s\n",
      "[303/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.95844, val loss: 22.52558, in 0.036s\n",
      "[304/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.93487, val loss: 22.50545, in 0.009s\n",
      "[305/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.91187, val loss: 22.48607, in 0.006s\n",
      "[306/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.88923, val loss: 22.46646, in 0.018s\n",
      "[307/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.86680, val loss: 22.44692, in 0.005s\n",
      "[308/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.84489, val loss: 22.42518, in 0.033s\n",
      "[309/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.82353, val loss: 22.38863, in 0.005s\n",
      "[310/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.79557, val loss: 22.31451, in 0.050s\n",
      "[311/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.77940, val loss: 22.26440, in 0.017s\n",
      "[312/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.76292, val loss: 22.25721, in 0.006s\n",
      "[313/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.75204, val loss: 22.24034, in 0.006s\n",
      "[314/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.74613, val loss: 22.23710, in 0.008s\n",
      "[315/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.74045, val loss: 22.23375, in 0.034s\n",
      "[316/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.70763, val loss: 22.15198, in 0.010s\n",
      "[317/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.68180, val loss: 22.13476, in 0.006s\n",
      "[318/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.65724, val loss: 22.11771, in 0.032s\n",
      "[319/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.62962, val loss: 22.04554, in 0.006s\n",
      "[320/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.60238, val loss: 21.97532, in 0.006s\n",
      "[321/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.57606, val loss: 21.89923, in 0.005s\n",
      "[322/10000] 1 tree, 31 leaves, max depth = 13, train loss: 22.56247, val loss: 21.89682, in 0.005s\n",
      "[323/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.55733, val loss: 21.88524, in 0.005s\n",
      "[324/10000] 1 tree, 31 leaves, max depth = 13, train loss: 22.55271, val loss: 21.88530, in 0.041s\n",
      "[325/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.55077, val loss: 21.88447, in 0.068s\n",
      "[326/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.52938, val loss: 21.87559, in 0.011s\n",
      "[327/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.52319, val loss: 21.87484, in 0.009s\n",
      "[328/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.51781, val loss: 21.87351, in 0.006s\n",
      "[329/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.49744, val loss: 21.86583, in 0.063s\n",
      "[330/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.48932, val loss: 21.86441, in 0.007s\n",
      "[331/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.48368, val loss: 21.86308, in 0.006s\n",
      "[332/10000] 1 tree, 31 leaves, max depth = 14, train loss: 22.48212, val loss: 21.86149, in 0.007s\n",
      "[333/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.46191, val loss: 21.85499, in 0.042s\n",
      "[334/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.44039, val loss: 21.83921, in 0.037s\n",
      "[335/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.42824, val loss: 21.82461, in 0.007s\n",
      "[336/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.40730, val loss: 21.81096, in 0.006s\n",
      "[337/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.38706, val loss: 21.80259, in 0.024s\n",
      "[338/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.36687, val loss: 21.79618, in 0.011s\n",
      "[339/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.36123, val loss: 21.79545, in 0.006s\n",
      "[340/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.35548, val loss: 21.79472, in 0.009s\n",
      "[341/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.34848, val loss: 21.75459, in 0.005s\n",
      "[342/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.33851, val loss: 21.74120, in 0.021s\n",
      "[343/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.30653, val loss: 21.65521, in 0.005s\n",
      "[344/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.29087, val loss: 21.65289, in 0.010s\n",
      "[345/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.27532, val loss: 21.65099, in 0.022s\n",
      "[346/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.25682, val loss: 21.63645, in 0.005s\n",
      "[347/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.23953, val loss: 21.62206, in 0.005s\n",
      "[348/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.23017, val loss: 21.61677, in 0.007s\n",
      "[349/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.21464, val loss: 21.60195, in 0.008s\n",
      "[350/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.20103, val loss: 21.59349, in 0.005s\n",
      "[351/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.18798, val loss: 21.58514, in 0.017s\n",
      "[352/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.17584, val loss: 21.57689, in 0.005s\n",
      "[353/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.16394, val loss: 21.56873, in 0.011s\n",
      "[354/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.15515, val loss: 21.56085, in 0.005s\n",
      "[355/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.15468, val loss: 21.56038, in 0.005s\n",
      "[356/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.15422, val loss: 21.56001, in 0.018s\n",
      "[357/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.15352, val loss: 21.55870, in 0.005s\n",
      "[358/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.15262, val loss: 21.55722, in 0.006s\n",
      "[359/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.15203, val loss: 21.55682, in 0.010s\n",
      "[360/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.13707, val loss: 21.52080, in 0.006s\n",
      "[361/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.13582, val loss: 21.51964, in 0.021s\n",
      "[362/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.11333, val loss: 21.47843, in 0.014s\n",
      "[363/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.09171, val loss: 21.43764, in 0.006s\n",
      "[364/10000] 1 tree, 31 leaves, max depth = 7, train loss: 22.08454, val loss: 21.41815, in 0.005s\n",
      "[365/10000] 1 tree, 31 leaves, max depth = 7, train loss: 22.08414, val loss: 21.41794, in 0.005s\n",
      "[366/10000] 1 tree, 31 leaves, max depth = 7, train loss: 22.08374, val loss: 21.41773, in 0.005s\n",
      "[367/10000] 1 tree, 31 leaves, max depth = 7, train loss: 22.08333, val loss: 21.41747, in 0.015s\n",
      "[368/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.08129, val loss: 21.41717, in 0.005s\n",
      "[369/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.06692, val loss: 21.42277, in 0.006s\n",
      "[370/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.04854, val loss: 21.37204, in 0.015s\n",
      "[371/10000] 1 tree, 31 leaves, max depth = 7, train loss: 22.04682, val loss: 21.36849, in 0.073s\n",
      "[372/10000] 1 tree, 31 leaves, max depth = 7, train loss: 22.04616, val loss: 21.36814, in 0.009s\n",
      "[373/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.04400, val loss: 21.36888, in 0.006s\n",
      "[374/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.02262, val loss: 21.31418, in 0.005s\n",
      "[375/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.00144, val loss: 21.26000, in 0.019s\n",
      "[376/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.98069, val loss: 21.20639, in 0.010s\n",
      "[377/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.95970, val loss: 21.15332, in 0.005s\n",
      "[378/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.93891, val loss: 21.10078, in 0.037s\n",
      "[379/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.91834, val loss: 21.04876, in 0.005s\n",
      "[380/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.89797, val loss: 20.99726, in 0.005s\n",
      "[381/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.87828, val loss: 20.94628, in 0.012s\n",
      "[382/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.85836, val loss: 20.89581, in 0.006s\n",
      "[383/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.85132, val loss: 20.89567, in 0.056s\n",
      "[384/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.85105, val loss: 20.89550, in 0.006s\n",
      "[385/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.84629, val loss: 20.86769, in 0.006s\n",
      "[386/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.84178, val loss: 20.84016, in 0.007s\n",
      "[387/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.84076, val loss: 20.84036, in 0.023s\n",
      "[388/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.84005, val loss: 20.83998, in 0.005s\n",
      "[389/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.83462, val loss: 20.82665, in 0.007s\n",
      "[390/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.82948, val loss: 20.81350, in 0.008s\n",
      "[391/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.82263, val loss: 20.81349, in 0.006s\n",
      "[392/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.82240, val loss: 20.81328, in 0.021s\n",
      "[393/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.82215, val loss: 20.81307, in 0.007s\n",
      "[394/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.81864, val loss: 20.81280, in 0.008s\n",
      "[395/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.81225, val loss: 20.81529, in 0.006s\n",
      "[396/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.81200, val loss: 20.81507, in 0.056s\n",
      "[397/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.79709, val loss: 20.81051, in 0.132s\n",
      "[398/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.79161, val loss: 20.81424, in 0.015s\n",
      "[399/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.77910, val loss: 20.81140, in 0.006s\n",
      "[400/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.77861, val loss: 20.81116, in 0.024s\n",
      "[401/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77695, val loss: 20.80929, in 0.005s\n",
      "[402/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77631, val loss: 20.80905, in 0.008s\n",
      "[403/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77569, val loss: 20.80881, in 0.020s\n",
      "[404/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.77516, val loss: 20.80856, in 0.010s\n",
      "[405/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77494, val loss: 20.80841, in 0.007s\n",
      "[406/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77473, val loss: 20.80823, in 0.012s\n",
      "[407/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77453, val loss: 20.80805, in 0.042s\n",
      "[408/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77432, val loss: 20.80787, in 0.030s\n",
      "[409/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77411, val loss: 20.80773, in 0.006s\n",
      "[410/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.77390, val loss: 20.80755, in 0.010s\n",
      "[411/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77370, val loss: 20.80737, in 0.055s\n",
      "[412/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77350, val loss: 20.80720, in 0.006s\n",
      "[413/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77330, val loss: 20.80702, in 0.005s\n",
      "[414/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.77310, val loss: 20.80685, in 0.009s\n",
      "[415/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77291, val loss: 20.80668, in 0.006s\n",
      "[416/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77272, val loss: 20.80651, in 0.005s\n",
      "[417/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77252, val loss: 20.80634, in 0.005s\n",
      "[418/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77233, val loss: 20.80617, in 0.016s\n",
      "[419/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77214, val loss: 20.80600, in 0.010s\n",
      "[420/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77195, val loss: 20.80583, in 0.006s\n",
      "[421/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77177, val loss: 20.80567, in 0.005s\n",
      "[422/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77158, val loss: 20.80551, in 0.020s\n",
      "[423/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77139, val loss: 20.80534, in 0.008s\n",
      "[424/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77121, val loss: 20.80518, in 0.007s\n",
      "[425/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77104, val loss: 20.80503, in 0.027s\n",
      "[426/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77086, val loss: 20.80487, in 0.009s\n",
      "[427/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77069, val loss: 20.80472, in 0.006s\n",
      "[428/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77051, val loss: 20.80456, in 0.005s\n",
      "[429/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77033, val loss: 20.80441, in 0.097s\n",
      "[430/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77015, val loss: 20.80431, in 0.007s\n",
      "[431/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.76998, val loss: 20.80416, in 0.007s\n",
      "[432/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.76981, val loss: 20.80401, in 0.008s\n",
      "[433/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.76964, val loss: 20.80386, in 0.031s\n",
      "[434/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.76947, val loss: 20.80372, in 0.012s\n",
      "[435/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.76930, val loss: 20.80358, in 0.006s\n",
      "[436/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.76913, val loss: 20.80344, in 0.032s\n",
      "[437/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.76897, val loss: 20.80330, in 0.007s\n",
      "[438/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.76880, val loss: 20.80316, in 0.010s\n",
      "[439/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.76865, val loss: 20.80302, in 0.015s\n",
      "[440/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.76849, val loss: 20.80289, in 0.009s\n",
      "[441/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.76834, val loss: 20.80275, in 0.006s\n",
      "[442/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.75864, val loss: 20.80324, in 0.006s\n",
      "[443/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.75839, val loss: 20.80320, in 0.028s\n",
      "[444/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.75185, val loss: 20.79244, in 0.009s\n",
      "[445/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.74550, val loss: 20.78192, in 0.007s\n",
      "[446/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.74533, val loss: 20.78189, in 0.017s\n",
      "[447/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.74515, val loss: 20.78186, in 0.006s\n",
      "[448/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.74497, val loss: 20.78173, in 0.005s\n",
      "[449/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.74481, val loss: 20.78160, in 0.010s\n",
      "[450/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.74464, val loss: 20.78148, in 0.005s\n",
      "[451/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.74447, val loss: 20.78135, in 0.005s\n",
      "[452/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.74430, val loss: 20.78122, in 0.005s\n",
      "[453/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.74415, val loss: 20.78104, in 0.020s\n",
      "[454/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.74400, val loss: 20.78086, in 0.010s\n",
      "[455/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.74386, val loss: 20.78069, in 0.005s\n",
      "[456/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.74369, val loss: 20.78051, in 0.005s\n",
      "[457/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.73901, val loss: 20.78015, in 0.020s\n",
      "[458/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.73760, val loss: 20.77833, in 0.010s\n",
      "[459/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.73746, val loss: 20.77821, in 0.037s\n",
      "[460/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.73729, val loss: 20.77810, in 0.007s\n",
      "[461/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.73712, val loss: 20.77806, in 0.005s\n",
      "[462/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.73693, val loss: 20.77812, in 0.005s\n",
      "[463/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.73677, val loss: 20.77800, in 0.026s\n",
      "[464/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.73663, val loss: 20.77789, in 0.006s\n",
      "[465/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.73649, val loss: 20.77778, in 0.009s\n",
      "[466/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.73634, val loss: 20.77767, in 0.005s\n",
      "[467/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.73621, val loss: 20.77758, in 0.018s\n",
      "[468/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.73606, val loss: 20.77742, in 0.005s\n",
      "[469/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.73593, val loss: 20.77726, in 0.010s\n",
      "[470/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.73580, val loss: 20.77710, in 0.023s\n",
      "[471/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.73566, val loss: 20.77700, in 0.005s\n",
      "[472/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.73553, val loss: 20.77690, in 0.008s\n",
      "[473/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.73539, val loss: 20.77680, in 0.006s\n",
      "[474/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.73527, val loss: 20.77670, in 0.007s\n",
      "[475/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.73514, val loss: 20.77660, in 0.026s\n",
      "[476/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.73501, val loss: 20.77650, in 0.005s\n",
      "[477/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.73423, val loss: 20.77545, in 0.011s\n",
      "[478/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.73411, val loss: 20.77531, in 0.007s\n",
      "[479/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.73400, val loss: 20.77518, in 0.005s\n",
      "[480/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.73388, val loss: 20.77505, in 0.088s\n",
      "[481/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.73378, val loss: 20.77496, in 0.040s\n",
      "[482/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.73189, val loss: 20.77376, in 0.007s\n",
      "[483/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.73027, val loss: 20.77269, in 0.005s\n",
      "[484/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.72837, val loss: 20.77146, in 0.008s\n",
      "[485/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.72680, val loss: 20.77041, in 0.019s\n",
      "[486/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.72667, val loss: 20.77032, in 0.018s\n",
      "[487/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.72648, val loss: 20.77020, in 0.095s\n",
      "[488/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.72637, val loss: 20.77011, in 0.007s\n",
      "[489/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.72501, val loss: 20.76905, in 0.006s\n",
      "[490/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.72372, val loss: 20.76812, in 0.008s\n",
      "[491/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.72360, val loss: 20.76803, in 0.019s\n",
      "[492/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.72349, val loss: 20.76794, in 0.006s\n",
      "[493/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.72337, val loss: 20.76786, in 0.005s\n",
      "[494/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.72327, val loss: 20.76778, in 0.008s\n",
      "[495/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.72292, val loss: 20.76769, in 0.005s\n",
      "[496/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.72192, val loss: 20.76642, in 0.017s\n",
      "[497/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.72181, val loss: 20.76638, in 0.006s\n",
      "[498/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.72168, val loss: 20.76634, in 0.006s\n",
      "[499/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.72136, val loss: 20.76612, in 0.009s\n",
      "[500/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.72127, val loss: 20.76605, in 0.006s\n",
      "[501/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.71925, val loss: 20.76532, in 0.016s\n",
      "[502/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.71915, val loss: 20.76525, in 0.006s\n",
      "[503/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.71906, val loss: 20.76518, in 0.005s\n",
      "[504/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.71897, val loss: 20.76511, in 0.006s\n",
      "[505/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.71703, val loss: 20.74838, in 0.008s\n",
      "[506/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.71509, val loss: 20.73182, in 0.006s\n",
      "[507/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.71317, val loss: 20.71542, in 0.059s\n",
      "[508/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.70971, val loss: 20.69149, in 0.068s\n",
      "[509/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70962, val loss: 20.69147, in 0.007s\n",
      "[510/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70954, val loss: 20.69140, in 0.009s\n",
      "[511/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70946, val loss: 20.69134, in 0.006s\n",
      "[512/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70937, val loss: 20.69129, in 0.032s\n",
      "[513/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70929, val loss: 20.69122, in 0.006s\n",
      "[514/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70922, val loss: 20.69112, in 0.020s\n",
      "[515/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70914, val loss: 20.69101, in 0.007s\n",
      "[516/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70907, val loss: 20.69090, in 0.014s\n",
      "[517/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70900, val loss: 20.69080, in 0.020s\n",
      "[518/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70893, val loss: 20.69074, in 0.019s\n",
      "[519/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70885, val loss: 20.69068, in 0.007s\n",
      "[520/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70878, val loss: 20.69062, in 0.007s\n",
      "[521/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70871, val loss: 20.69056, in 0.006s\n",
      "[522/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70864, val loss: 20.69050, in 0.020s\n",
      "[523/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70858, val loss: 20.69044, in 0.006s\n",
      "[524/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70851, val loss: 20.69039, in 0.010s\n",
      "[525/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.70844, val loss: 20.69033, in 0.005s\n",
      "[526/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.70838, val loss: 20.69027, in 0.019s\n",
      "[527/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70831, val loss: 20.69022, in 0.006s\n",
      "[528/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70824, val loss: 20.69016, in 0.007s\n",
      "[529/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70818, val loss: 20.69011, in 0.005s\n",
      "[530/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70812, val loss: 20.69005, in 0.027s\n",
      "[531/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70805, val loss: 20.69000, in 0.006s\n",
      "[532/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70798, val loss: 20.68994, in 0.005s\n",
      "[533/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70791, val loss: 20.68989, in 0.009s\n",
      "[534/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70784, val loss: 20.68984, in 0.006s\n",
      "[535/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70778, val loss: 20.68979, in 0.017s\n",
      "[536/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70772, val loss: 20.68974, in 0.015s\n",
      "[537/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70765, val loss: 20.68969, in 0.006s\n",
      "[538/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70759, val loss: 20.68964, in 0.005s\n",
      "[539/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70753, val loss: 20.68959, in 0.038s\n",
      "[540/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70747, val loss: 20.68954, in 0.022s\n",
      "[541/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70741, val loss: 20.68949, in 0.006s\n",
      "[542/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70735, val loss: 20.68944, in 0.006s\n",
      "[543/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70729, val loss: 20.68939, in 0.008s\n",
      "[544/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70723, val loss: 20.68934, in 0.006s\n",
      "[545/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70718, val loss: 20.68930, in 0.083s\n",
      "[546/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70712, val loss: 20.68925, in 0.034s\n",
      "[547/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70706, val loss: 20.68921, in 0.007s\n",
      "[548/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70701, val loss: 20.68916, in 0.006s\n",
      "[549/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70695, val loss: 20.68912, in 0.009s\n",
      "[550/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70689, val loss: 20.68907, in 0.016s\n",
      "[551/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70684, val loss: 20.68903, in 0.008s\n",
      "[552/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70678, val loss: 20.68898, in 0.019s\n",
      "[553/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70673, val loss: 20.68894, in 0.005s\n",
      "[554/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70668, val loss: 20.68890, in 0.066s\n",
      "[555/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70663, val loss: 20.68886, in 0.006s\n",
      "[556/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70658, val loss: 20.68881, in 0.009s\n",
      "[557/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70652, val loss: 20.68877, in 0.006s\n",
      "[558/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70647, val loss: 20.68873, in 0.016s\n",
      "[559/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70642, val loss: 20.68869, in 0.009s\n",
      "[560/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70637, val loss: 20.68865, in 0.007s\n",
      "[561/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70632, val loss: 20.68861, in 0.013s\n",
      "[562/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70628, val loss: 20.68857, in 0.016s\n",
      "[563/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70623, val loss: 20.68853, in 0.005s\n",
      "[564/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70618, val loss: 20.68849, in 0.008s\n",
      "[565/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70613, val loss: 20.68846, in 0.006s\n",
      "[566/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70609, val loss: 20.68842, in 0.006s\n",
      "[567/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70604, val loss: 20.68838, in 0.020s\n",
      "[568/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.70599, val loss: 20.68835, in 0.010s\n",
      "[569/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70595, val loss: 20.68832, in 0.007s\n",
      "[570/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70590, val loss: 20.68828, in 0.017s\n",
      "[571/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70586, val loss: 20.68821, in 0.006s\n",
      "[572/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70582, val loss: 20.68813, in 0.009s\n",
      "[573/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70578, val loss: 20.68806, in 0.006s\n",
      "[574/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70574, val loss: 20.68798, in 0.014s\n",
      "[575/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70569, val loss: 20.68791, in 0.006s\n",
      "[576/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70565, val loss: 20.68783, in 0.017s\n",
      "[577/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70561, val loss: 20.68776, in 0.006s\n",
      "[578/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70558, val loss: 20.68769, in 0.009s\n",
      "[579/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70554, val loss: 20.68762, in 0.006s\n",
      "[580/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70550, val loss: 20.68754, in 0.005s\n",
      "[581/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70546, val loss: 20.68747, in 0.031s\n",
      "[582/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70542, val loss: 20.68740, in 0.006s\n",
      "[583/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70538, val loss: 20.68733, in 0.013s\n",
      "[584/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70535, val loss: 20.68726, in 0.005s\n",
      "[585/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70531, val loss: 20.68720, in 0.017s\n",
      "[586/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70527, val loss: 20.68713, in 0.006s\n",
      "[587/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70524, val loss: 20.68706, in 0.009s\n",
      "[588/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70520, val loss: 20.68700, in 0.006s\n",
      "[589/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70517, val loss: 20.68693, in 0.005s\n",
      "[590/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70513, val loss: 20.68687, in 0.120s\n",
      "[591/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70510, val loss: 20.68684, in 0.007s\n",
      "[592/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70506, val loss: 20.68681, in 0.011s\n",
      "[593/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70503, val loss: 20.68679, in 0.020s\n",
      "[594/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70500, val loss: 20.68676, in 0.006s\n",
      "[595/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70497, val loss: 20.68674, in 0.006s\n",
      "[596/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70494, val loss: 20.68671, in 0.010s\n",
      "[597/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70490, val loss: 20.68665, in 0.025s\n",
      "[598/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70486, val loss: 20.68662, in 0.006s\n",
      "[599/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70483, val loss: 20.68656, in 0.015s\n",
      "[600/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70480, val loss: 20.68653, in 0.006s\n",
      "[601/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70476, val loss: 20.68647, in 0.020s\n",
      "[602/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70473, val loss: 20.68644, in 0.006s\n",
      "[603/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70470, val loss: 20.68642, in 0.006s\n",
      "[604/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70467, val loss: 20.68639, in 0.019s\n",
      "[605/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70464, val loss: 20.68637, in 0.019s\n",
      "[606/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70461, val loss: 20.68634, in 0.006s\n",
      "[607/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70458, val loss: 20.68632, in 0.005s\n",
      "[608/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70455, val loss: 20.68629, in 0.018s\n",
      "[609/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70452, val loss: 20.68623, in 0.010s\n",
      "[610/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70449, val loss: 20.68621, in 0.005s\n",
      "[611/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70447, val loss: 20.68618, in 0.018s\n",
      "[612/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70444, val loss: 20.68613, in 0.005s\n",
      "[613/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70441, val loss: 20.68610, in 0.010s\n",
      "[614/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.70438, val loss: 20.68608, in 0.005s\n",
      "[615/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70435, val loss: 20.68603, in 0.021s\n",
      "[616/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70431, val loss: 20.68600, in 0.027s\n",
      "[617/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70428, val loss: 20.68598, in 0.006s\n",
      "[618/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70425, val loss: 20.68596, in 0.042s\n",
      "[619/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70422, val loss: 20.68593, in 0.010s\n",
      "[620/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70419, val loss: 20.68591, in 0.005s\n",
      "[621/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70416, val loss: 20.68589, in 0.036s\n",
      "[622/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70414, val loss: 20.68587, in 0.006s\n",
      "[623/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70411, val loss: 20.68585, in 0.043s\n",
      "[624/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70408, val loss: 20.68583, in 0.008s\n",
      "[625/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70405, val loss: 20.68581, in 0.022s\n",
      "[626/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70402, val loss: 20.68578, in 0.013s\n",
      "[627/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70399, val loss: 20.68577, in 0.005s\n",
      "[628/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70396, val loss: 20.68575, in 0.077s\n",
      "[629/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70394, val loss: 20.68573, in 0.089s\n",
      "[630/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70391, val loss: 20.68571, in 0.007s\n",
      "[631/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70388, val loss: 20.68569, in 0.005s\n",
      "[632/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70385, val loss: 20.68567, in 0.007s\n",
      "[633/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70382, val loss: 20.68565, in 0.021s\n",
      "[634/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70380, val loss: 20.68563, in 0.008s\n",
      "[635/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70377, val loss: 20.68561, in 0.005s\n",
      "[636/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70374, val loss: 20.68559, in 0.020s\n",
      "[637/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70372, val loss: 20.68557, in 0.007s\n",
      "[638/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70369, val loss: 20.68555, in 0.005s\n",
      "[639/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70366, val loss: 20.68554, in 0.007s\n",
      "[640/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70364, val loss: 20.68552, in 0.080s\n",
      "[641/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70361, val loss: 20.68550, in 0.062s\n",
      "[642/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70358, val loss: 20.68548, in 0.010s\n",
      "[643/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70356, val loss: 20.68547, in 0.006s\n",
      "[644/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70353, val loss: 20.68545, in 0.026s\n",
      "[645/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70351, val loss: 20.68543, in 0.007s\n",
      "[646/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70349, val loss: 20.68541, in 0.005s\n",
      "[647/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70346, val loss: 20.68540, in 0.009s\n",
      "[648/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70344, val loss: 20.68538, in 0.017s\n",
      "[649/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70342, val loss: 20.68537, in 0.005s\n",
      "[650/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70339, val loss: 20.68535, in 0.009s\n",
      "[651/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70337, val loss: 20.68534, in 0.005s\n",
      "[652/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70335, val loss: 20.68532, in 0.006s\n",
      "[653/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70332, val loss: 20.68531, in 0.018s\n",
      "[654/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70330, val loss: 20.68529, in 0.011s\n",
      "[655/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70328, val loss: 20.68528, in 0.009s\n",
      "[656/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70326, val loss: 20.68526, in 0.006s\n",
      "[657/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70324, val loss: 20.68525, in 0.050s\n",
      "[658/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70321, val loss: 20.68523, in 0.020s\n",
      "[659/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70319, val loss: 20.68522, in 0.006s\n",
      "[660/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70317, val loss: 20.68520, in 0.009s\n",
      "[661/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70315, val loss: 20.68519, in 0.005s\n",
      "[662/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70313, val loss: 20.68518, in 0.005s\n",
      "[663/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70311, val loss: 20.68516, in 0.005s\n",
      "[664/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70309, val loss: 20.68515, in 0.021s\n",
      "[665/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70307, val loss: 20.68513, in 0.007s\n",
      "[666/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70305, val loss: 20.68512, in 0.005s\n",
      "[667/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70303, val loss: 20.68511, in 0.008s\n",
      "[668/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70301, val loss: 20.68510, in 0.017s\n",
      "[669/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70300, val loss: 20.68508, in 0.006s\n",
      "[670/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70298, val loss: 20.68507, in 0.006s\n",
      "[671/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70296, val loss: 20.68506, in 0.008s\n",
      "[672/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70295, val loss: 20.68504, in 0.011s\n",
      "[673/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70293, val loss: 20.68503, in 0.020s\n",
      "[674/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70292, val loss: 20.68502, in 0.005s\n",
      "[675/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70290, val loss: 20.68501, in 0.006s\n",
      "[676/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70289, val loss: 20.68500, in 0.040s\n",
      "[677/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70288, val loss: 20.68498, in 0.010s\n",
      "[678/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70286, val loss: 20.68497, in 0.006s\n",
      "[679/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70285, val loss: 20.68496, in 0.005s\n",
      "[680/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70283, val loss: 20.68495, in 0.018s\n",
      "[681/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70282, val loss: 20.68494, in 0.008s\n",
      "[682/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70280, val loss: 20.68493, in 0.006s\n",
      "[683/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70279, val loss: 20.68491, in 0.005s\n",
      "[684/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70278, val loss: 20.68490, in 0.005s\n",
      "[685/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70276, val loss: 20.68489, in 0.101s\n",
      "[686/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70275, val loss: 20.68488, in 0.009s\n",
      "[687/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70269, val loss: 20.68488, in 0.006s\n",
      "[688/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70267, val loss: 20.68487, in 0.053s\n",
      "[689/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70266, val loss: 20.68486, in 0.006s\n",
      "[690/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70265, val loss: 20.68484, in 0.020s\n",
      "[691/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70263, val loss: 20.68483, in 0.005s\n",
      "[692/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70262, val loss: 20.68482, in 0.006s\n",
      "[693/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70261, val loss: 20.68481, in 0.008s\n",
      "[694/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70259, val loss: 20.68480, in 0.005s\n",
      "[695/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70255, val loss: 20.68488, in 0.019s\n",
      "[696/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70250, val loss: 20.68495, in 0.005s\n",
      "[697/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70248, val loss: 20.68495, in 0.007s\n",
      "[698/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70246, val loss: 20.68495, in 0.005s\n",
      "[699/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70245, val loss: 20.68495, in 0.005s\n",
      "[700/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70243, val loss: 20.68496, in 0.005s\n",
      "[701/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70241, val loss: 20.68496, in 0.040s\n",
      "[702/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70239, val loss: 20.68496, in 0.006s\n",
      "[703/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70237, val loss: 20.68497, in 0.082s\n",
      "[704/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.70236, val loss: 20.68498, in 0.006s\n",
      "Fit 704 trees in 9.456 s, (21824 total leaves)\n",
      "Time spent computing histograms: 1.956s\n",
      "Time spent finding best splits:  1.222s\n",
      "Time spent applying splits:      1.797s\n",
      "Time spent predicting:           0.590s\n",
      "Binning 0.001 GB of training data: 0.012 s\n",
      "Binning 0.000 GB of validation data: 0.002 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/10000] 1 tree, 31 leaves, max depth = 8, train loss: 42.81176, val loss: 26.14317, in 0.027s\n",
      "[2/10000] 1 tree, 31 leaves, max depth = 10, train loss: 42.72047, val loss: 26.05532, in 0.009s\n",
      "[3/10000] 1 tree, 31 leaves, max depth = 10, train loss: 42.63011, val loss: 25.96834, in 0.006s\n",
      "[4/10000] 1 tree, 31 leaves, max depth = 10, train loss: 42.54065, val loss: 25.88239, in 0.009s\n",
      "[5/10000] 1 tree, 31 leaves, max depth = 10, train loss: 42.45222, val loss: 25.79730, in 0.005s\n",
      "[6/10000] 1 tree, 31 leaves, max depth = 8, train loss: 42.36500, val loss: 25.71354, in 0.020s\n",
      "[7/10000] 1 tree, 31 leaves, max depth = 8, train loss: 42.27135, val loss: 25.62248, in 0.005s\n",
      "[8/10000] 1 tree, 31 leaves, max depth = 8, train loss: 42.17862, val loss: 25.53233, in 0.010s\n",
      "[9/10000] 1 tree, 31 leaves, max depth = 7, train loss: 42.08679, val loss: 25.44300, in 0.005s\n",
      "[10/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.99589, val loss: 25.35465, in 0.005s\n",
      "[11/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.90670, val loss: 25.26787, in 0.020s\n",
      "[12/10000] 1 tree, 31 leaves, max depth = 9, train loss: 41.80831, val loss: 25.18160, in 0.005s\n",
      "[13/10000] 1 tree, 31 leaves, max depth = 9, train loss: 41.71089, val loss: 25.09620, in 0.006s\n",
      "[14/10000] 1 tree, 31 leaves, max depth = 9, train loss: 41.61445, val loss: 25.01166, in 0.007s\n",
      "[15/10000] 1 tree, 31 leaves, max depth = 9, train loss: 41.51924, val loss: 24.92796, in 0.006s\n",
      "[16/10000] 1 tree, 31 leaves, max depth = 10, train loss: 41.41989, val loss: 24.84300, in 0.005s\n",
      "[17/10000] 1 tree, 31 leaves, max depth = 10, train loss: 41.32180, val loss: 24.75889, in 0.072s\n",
      "[18/10000] 1 tree, 31 leaves, max depth = 10, train loss: 41.22416, val loss: 24.67452, in 0.011s\n",
      "[19/10000] 1 tree, 31 leaves, max depth = 10, train loss: 41.12832, val loss: 24.59100, in 0.006s\n",
      "[20/10000] 1 tree, 31 leaves, max depth = 10, train loss: 41.02417, val loss: 24.49893, in 0.020s\n",
      "[21/10000] 1 tree, 31 leaves, max depth = 10, train loss: 40.92113, val loss: 24.40780, in 0.007s\n",
      "[22/10000] 1 tree, 31 leaves, max depth = 10, train loss: 40.81935, val loss: 24.31923, in 0.026s\n",
      "[23/10000] 1 tree, 31 leaves, max depth = 10, train loss: 40.71940, val loss: 24.23492, in 0.007s\n",
      "[24/10000] 1 tree, 31 leaves, max depth = 10, train loss: 40.61149, val loss: 24.13794, in 0.007s\n",
      "[25/10000] 1 tree, 31 leaves, max depth = 10, train loss: 40.50487, val loss: 24.04190, in 0.005s\n",
      "[26/10000] 1 tree, 31 leaves, max depth = 10, train loss: 40.39964, val loss: 23.94685, in 0.025s\n",
      "[27/10000] 1 tree, 31 leaves, max depth = 10, train loss: 40.29551, val loss: 23.85269, in 0.013s\n",
      "[28/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.20208, val loss: 23.77240, in 0.005s\n",
      "[29/10000] 1 tree, 31 leaves, max depth = 9, train loss: 40.09327, val loss: 23.69434, in 0.009s\n",
      "[30/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.98678, val loss: 23.61813, in 0.026s\n",
      "[31/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.88221, val loss: 23.54269, in 0.007s\n",
      "[32/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.77869, val loss: 23.46800, in 0.010s\n",
      "[33/10000] 1 tree, 31 leaves, max depth = 9, train loss: 39.67725, val loss: 23.39408, in 0.039s\n",
      "[34/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.56997, val loss: 23.31304, in 0.007s\n",
      "[35/10000] 1 tree, 31 leaves, max depth = 9, train loss: 39.46443, val loss: 23.23298, in 0.006s\n",
      "[36/10000] 1 tree, 31 leaves, max depth = 9, train loss: 39.35453, val loss: 23.14903, in 0.029s\n",
      "[37/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.26218, val loss: 23.07464, in 0.006s\n",
      "[38/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.14698, val loss: 22.99486, in 0.085s\n",
      "[39/10000] 1 tree, 31 leaves, max depth = 9, train loss: 39.03387, val loss: 22.90525, in 0.006s\n",
      "[40/10000] 1 tree, 31 leaves, max depth = 9, train loss: 38.92220, val loss: 22.81661, in 0.006s\n",
      "[41/10000] 1 tree, 31 leaves, max depth = 9, train loss: 38.81684, val loss: 22.73581, in 0.005s\n",
      "[42/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.70653, val loss: 22.65199, in 0.053s\n",
      "[43/10000] 1 tree, 31 leaves, max depth = 9, train loss: 38.59614, val loss: 22.56984, in 0.022s\n",
      "[44/10000] 1 tree, 31 leaves, max depth = 10, train loss: 38.48322, val loss: 22.48769, in 0.006s\n",
      "[45/10000] 1 tree, 31 leaves, max depth = 9, train loss: 38.37125, val loss: 22.40805, in 0.006s\n",
      "[46/10000] 1 tree, 31 leaves, max depth = 9, train loss: 38.26147, val loss: 22.33091, in 0.009s\n",
      "[47/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.14625, val loss: 22.26765, in 0.020s\n",
      "[48/10000] 1 tree, 31 leaves, max depth = 9, train loss: 38.03560, val loss: 22.20745, in 0.006s\n",
      "[49/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.92598, val loss: 22.14628, in 0.005s\n",
      "[50/10000] 1 tree, 31 leaves, max depth = 9, train loss: 37.81091, val loss: 22.08079, in 0.009s\n",
      "[51/10000] 1 tree, 31 leaves, max depth = 10, train loss: 37.69894, val loss: 22.01673, in 0.007s\n",
      "[52/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.58505, val loss: 21.95195, in 0.006s\n",
      "[53/10000] 1 tree, 31 leaves, max depth = 7, train loss: 37.47381, val loss: 21.88723, in 0.006s\n",
      "[54/10000] 1 tree, 31 leaves, max depth = 9, train loss: 37.36799, val loss: 21.82566, in 0.036s\n",
      "[55/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.25342, val loss: 21.76350, in 0.006s\n",
      "[56/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.14556, val loss: 21.69924, in 0.018s\n",
      "[57/10000] 1 tree, 31 leaves, max depth = 9, train loss: 37.02408, val loss: 21.62218, in 0.006s\n",
      "[58/10000] 1 tree, 31 leaves, max depth = 9, train loss: 36.90704, val loss: 21.54462, in 0.010s\n",
      "[59/10000] 1 tree, 31 leaves, max depth = 9, train loss: 36.79237, val loss: 21.46806, in 0.006s\n",
      "[60/10000] 1 tree, 31 leaves, max depth = 10, train loss: 36.69894, val loss: 21.40626, in 0.017s\n",
      "[61/10000] 1 tree, 31 leaves, max depth = 10, train loss: 36.58161, val loss: 21.33778, in 0.006s\n",
      "[62/10000] 1 tree, 31 leaves, max depth = 9, train loss: 36.46547, val loss: 21.27050, in 0.019s\n",
      "[63/10000] 1 tree, 31 leaves, max depth = 10, train loss: 36.35181, val loss: 21.20457, in 0.051s\n",
      "[64/10000] 1 tree, 31 leaves, max depth = 10, train loss: 36.22373, val loss: 21.12504, in 0.010s\n",
      "[65/10000] 1 tree, 31 leaves, max depth = 10, train loss: 36.09839, val loss: 21.05202, in 0.006s\n",
      "[66/10000] 1 tree, 31 leaves, max depth = 10, train loss: 35.97468, val loss: 20.97980, in 0.020s\n",
      "[67/10000] 1 tree, 31 leaves, max depth = 10, train loss: 35.85313, val loss: 20.90772, in 0.006s\n",
      "[68/10000] 1 tree, 31 leaves, max depth = 10, train loss: 35.73691, val loss: 20.83759, in 0.005s\n",
      "[69/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.62434, val loss: 20.77352, in 0.005s\n",
      "[70/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.50656, val loss: 20.71348, in 0.109s\n",
      "[71/10000] 1 tree, 31 leaves, max depth = 7, train loss: 35.38615, val loss: 20.64136, in 0.007s\n",
      "[72/10000] 1 tree, 31 leaves, max depth = 10, train loss: 35.26316, val loss: 20.56222, in 0.006s\n",
      "[73/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.14005, val loss: 20.49079, in 0.005s\n",
      "[74/10000] 1 tree, 31 leaves, max depth = 10, train loss: 35.02008, val loss: 20.41450, in 0.029s\n",
      "[75/10000] 1 tree, 31 leaves, max depth = 10, train loss: 34.89512, val loss: 20.35359, in 0.006s\n",
      "[76/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.77185, val loss: 20.29330, in 0.017s\n",
      "[77/10000] 1 tree, 31 leaves, max depth = 10, train loss: 34.65820, val loss: 20.22417, in 0.022s\n",
      "[78/10000] 1 tree, 31 leaves, max depth = 7, train loss: 34.53690, val loss: 20.16342, in 0.005s\n",
      "[79/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.43421, val loss: 20.10498, in 0.007s\n",
      "[80/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.32453, val loss: 20.03576, in 0.011s\n",
      "[81/10000] 1 tree, 31 leaves, max depth = 10, train loss: 34.19979, val loss: 19.96829, in 0.029s\n",
      "[82/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.08205, val loss: 19.90100, in 0.007s\n",
      "[83/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.95994, val loss: 19.83151, in 0.049s\n",
      "[84/10000] 1 tree, 31 leaves, max depth = 9, train loss: 33.84123, val loss: 19.76689, in 0.006s\n",
      "[85/10000] 1 tree, 31 leaves, max depth = 9, train loss: 33.72586, val loss: 19.69254, in 0.006s\n",
      "[86/10000] 1 tree, 31 leaves, max depth = 9, train loss: 33.61263, val loss: 19.61893, in 0.071s\n",
      "[87/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.50097, val loss: 19.54544, in 0.109s\n",
      "[88/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.38665, val loss: 19.48246, in 0.019s\n",
      "[89/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.29555, val loss: 19.42561, in 0.025s\n",
      "[90/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.18406, val loss: 19.35364, in 0.006s\n",
      "[91/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.07433, val loss: 19.29116, in 0.008s\n",
      "[92/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.94212, val loss: 19.24223, in 0.040s\n",
      "[93/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.81639, val loss: 19.18219, in 0.006s\n",
      "[94/10000] 1 tree, 31 leaves, max depth = 9, train loss: 32.69008, val loss: 19.13411, in 0.036s\n",
      "[95/10000] 1 tree, 31 leaves, max depth = 7, train loss: 32.57651, val loss: 19.07639, in 0.009s\n",
      "[96/10000] 1 tree, 31 leaves, max depth = 9, train loss: 32.46434, val loss: 19.01754, in 0.056s\n",
      "[97/10000] 1 tree, 31 leaves, max depth = 10, train loss: 32.35037, val loss: 18.95927, in 0.015s\n",
      "[98/10000] 1 tree, 31 leaves, max depth = 9, train loss: 32.22710, val loss: 18.90468, in 0.006s\n",
      "[99/10000] 1 tree, 31 leaves, max depth = 10, train loss: 32.10803, val loss: 18.86823, in 0.151s\n",
      "[100/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.00823, val loss: 18.84189, in 0.006s\n",
      "[101/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.87819, val loss: 18.78097, in 0.040s\n",
      "[102/10000] 1 tree, 31 leaves, max depth = 10, train loss: 31.77876, val loss: 18.75519, in 0.012s\n",
      "[103/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.66170, val loss: 18.71341, in 0.005s\n",
      "[104/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.54731, val loss: 18.67154, in 0.005s\n",
      "[105/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.43442, val loss: 18.63722, in 0.055s\n",
      "[106/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.32397, val loss: 18.60295, in 0.008s\n",
      "[107/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.21574, val loss: 18.56872, in 0.006s\n",
      "[108/10000] 1 tree, 31 leaves, max depth = 7, train loss: 31.10551, val loss: 18.51832, in 0.005s\n",
      "[109/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.99074, val loss: 18.46195, in 0.008s\n",
      "[110/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.87973, val loss: 18.40660, in 0.025s\n",
      "[111/10000] 1 tree, 31 leaves, max depth = 10, train loss: 30.76896, val loss: 18.37298, in 0.005s\n",
      "[112/10000] 1 tree, 31 leaves, max depth = 9, train loss: 30.65634, val loss: 18.32928, in 0.005s\n",
      "[113/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.55126, val loss: 18.27466, in 0.005s\n",
      "[114/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.44130, val loss: 18.24015, in 0.021s\n",
      "[115/10000] 1 tree, 31 leaves, max depth = 9, train loss: 30.32838, val loss: 18.20137, in 0.007s\n",
      "[116/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.21740, val loss: 18.13981, in 0.005s\n",
      "[117/10000] 1 tree, 31 leaves, max depth = 10, train loss: 30.14385, val loss: 18.11012, in 0.005s\n",
      "[118/10000] 1 tree, 31 leaves, max depth = 9, train loss: 30.05665, val loss: 18.08771, in 0.005s\n",
      "[119/10000] 1 tree, 31 leaves, max depth = 9, train loss: 29.96982, val loss: 18.06640, in 0.022s\n",
      "[120/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.87543, val loss: 18.03927, in 0.007s\n",
      "[121/10000] 1 tree, 31 leaves, max depth = 7, train loss: 29.78455, val loss: 18.00900, in 0.005s\n",
      "[122/10000] 1 tree, 31 leaves, max depth = 10, train loss: 29.68317, val loss: 17.96460, in 0.008s\n",
      "[123/10000] 1 tree, 31 leaves, max depth = 10, train loss: 29.58463, val loss: 17.91799, in 0.023s\n",
      "[124/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.48821, val loss: 17.88939, in 0.006s\n",
      "[125/10000] 1 tree, 31 leaves, max depth = 9, train loss: 29.41275, val loss: 17.86320, in 0.006s\n",
      "[126/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.31265, val loss: 17.80473, in 0.030s\n",
      "[127/10000] 1 tree, 31 leaves, max depth = 9, train loss: 29.24278, val loss: 17.78119, in 0.007s\n",
      "[128/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.15673, val loss: 17.75626, in 0.005s\n",
      "[129/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.07168, val loss: 17.72132, in 0.008s\n",
      "[130/10000] 1 tree, 31 leaves, max depth = 10, train loss: 29.00588, val loss: 17.69227, in 0.005s\n",
      "[131/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.92295, val loss: 17.66009, in 0.005s\n",
      "[132/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.84172, val loss: 17.62823, in 0.065s\n",
      "[133/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.76454, val loss: 17.59663, in 0.007s\n",
      "[134/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.68179, val loss: 17.55495, in 0.006s\n",
      "[135/10000] 1 tree, 31 leaves, max depth = 10, train loss: 28.59980, val loss: 17.51900, in 0.010s\n",
      "[136/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.51095, val loss: 17.47080, in 0.120s\n",
      "[137/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.41805, val loss: 17.41623, in 0.019s\n",
      "[138/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.33833, val loss: 17.38035, in 0.038s\n",
      "[139/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.25344, val loss: 17.34524, in 0.047s\n",
      "[140/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.17542, val loss: 17.30912, in 0.006s\n",
      "[141/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.09843, val loss: 17.27316, in 0.006s\n",
      "[142/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.02191, val loss: 17.23835, in 0.008s\n",
      "[143/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.94560, val loss: 17.20274, in 0.005s\n",
      "[144/10000] 1 tree, 31 leaves, max depth = 7, train loss: 27.85849, val loss: 17.15085, in 0.073s\n",
      "[145/10000] 1 tree, 31 leaves, max depth = 7, train loss: 27.78501, val loss: 17.11600, in 0.011s\n",
      "[146/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.71436, val loss: 17.08769, in 0.006s\n",
      "[147/10000] 1 tree, 31 leaves, max depth = 7, train loss: 27.65036, val loss: 17.06766, in 0.022s\n",
      "[148/10000] 1 tree, 31 leaves, max depth = 7, train loss: 27.58406, val loss: 17.04532, in 0.010s\n",
      "[149/10000] 1 tree, 31 leaves, max depth = 7, train loss: 27.49719, val loss: 17.03244, in 0.006s\n",
      "[150/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.43031, val loss: 17.02397, in 0.009s\n",
      "[151/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.34593, val loss: 17.01148, in 0.006s\n",
      "[152/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.28025, val loss: 16.99247, in 0.027s\n",
      "[153/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.21737, val loss: 16.98443, in 0.006s\n",
      "[154/10000] 1 tree, 31 leaves, max depth = 7, train loss: 27.15154, val loss: 16.95054, in 0.007s\n",
      "[155/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.09005, val loss: 16.94255, in 0.009s\n",
      "[156/10000] 1 tree, 31 leaves, max depth = 7, train loss: 27.01690, val loss: 16.93383, in 0.028s\n",
      "[157/10000] 1 tree, 31 leaves, max depth = 10, train loss: 26.95135, val loss: 16.89570, in 0.009s\n",
      "[158/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.89283, val loss: 16.86768, in 0.005s\n",
      "[159/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.82397, val loss: 16.81984, in 0.005s\n",
      "[160/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.77386, val loss: 16.80206, in 0.022s\n",
      "[161/10000] 1 tree, 31 leaves, max depth = 7, train loss: 26.71060, val loss: 16.76361, in 0.008s\n",
      "[162/10000] 1 tree, 31 leaves, max depth = 7, train loss: 26.64834, val loss: 16.72543, in 0.006s\n",
      "[163/10000] 1 tree, 31 leaves, max depth = 7, train loss: 26.58822, val loss: 16.68714, in 0.006s\n",
      "[164/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.52103, val loss: 16.65781, in 0.104s\n",
      "[165/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.45553, val loss: 16.62782, in 0.006s\n",
      "[166/10000] 1 tree, 31 leaves, max depth = 7, train loss: 26.40117, val loss: 16.60190, in 0.006s\n",
      "[167/10000] 1 tree, 31 leaves, max depth = 7, train loss: 26.34598, val loss: 16.57403, in 0.005s\n",
      "[168/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.29087, val loss: 16.54051, in 0.036s\n",
      "[169/10000] 1 tree, 31 leaves, max depth = 11, train loss: 26.23597, val loss: 16.50122, in 0.009s\n",
      "[170/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.18688, val loss: 16.47604, in 0.005s\n",
      "[171/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.14010, val loss: 16.44994, in 0.005s\n",
      "[172/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.08871, val loss: 16.41902, in 0.031s\n",
      "[173/10000] 1 tree, 31 leaves, max depth = 7, train loss: 26.04046, val loss: 16.40815, in 0.005s\n",
      "[174/10000] 1 tree, 31 leaves, max depth = 7, train loss: 25.99398, val loss: 16.39715, in 0.019s\n",
      "[175/10000] 1 tree, 31 leaves, max depth = 7, train loss: 25.94962, val loss: 16.36613, in 0.005s\n",
      "[176/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.92245, val loss: 16.35285, in 0.009s\n",
      "[177/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.89960, val loss: 16.33871, in 0.006s\n",
      "[178/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.87532, val loss: 16.31693, in 0.006s\n",
      "[179/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.83156, val loss: 16.29301, in 0.034s\n",
      "[180/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.78776, val loss: 16.27086, in 0.005s\n",
      "[181/10000] 1 tree, 31 leaves, max depth = 11, train loss: 25.73703, val loss: 16.24134, in 0.012s\n",
      "[182/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.69658, val loss: 16.21950, in 0.006s\n",
      "[183/10000] 1 tree, 31 leaves, max depth = 11, train loss: 25.65489, val loss: 16.16929, in 0.022s\n",
      "[184/10000] 1 tree, 31 leaves, max depth = 7, train loss: 25.60505, val loss: 16.13863, in 0.009s\n",
      "[185/10000] 1 tree, 31 leaves, max depth = 7, train loss: 25.55715, val loss: 16.10981, in 0.011s\n",
      "[186/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.50478, val loss: 16.09429, in 0.020s\n",
      "[187/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.48217, val loss: 16.07984, in 0.005s\n",
      "[188/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.43003, val loss: 16.06621, in 0.006s\n",
      "[189/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.39197, val loss: 16.04408, in 0.012s\n",
      "[190/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.34059, val loss: 16.03202, in 0.009s\n",
      "[191/10000] 1 tree, 31 leaves, max depth = 7, train loss: 25.31111, val loss: 16.01398, in 0.021s\n",
      "[192/10000] 1 tree, 31 leaves, max depth = 7, train loss: 25.26477, val loss: 15.99802, in 0.005s\n",
      "[193/10000] 1 tree, 31 leaves, max depth = 7, train loss: 25.21374, val loss: 15.98776, in 0.010s\n",
      "[194/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.19253, val loss: 15.97600, in 0.005s\n",
      "[195/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.14589, val loss: 15.97518, in 0.005s\n",
      "[196/10000] 1 tree, 31 leaves, max depth = 7, train loss: 25.09944, val loss: 15.96147, in 0.021s\n",
      "[197/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.05361, val loss: 15.95293, in 0.008s\n",
      "[198/10000] 1 tree, 31 leaves, max depth = 7, train loss: 25.00885, val loss: 15.93935, in 0.027s\n",
      "[199/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.97808, val loss: 15.92012, in 0.066s\n",
      "[200/10000] 1 tree, 31 leaves, max depth = 7, train loss: 24.93670, val loss: 15.90453, in 0.045s\n",
      "[201/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.90159, val loss: 15.88690, in 0.006s\n",
      "[202/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.86740, val loss: 15.86956, in 0.010s\n",
      "[203/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.83416, val loss: 15.85269, in 0.023s\n",
      "[204/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.80217, val loss: 15.83553, in 0.019s\n",
      "[205/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.77005, val loss: 15.81655, in 0.005s\n",
      "[206/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.74624, val loss: 15.81352, in 0.022s\n",
      "[207/10000] 1 tree, 31 leaves, max depth = 7, train loss: 24.72632, val loss: 15.80954, in 0.005s\n",
      "[208/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.71639, val loss: 15.80537, in 0.008s\n",
      "[209/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.70434, val loss: 15.80262, in 0.005s\n",
      "[210/10000] 1 tree, 31 leaves, max depth = 11, train loss: 24.68405, val loss: 15.79537, in 0.005s\n",
      "[211/10000] 1 tree, 31 leaves, max depth = 7, train loss: 24.64907, val loss: 15.77069, in 0.028s\n",
      "[212/10000] 1 tree, 31 leaves, max depth = 7, train loss: 24.62197, val loss: 15.75336, in 0.005s\n",
      "[213/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.60814, val loss: 15.74770, in 0.006s\n",
      "[214/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.60058, val loss: 15.74377, in 0.008s\n",
      "[215/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.56541, val loss: 15.73760, in 0.005s\n",
      "[216/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.52916, val loss: 15.72823, in 0.005s\n",
      "[217/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.49342, val loss: 15.72023, in 0.020s\n",
      "[218/10000] 1 tree, 31 leaves, max depth = 12, train loss: 24.45950, val loss: 15.71336, in 0.005s\n",
      "[219/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.42566, val loss: 15.70632, in 0.005s\n",
      "[220/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.39298, val loss: 15.69628, in 0.008s\n",
      "[221/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.36380, val loss: 15.67440, in 0.005s\n",
      "[222/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.32726, val loss: 15.66463, in 0.005s\n",
      "[223/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.31407, val loss: 15.65848, in 0.021s\n",
      "[224/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.28339, val loss: 15.65274, in 0.034s\n",
      "[225/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.24969, val loss: 15.64705, in 0.006s\n",
      "[226/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.23740, val loss: 15.64242, in 0.006s\n",
      "[227/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.22230, val loss: 15.63755, in 0.009s\n",
      "[228/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.21108, val loss: 15.63326, in 0.021s\n",
      "[229/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.20101, val loss: 15.62485, in 0.024s\n",
      "[230/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.19107, val loss: 15.61652, in 0.006s\n",
      "[231/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.15872, val loss: 15.61216, in 0.007s\n",
      "[232/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.14864, val loss: 15.60186, in 0.022s\n",
      "[233/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.13851, val loss: 15.59886, in 0.005s\n",
      "[234/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.11754, val loss: 15.58386, in 0.044s\n",
      "[235/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.09183, val loss: 15.58700, in 0.006s\n",
      "[236/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.08179, val loss: 15.57732, in 0.006s\n",
      "[237/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.07115, val loss: 15.56763, in 0.010s\n",
      "[238/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.06171, val loss: 15.55753, in 0.019s\n",
      "[239/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.04147, val loss: 15.55565, in 0.009s\n",
      "[240/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.01614, val loss: 15.55624, in 0.005s\n",
      "[241/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.01127, val loss: 15.55621, in 0.005s\n",
      "[242/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.98747, val loss: 15.54413, in 0.026s\n",
      "[243/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.97785, val loss: 15.54564, in 0.006s\n",
      "[244/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.96882, val loss: 15.54479, in 0.006s\n",
      "[245/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.94628, val loss: 15.52479, in 0.029s\n",
      "[246/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.92399, val loss: 15.50521, in 0.006s\n",
      "[247/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.90397, val loss: 15.49234, in 0.006s\n",
      "[248/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.88780, val loss: 15.46616, in 0.009s\n",
      "[249/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.86069, val loss: 15.45604, in 0.021s\n",
      "[250/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.84557, val loss: 15.43872, in 0.005s\n",
      "[251/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.82052, val loss: 15.42296, in 0.005s\n",
      "[252/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.80584, val loss: 15.40595, in 0.009s\n",
      "[253/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.78226, val loss: 15.39962, in 0.005s\n",
      "[254/10000] 1 tree, 31 leaves, max depth = 12, train loss: 23.76749, val loss: 15.39300, in 0.020s\n",
      "[255/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.75991, val loss: 15.38751, in 0.005s\n",
      "[256/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.74827, val loss: 15.37085, in 0.009s\n",
      "[257/10000] 1 tree, 31 leaves, max depth = 12, train loss: 23.73425, val loss: 15.36588, in 0.033s\n",
      "[258/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.70570, val loss: 15.32848, in 0.007s\n",
      "[259/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.69192, val loss: 15.31137, in 0.006s\n",
      "[260/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.66814, val loss: 15.30696, in 0.021s\n",
      "[261/10000] 1 tree, 31 leaves, max depth = 12, train loss: 23.64733, val loss: 15.30350, in 0.005s\n",
      "[262/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.63146, val loss: 15.30116, in 0.005s\n",
      "[263/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.59996, val loss: 15.29777, in 0.005s\n",
      "[264/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.57893, val loss: 15.29527, in 0.008s\n",
      "[265/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.56481, val loss: 15.28488, in 0.005s\n",
      "[266/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.54531, val loss: 15.28866, in 0.005s\n",
      "[267/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.53131, val loss: 15.27739, in 0.042s\n",
      "[268/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.52227, val loss: 15.26650, in 0.005s\n",
      "[269/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.49470, val loss: 15.26299, in 0.054s\n",
      "[270/10000] 1 tree, 31 leaves, max depth = 12, train loss: 23.47795, val loss: 15.24548, in 0.010s\n",
      "[271/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.46534, val loss: 15.22432, in 0.006s\n",
      "[272/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.45522, val loss: 15.21682, in 0.038s\n",
      "[273/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.43355, val loss: 15.21330, in 0.012s\n",
      "[274/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.41868, val loss: 15.20508, in 0.006s\n",
      "[275/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.40180, val loss: 15.18306, in 0.005s\n",
      "[276/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.39209, val loss: 15.17080, in 0.103s\n",
      "[277/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.37547, val loss: 15.15016, in 0.006s\n",
      "[278/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.35937, val loss: 15.12808, in 0.006s\n",
      "[279/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.34151, val loss: 15.08177, in 0.036s\n",
      "[280/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.32363, val loss: 15.03527, in 0.009s\n",
      "[281/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.30684, val loss: 14.99007, in 0.005s\n",
      "[282/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.29006, val loss: 14.96541, in 0.005s\n",
      "[283/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.27426, val loss: 14.94112, in 0.026s\n",
      "[284/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.25782, val loss: 14.91311, in 0.006s\n",
      "[285/10000] 1 tree, 31 leaves, max depth = 12, train loss: 23.24588, val loss: 14.88969, in 0.009s\n",
      "[286/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.22977, val loss: 14.85825, in 0.023s\n",
      "[287/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.21379, val loss: 14.82712, in 0.022s\n",
      "[288/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.19656, val loss: 14.79636, in 0.040s\n",
      "[289/10000] 1 tree, 31 leaves, max depth = 12, train loss: 23.17978, val loss: 14.76689, in 0.068s\n",
      "[290/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.16795, val loss: 14.74467, in 0.007s\n",
      "[291/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.15382, val loss: 14.72383, in 0.005s\n",
      "[292/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.14066, val loss: 14.71361, in 0.007s\n",
      "[293/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.12573, val loss: 14.69562, in 0.022s\n",
      "[294/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.10941, val loss: 14.66856, in 0.007s\n",
      "[295/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.09487, val loss: 14.64621, in 0.010s\n",
      "[296/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.08100, val loss: 14.62304, in 0.024s\n",
      "[297/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.06702, val loss: 14.60027, in 0.009s\n",
      "[298/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.05296, val loss: 14.57819, in 0.005s\n",
      "[299/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.03770, val loss: 14.54130, in 0.049s\n",
      "[300/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.02652, val loss: 14.52000, in 0.009s\n",
      "[301/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.01068, val loss: 14.48204, in 0.005s\n",
      "[302/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.99992, val loss: 14.47044, in 0.035s\n",
      "[303/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.98474, val loss: 14.43454, in 0.005s\n",
      "[304/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.97524, val loss: 14.42473, in 0.005s\n",
      "[305/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.94355, val loss: 14.42667, in 0.024s\n",
      "[306/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.92848, val loss: 14.42145, in 0.007s\n",
      "[307/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.91534, val loss: 14.41096, in 0.005s\n",
      "[308/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.90594, val loss: 14.40955, in 0.053s\n",
      "[309/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.89636, val loss: 14.40807, in 0.007s\n",
      "[310/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.88359, val loss: 14.39274, in 0.024s\n",
      "[311/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.87378, val loss: 14.39149, in 0.006s\n",
      "[312/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.84448, val loss: 14.39015, in 0.023s\n",
      "[313/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.81474, val loss: 14.38850, in 0.006s\n",
      "[314/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.79775, val loss: 14.37638, in 0.005s\n",
      "[315/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.78028, val loss: 14.36350, in 0.022s\n",
      "[316/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.77130, val loss: 14.35653, in 0.017s\n",
      "[317/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.75866, val loss: 14.35566, in 0.050s\n",
      "[318/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.74938, val loss: 14.34586, in 0.029s\n",
      "[319/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.74078, val loss: 14.33642, in 0.006s\n",
      "[320/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.73152, val loss: 14.32493, in 0.005s\n",
      "[321/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.72205, val loss: 14.31591, in 0.104s\n",
      "[322/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.71011, val loss: 14.30666, in 0.007s\n",
      "[323/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.70230, val loss: 14.29768, in 0.006s\n",
      "[324/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.69349, val loss: 14.28861, in 0.043s\n",
      "[325/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.67640, val loss: 14.28544, in 0.006s\n",
      "[326/10000] 1 tree, 31 leaves, max depth = 14, train loss: 22.66759, val loss: 14.28562, in 0.005s\n",
      "[327/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.65888, val loss: 14.28164, in 0.010s\n",
      "[328/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.64924, val loss: 14.26316, in 0.005s\n",
      "[329/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.64146, val loss: 14.25447, in 0.005s\n",
      "[330/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.63913, val loss: 14.25393, in 0.089s\n",
      "[331/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.63052, val loss: 14.24783, in 0.006s\n",
      "[332/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.62247, val loss: 14.23005, in 0.009s\n",
      "[333/10000] 1 tree, 31 leaves, max depth = 13, train loss: 22.61151, val loss: 14.22252, in 0.006s\n",
      "[334/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.59644, val loss: 14.21620, in 0.010s\n",
      "[335/10000] 1 tree, 31 leaves, max depth = 13, train loss: 22.59269, val loss: 14.21000, in 0.022s\n",
      "[336/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.57993, val loss: 14.17372, in 0.005s\n",
      "[337/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.57712, val loss: 14.17122, in 0.005s\n",
      "[338/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.55536, val loss: 14.16417, in 0.009s\n",
      "[339/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.54451, val loss: 14.14037, in 0.005s\n",
      "[340/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.53652, val loss: 14.13391, in 0.022s\n",
      "[341/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.53002, val loss: 14.13297, in 0.005s\n",
      "[342/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.52276, val loss: 14.13204, in 0.005s\n",
      "[343/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.51239, val loss: 14.12768, in 0.005s\n",
      "[344/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.49634, val loss: 14.10118, in 0.039s\n",
      "[345/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.49241, val loss: 14.09575, in 0.006s\n",
      "[346/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.48699, val loss: 14.09546, in 0.009s\n",
      "[347/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.48061, val loss: 14.09920, in 0.023s\n",
      "[348/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.47533, val loss: 14.09878, in 0.005s\n",
      "[349/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.47011, val loss: 14.09839, in 0.005s\n",
      "[350/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.46494, val loss: 14.09798, in 0.009s\n",
      "[351/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.45989, val loss: 14.09759, in 0.005s\n",
      "[352/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.45512, val loss: 14.09720, in 0.005s\n",
      "[353/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.45041, val loss: 14.09681, in 0.022s\n",
      "[354/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.44574, val loss: 14.09643, in 0.005s\n",
      "[355/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.44118, val loss: 14.09605, in 0.016s\n",
      "[356/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.43880, val loss: 14.09557, in 0.005s\n",
      "Fit 356 trees in 5.869 s, (11036 total leaves)\n",
      "Time spent computing histograms: 1.300s\n",
      "Time spent finding best splits:  0.711s\n",
      "Time spent applying splits:      1.112s\n",
      "Time spent predicting:           0.354s\n",
      "Binning 0.001 GB of training data: 0.012 s\n",
      "Binning 0.000 GB of validation data: 0.026 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/10000] 1 tree, 31 leaves, max depth = 8, train loss: 42.00621, val loss: 26.93071, in 0.006s\n",
      "[2/10000] 1 tree, 31 leaves, max depth = 11, train loss: 41.90616, val loss: 26.83347, in 0.023s\n",
      "[3/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.80704, val loss: 26.73698, in 0.005s\n",
      "[4/10000] 1 tree, 31 leaves, max depth = 9, train loss: 41.70899, val loss: 26.64160, in 0.005s\n",
      "[5/10000] 1 tree, 31 leaves, max depth = 9, train loss: 41.61190, val loss: 26.54695, in 0.008s\n",
      "[6/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.51898, val loss: 26.45636, in 0.046s\n",
      "[7/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.41390, val loss: 26.36334, in 0.006s\n",
      "[8/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.30985, val loss: 26.27117, in 0.023s\n",
      "[9/10000] 1 tree, 31 leaves, max depth = 7, train loss: 41.20688, val loss: 26.18008, in 0.007s\n",
      "[10/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.10650, val loss: 26.08974, in 0.005s\n",
      "[11/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.00002, val loss: 25.99699, in 0.005s\n",
      "[12/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.89455, val loss: 25.90513, in 0.005s\n",
      "[13/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.79019, val loss: 25.81422, in 0.021s\n",
      "[14/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.68867, val loss: 25.72423, in 0.009s\n",
      "[15/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.57988, val loss: 25.62790, in 0.005s\n",
      "[16/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.47186, val loss: 25.53141, in 0.009s\n",
      "[17/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.36545, val loss: 25.43913, in 0.023s\n",
      "[18/10000] 1 tree, 31 leaves, max depth = 11, train loss: 40.26650, val loss: 25.34685, in 0.007s\n",
      "[19/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.16317, val loss: 25.25971, in 0.006s\n",
      "[20/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.06020, val loss: 25.17090, in 0.053s\n",
      "[21/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.95259, val loss: 25.07101, in 0.007s\n",
      "[22/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.84503, val loss: 24.97136, in 0.008s\n",
      "[23/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.73929, val loss: 24.87271, in 0.006s\n",
      "[24/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.63065, val loss: 24.78129, in 0.032s\n",
      "[25/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.52306, val loss: 24.69104, in 0.008s\n",
      "[26/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.41731, val loss: 24.60175, in 0.023s\n",
      "[27/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.30544, val loss: 24.50504, in 0.006s\n",
      "[28/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.19476, val loss: 24.40846, in 0.006s\n",
      "[29/10000] 1 tree, 31 leaves, max depth = 9, train loss: 39.08216, val loss: 24.31367, in 0.007s\n",
      "[30/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.97192, val loss: 24.22095, in 0.005s\n",
      "[31/10000] 1 tree, 31 leaves, max depth = 7, train loss: 38.86583, val loss: 24.12908, in 0.023s\n",
      "[32/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.75282, val loss: 24.03215, in 0.007s\n",
      "[33/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.63812, val loss: 23.93578, in 0.005s\n",
      "[34/10000] 1 tree, 31 leaves, max depth = 7, train loss: 38.52744, val loss: 23.83939, in 0.005s\n",
      "[35/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.41029, val loss: 23.74046, in 0.007s\n",
      "[36/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.29699, val loss: 23.64321, in 0.032s\n",
      "[37/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.18281, val loss: 23.54588, in 0.005s\n",
      "[38/10000] 1 tree, 31 leaves, max depth = 9, train loss: 38.07037, val loss: 23.45073, in 0.027s\n",
      "[39/10000] 1 tree, 31 leaves, max depth = 10, train loss: 37.95285, val loss: 23.36251, in 0.005s\n",
      "[40/10000] 1 tree, 31 leaves, max depth = 9, train loss: 37.83614, val loss: 23.27428, in 0.005s\n",
      "[41/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.72037, val loss: 23.18921, in 0.012s\n",
      "[42/10000] 1 tree, 31 leaves, max depth = 9, train loss: 37.60588, val loss: 23.11694, in 0.005s\n",
      "[43/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.50343, val loss: 23.05192, in 0.027s\n",
      "[44/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.39840, val loss: 22.99116, in 0.017s\n",
      "[45/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.27878, val loss: 22.92531, in 0.025s\n",
      "[46/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.15130, val loss: 22.85556, in 0.006s\n",
      "[47/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.02933, val loss: 22.79035, in 0.006s\n",
      "[48/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.90851, val loss: 22.72322, in 0.008s\n",
      "[49/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.79734, val loss: 22.64823, in 0.039s\n",
      "[50/10000] 1 tree, 31 leaves, max depth = 9, train loss: 36.67928, val loss: 22.57056, in 0.005s\n",
      "[51/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.56170, val loss: 22.49796, in 0.005s\n",
      "[52/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.44086, val loss: 22.42760, in 0.097s\n",
      "[53/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.32659, val loss: 22.35677, in 0.006s\n",
      "[54/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.20970, val loss: 22.28785, in 0.006s\n",
      "[55/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.08606, val loss: 22.21199, in 0.008s\n",
      "[56/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.96031, val loss: 22.14374, in 0.026s\n",
      "[57/10000] 1 tree, 31 leaves, max depth = 9, train loss: 35.84428, val loss: 22.06703, in 0.006s\n",
      "[58/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.72862, val loss: 21.99014, in 0.008s\n",
      "[59/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.60303, val loss: 21.90931, in 0.006s\n",
      "[60/10000] 1 tree, 31 leaves, max depth = 9, train loss: 35.48311, val loss: 21.83276, in 0.005s\n",
      "[61/10000] 1 tree, 31 leaves, max depth = 9, train loss: 35.36610, val loss: 21.76443, in 0.041s\n",
      "[62/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.24058, val loss: 21.69218, in 0.037s\n",
      "[63/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.11803, val loss: 21.62771, in 0.009s\n",
      "[64/10000] 1 tree, 31 leaves, max depth = 9, train loss: 34.99699, val loss: 21.54503, in 0.021s\n",
      "[65/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.86374, val loss: 21.46078, in 0.017s\n",
      "[66/10000] 1 tree, 31 leaves, max depth = 11, train loss: 34.73116, val loss: 21.37268, in 0.006s\n",
      "[67/10000] 1 tree, 31 leaves, max depth = 9, train loss: 34.60305, val loss: 21.29026, in 0.006s\n",
      "[68/10000] 1 tree, 31 leaves, max depth = 7, train loss: 34.47200, val loss: 21.22108, in 0.005s\n",
      "[69/10000] 1 tree, 31 leaves, max depth = 11, train loss: 34.34314, val loss: 21.14937, in 0.008s\n",
      "[70/10000] 1 tree, 31 leaves, max depth = 7, train loss: 34.21690, val loss: 21.08073, in 0.029s\n",
      "[71/10000] 1 tree, 31 leaves, max depth = 10, train loss: 34.09756, val loss: 21.00473, in 0.028s\n",
      "[72/10000] 1 tree, 31 leaves, max depth = 10, train loss: 33.96996, val loss: 20.93461, in 0.006s\n",
      "[73/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.85746, val loss: 20.86251, in 0.006s\n",
      "[74/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.74376, val loss: 20.78751, in 0.009s\n",
      "[75/10000] 1 tree, 31 leaves, max depth = 10, train loss: 33.62085, val loss: 20.71609, in 0.027s\n",
      "[76/10000] 1 tree, 31 leaves, max depth = 10, train loss: 33.51172, val loss: 20.65804, in 0.006s\n",
      "[77/10000] 1 tree, 31 leaves, max depth = 9, train loss: 33.38254, val loss: 20.58826, in 0.005s\n",
      "[78/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.25443, val loss: 20.51992, in 0.008s\n",
      "[79/10000] 1 tree, 31 leaves, max depth = 9, train loss: 33.12951, val loss: 20.45082, in 0.007s\n",
      "[80/10000] 1 tree, 31 leaves, max depth = 9, train loss: 33.00603, val loss: 20.38359, in 0.005s\n",
      "[81/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.88294, val loss: 20.31633, in 0.008s\n",
      "[82/10000] 1 tree, 31 leaves, max depth = 9, train loss: 32.75952, val loss: 20.24357, in 0.023s\n",
      "[83/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.64687, val loss: 20.18500, in 0.007s\n",
      "[84/10000] 1 tree, 31 leaves, max depth = 9, train loss: 32.50876, val loss: 20.10895, in 0.009s\n",
      "[85/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.37351, val loss: 20.03565, in 0.006s\n",
      "[86/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.25409, val loss: 19.93916, in 0.024s\n",
      "[87/10000] 1 tree, 31 leaves, max depth = 10, train loss: 32.14091, val loss: 19.87518, in 0.005s\n",
      "[88/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.03042, val loss: 19.81203, in 0.005s\n",
      "[89/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.90029, val loss: 19.77117, in 0.008s\n",
      "[90/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.77798, val loss: 19.70639, in 0.012s\n",
      "[91/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.65172, val loss: 19.64855, in 0.108s\n",
      "[92/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.52845, val loss: 19.60699, in 0.007s\n",
      "[93/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.40488, val loss: 19.56566, in 0.006s\n",
      "[94/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.28430, val loss: 19.52314, in 0.008s\n",
      "[95/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.16620, val loss: 19.48474, in 0.032s\n",
      "[96/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.05617, val loss: 19.44286, in 0.006s\n",
      "[97/10000] 1 tree, 31 leaves, max depth = 9, train loss: 30.93358, val loss: 19.40469, in 0.007s\n",
      "[98/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.82242, val loss: 19.36344, in 0.040s\n",
      "[99/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.71182, val loss: 19.31119, in 0.117s\n",
      "[100/10000] 1 tree, 31 leaves, max depth = 11, train loss: 30.60328, val loss: 19.27092, in 0.006s\n",
      "[101/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.48245, val loss: 19.21017, in 0.006s\n",
      "[102/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.34885, val loss: 19.16716, in 0.047s\n",
      "[103/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.22890, val loss: 19.10636, in 0.011s\n",
      "[104/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.10724, val loss: 19.04111, in 0.006s\n",
      "[105/10000] 1 tree, 31 leaves, max depth = 9, train loss: 29.98673, val loss: 18.97472, in 0.027s\n",
      "[106/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.87158, val loss: 18.91926, in 0.008s\n",
      "[107/10000] 1 tree, 31 leaves, max depth = 7, train loss: 29.74923, val loss: 18.87287, in 0.006s\n",
      "[108/10000] 1 tree, 31 leaves, max depth = 9, train loss: 29.62935, val loss: 18.81734, in 0.050s\n",
      "[109/10000] 1 tree, 31 leaves, max depth = 10, train loss: 29.54495, val loss: 18.77848, in 0.033s\n",
      "[110/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.42528, val loss: 18.73966, in 0.006s\n",
      "[111/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.31873, val loss: 18.70549, in 0.059s\n",
      "[112/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.21691, val loss: 18.67455, in 0.010s\n",
      "[113/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.10748, val loss: 18.63676, in 0.006s\n",
      "[114/10000] 1 tree, 31 leaves, max depth = 10, train loss: 28.99779, val loss: 18.59733, in 0.005s\n",
      "[115/10000] 1 tree, 31 leaves, max depth = 12, train loss: 28.88614, val loss: 18.56233, in 0.020s\n",
      "[116/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.78035, val loss: 18.52481, in 0.008s\n",
      "[117/10000] 1 tree, 31 leaves, max depth = 10, train loss: 28.67588, val loss: 18.48732, in 0.006s\n",
      "[118/10000] 1 tree, 31 leaves, max depth = 10, train loss: 28.58159, val loss: 18.46039, in 0.005s\n",
      "[119/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.49014, val loss: 18.43345, in 0.035s\n",
      "[120/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.39496, val loss: 18.38736, in 0.008s\n",
      "[121/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.29282, val loss: 18.34832, in 0.113s\n",
      "[122/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.19580, val loss: 18.31376, in 0.009s\n",
      "[123/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.09894, val loss: 18.25726, in 0.006s\n",
      "[124/10000] 1 tree, 31 leaves, max depth = 10, train loss: 28.01947, val loss: 18.22993, in 0.005s\n",
      "[125/10000] 1 tree, 31 leaves, max depth = 7, train loss: 27.94705, val loss: 18.19707, in 0.023s\n",
      "[126/10000] 1 tree, 31 leaves, max depth = 7, train loss: 27.86262, val loss: 18.15683, in 0.006s\n",
      "[127/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.78595, val loss: 18.13083, in 0.006s\n",
      "[128/10000] 1 tree, 31 leaves, max depth = 10, train loss: 27.69757, val loss: 18.08769, in 0.009s\n",
      "[129/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.61152, val loss: 18.04665, in 0.006s\n",
      "[130/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.54550, val loss: 18.01649, in 0.046s\n",
      "[131/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.44826, val loss: 17.99736, in 0.006s\n",
      "[132/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.35002, val loss: 17.96137, in 0.005s\n",
      "[133/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.26029, val loss: 17.93889, in 0.037s\n",
      "[134/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.17042, val loss: 17.92204, in 0.009s\n",
      "[135/10000] 1 tree, 31 leaves, max depth = 10, train loss: 27.08999, val loss: 17.88647, in 0.059s\n",
      "[136/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.01142, val loss: 17.85145, in 0.006s\n",
      "[137/10000] 1 tree, 31 leaves, max depth = 10, train loss: 26.93192, val loss: 17.82248, in 0.021s\n",
      "[138/10000] 1 tree, 31 leaves, max depth = 10, train loss: 26.85455, val loss: 17.79346, in 0.008s\n",
      "[139/10000] 1 tree, 31 leaves, max depth = 13, train loss: 26.77482, val loss: 17.74701, in 0.006s\n",
      "[140/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.69208, val loss: 17.73156, in 0.368s\n",
      "[141/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.61154, val loss: 17.71985, in 0.007s\n",
      "[142/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.54060, val loss: 17.69154, in 0.013s\n",
      "[143/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.47103, val loss: 17.66309, in 0.060s\n",
      "[144/10000] 1 tree, 31 leaves, max depth = 10, train loss: 26.40578, val loss: 17.62751, in 0.011s\n",
      "[145/10000] 1 tree, 31 leaves, max depth = 10, train loss: 26.33333, val loss: 17.59737, in 0.006s\n",
      "[146/10000] 1 tree, 31 leaves, max depth = 7, train loss: 26.27200, val loss: 17.57655, in 0.025s\n",
      "[147/10000] 1 tree, 31 leaves, max depth = 11, train loss: 26.20526, val loss: 17.54727, in 0.008s\n",
      "[148/10000] 1 tree, 31 leaves, max depth = 7, train loss: 26.14505, val loss: 17.52156, in 0.010s\n",
      "[149/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.07456, val loss: 17.51245, in 0.009s\n",
      "[150/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.01858, val loss: 17.49243, in 0.155s\n",
      "[151/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.95379, val loss: 17.43431, in 0.016s\n",
      "[152/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.88504, val loss: 17.40925, in 0.039s\n",
      "[153/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.82742, val loss: 17.38421, in 0.006s\n",
      "[154/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.76018, val loss: 17.36683, in 0.005s\n",
      "[155/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.70103, val loss: 17.34083, in 0.006s\n",
      "[156/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.62717, val loss: 17.32425, in 0.012s\n",
      "[157/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.56532, val loss: 17.29638, in 0.029s\n",
      "[158/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.50688, val loss: 17.26325, in 0.009s\n",
      "[159/10000] 1 tree, 31 leaves, max depth = 7, train loss: 25.45327, val loss: 17.25485, in 0.018s\n",
      "[160/10000] 1 tree, 31 leaves, max depth = 11, train loss: 25.38950, val loss: 17.24631, in 0.006s\n",
      "[161/10000] 1 tree, 31 leaves, max depth = 11, train loss: 25.32802, val loss: 17.23756, in 0.005s\n",
      "[162/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.27401, val loss: 17.19560, in 0.022s\n",
      "[163/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.21610, val loss: 17.18608, in 0.005s\n",
      "[164/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.16988, val loss: 17.17342, in 0.009s\n",
      "[165/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.12061, val loss: 17.13895, in 0.005s\n",
      "[166/10000] 1 tree, 31 leaves, max depth = 11, train loss: 25.06837, val loss: 17.09696, in 0.005s\n",
      "[167/10000] 1 tree, 31 leaves, max depth = 14, train loss: 25.02214, val loss: 17.06773, in 0.024s\n",
      "[168/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.97651, val loss: 17.04680, in 0.009s\n",
      "[169/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.92794, val loss: 17.01364, in 0.006s\n",
      "[170/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.88361, val loss: 16.99236, in 0.006s\n",
      "[171/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.85604, val loss: 16.96919, in 0.026s\n",
      "[172/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.80904, val loss: 16.92887, in 0.005s\n",
      "[173/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.76146, val loss: 16.89035, in 0.009s\n",
      "[174/10000] 1 tree, 31 leaves, max depth = 11, train loss: 24.71797, val loss: 16.87098, in 0.005s\n",
      "[175/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.67369, val loss: 16.83387, in 0.005s\n",
      "[176/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.62540, val loss: 16.80530, in 0.064s\n",
      "[177/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.58685, val loss: 16.77242, in 0.052s\n",
      "[178/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.54865, val loss: 16.74044, in 0.005s\n",
      "[179/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.51201, val loss: 16.70900, in 0.009s\n",
      "[180/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.48164, val loss: 16.69403, in 0.005s\n",
      "[181/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.44396, val loss: 16.65821, in 0.005s\n",
      "[182/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.40865, val loss: 16.63810, in 0.037s\n",
      "[183/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.36548, val loss: 16.59420, in 0.005s\n",
      "[184/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.33213, val loss: 16.56240, in 0.010s\n",
      "[185/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.30524, val loss: 16.55785, in 0.094s\n",
      "[186/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.27064, val loss: 16.52571, in 0.005s\n",
      "[187/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.23498, val loss: 16.49658, in 0.005s\n",
      "[188/10000] 1 tree, 31 leaves, max depth = 11, train loss: 24.20169, val loss: 16.46179, in 0.009s\n",
      "[189/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.15651, val loss: 16.45426, in 0.033s\n",
      "[190/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.11243, val loss: 16.44350, in 0.006s\n",
      "[191/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.07183, val loss: 16.43397, in 0.005s\n",
      "[192/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.02711, val loss: 16.42136, in 0.005s\n",
      "[193/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.99591, val loss: 16.41081, in 0.008s\n",
      "[194/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.96438, val loss: 16.38413, in 0.005s\n",
      "[195/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.92867, val loss: 16.36200, in 0.034s\n",
      "[196/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.86336, val loss: 16.34691, in 0.021s\n",
      "[197/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.79869, val loss: 16.33206, in 0.007s\n",
      "[198/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.73493, val loss: 16.31717, in 0.006s\n",
      "[199/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.70168, val loss: 16.29605, in 0.007s\n",
      "[200/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.66399, val loss: 16.25643, in 0.031s\n",
      "[201/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.62942, val loss: 16.21777, in 0.006s\n",
      "[202/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.59284, val loss: 16.18079, in 0.009s\n",
      "[203/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.55677, val loss: 16.14316, in 0.006s\n",
      "[204/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.52302, val loss: 16.10734, in 0.021s\n",
      "[205/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.48954, val loss: 16.07225, in 0.005s\n",
      "[206/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.47781, val loss: 16.06417, in 0.011s\n",
      "[207/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.44797, val loss: 16.04623, in 0.005s\n",
      "[208/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.41385, val loss: 16.02336, in 0.089s\n",
      "[209/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.35745, val loss: 16.00972, in 0.009s\n",
      "[210/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.34677, val loss: 16.00136, in 0.006s\n",
      "[211/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.33361, val loss: 15.99558, in 0.005s\n",
      "[212/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.30376, val loss: 15.95474, in 0.055s\n",
      "[213/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.29068, val loss: 15.95037, in 0.024s\n",
      "[214/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.26503, val loss: 15.92800, in 0.005s\n",
      "[215/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.24974, val loss: 15.91285, in 0.015s\n",
      "[216/10000] 1 tree, 31 leaves, max depth = 7, train loss: 23.23481, val loss: 15.89790, in 0.005s\n",
      "[217/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.21200, val loss: 15.87553, in 0.091s\n",
      "[218/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.18864, val loss: 15.85451, in 0.006s\n",
      "[219/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.16619, val loss: 15.83206, in 0.005s\n",
      "[220/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.14035, val loss: 15.80592, in 0.006s\n",
      "[221/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.10902, val loss: 15.80098, in 0.007s\n",
      "[222/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.09777, val loss: 15.79619, in 0.005s\n",
      "[223/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.06537, val loss: 15.79190, in 0.113s\n",
      "[224/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.03442, val loss: 15.78668, in 0.005s\n",
      "[225/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.00992, val loss: 15.75879, in 0.007s\n",
      "[226/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.98169, val loss: 15.73106, in 0.005s\n",
      "[227/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.97116, val loss: 15.72592, in 0.005s\n",
      "[228/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.94740, val loss: 15.69973, in 0.005s\n",
      "[229/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.93686, val loss: 15.69424, in 0.025s\n",
      "[230/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.90950, val loss: 15.66323, in 0.006s\n",
      "[231/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.88408, val loss: 15.63247, in 0.005s\n",
      "[232/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.86569, val loss: 15.61046, in 0.009s\n",
      "[233/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.84882, val loss: 15.60812, in 0.053s\n",
      "[234/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.83847, val loss: 15.59161, in 0.134s\n",
      "[235/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.78960, val loss: 15.58229, in 0.007s\n",
      "[236/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.74197, val loss: 15.57276, in 0.005s\n",
      "[237/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.69459, val loss: 15.56336, in 0.007s\n",
      "[238/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.67413, val loss: 15.54022, in 0.111s\n",
      "[239/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.62929, val loss: 15.53137, in 0.009s\n",
      "[240/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.60886, val loss: 15.50274, in 0.007s\n",
      "[241/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.58864, val loss: 15.47420, in 0.020s\n",
      "[242/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.56848, val loss: 15.44639, in 0.005s\n",
      "[243/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.54857, val loss: 15.41906, in 0.007s\n",
      "[244/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.53968, val loss: 15.41450, in 0.009s\n",
      "[245/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.53095, val loss: 15.41048, in 0.013s\n",
      "[246/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.52288, val loss: 15.40205, in 0.027s\n",
      "[247/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.51320, val loss: 15.38763, in 0.006s\n",
      "[248/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.50198, val loss: 15.37451, in 0.006s\n",
      "[249/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.48461, val loss: 15.35095, in 0.011s\n",
      "[250/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.46805, val loss: 15.32629, in 0.068s\n",
      "[251/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.44532, val loss: 15.30371, in 0.007s\n",
      "[252/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.42855, val loss: 15.28173, in 0.012s\n",
      "[253/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.38572, val loss: 15.27441, in 0.027s\n",
      "[254/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.35765, val loss: 15.22994, in 0.005s\n",
      "[255/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.33341, val loss: 15.22793, in 0.005s\n",
      "[256/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31725, val loss: 15.20557, in 0.009s\n",
      "[257/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.30138, val loss: 15.18344, in 0.005s\n",
      "[258/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.27587, val loss: 15.17965, in 0.006s\n",
      "[259/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.25189, val loss: 15.17751, in 0.015s\n",
      "[260/10000] 1 tree, 31 leaves, max depth = 13, train loss: 22.22887, val loss: 15.17518, in 0.086s\n",
      "[261/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.21906, val loss: 15.16064, in 0.006s\n",
      "[262/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.20560, val loss: 15.14426, in 0.005s\n",
      "[263/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.19329, val loss: 15.12831, in 0.008s\n",
      "[264/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.17406, val loss: 15.11191, in 0.028s\n",
      "[265/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.16166, val loss: 15.09506, in 0.006s\n",
      "[266/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.14405, val loss: 15.07920, in 0.005s\n",
      "[267/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.13018, val loss: 15.05922, in 0.005s\n",
      "[268/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.11685, val loss: 15.03945, in 0.033s\n",
      "[269/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.10401, val loss: 15.02165, in 0.007s\n",
      "[270/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.09251, val loss: 15.00600, in 0.005s\n",
      "[271/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.07673, val loss: 15.00303, in 0.005s\n",
      "[272/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.06250, val loss: 14.98437, in 0.026s\n",
      "[273/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.04697, val loss: 14.98005, in 0.009s\n",
      "[274/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.02181, val loss: 14.97377, in 0.006s\n",
      "[275/10000] 1 tree, 31 leaves, max depth = 13, train loss: 22.00991, val loss: 14.96003, in 0.006s\n",
      "[276/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.99889, val loss: 14.95170, in 0.061s\n",
      "[277/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.98792, val loss: 14.94363, in 0.129s\n",
      "[278/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.97732, val loss: 14.93580, in 0.007s\n",
      "[279/10000] 1 tree, 31 leaves, max depth = 13, train loss: 21.96442, val loss: 14.92539, in 0.006s\n",
      "[280/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.94579, val loss: 14.89421, in 0.032s\n",
      "[281/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.92790, val loss: 14.85918, in 0.005s\n",
      "[282/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.90934, val loss: 14.82467, in 0.052s\n",
      "[283/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.89176, val loss: 14.79040, in 0.006s\n",
      "[284/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.87206, val loss: 14.76046, in 0.006s\n",
      "[285/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.84505, val loss: 14.75341, in 0.049s\n",
      "[286/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.82769, val loss: 14.72388, in 0.007s\n",
      "[287/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.80091, val loss: 14.71669, in 0.006s\n",
      "[288/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.77483, val loss: 14.70960, in 0.036s\n",
      "[289/10000] 1 tree, 31 leaves, max depth = 12, train loss: 21.76341, val loss: 14.70114, in 0.006s\n",
      "[290/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.73955, val loss: 14.69421, in 0.007s\n",
      "[291/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.71686, val loss: 14.68736, in 0.005s\n",
      "[292/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.70283, val loss: 14.68223, in 0.027s\n",
      "[293/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.69282, val loss: 14.67800, in 0.007s\n",
      "[294/10000] 1 tree, 31 leaves, max depth = 13, train loss: 21.67539, val loss: 14.65631, in 0.005s\n",
      "[295/10000] 1 tree, 31 leaves, max depth = 13, train loss: 21.66394, val loss: 14.65338, in 0.008s\n",
      "[296/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.65495, val loss: 14.64259, in 0.027s\n",
      "[297/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.64661, val loss: 14.63158, in 0.066s\n",
      "[298/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.63841, val loss: 14.63056, in 0.040s\n",
      "[299/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.62297, val loss: 14.61960, in 0.008s\n",
      "[300/10000] 1 tree, 31 leaves, max depth = 12, train loss: 21.61231, val loss: 14.61243, in 0.005s\n",
      "[301/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.59718, val loss: 14.60740, in 0.005s\n",
      "[302/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.58519, val loss: 14.57861, in 0.032s\n",
      "[303/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.57436, val loss: 14.57363, in 0.005s\n",
      "[304/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.56234, val loss: 14.54385, in 0.005s\n",
      "[305/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.55068, val loss: 14.51586, in 0.027s\n",
      "[306/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.53914, val loss: 14.48815, in 0.007s\n",
      "[307/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.52767, val loss: 14.45981, in 0.005s\n",
      "[308/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.51659, val loss: 14.43261, in 0.008s\n",
      "[309/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.50532, val loss: 14.40560, in 0.026s\n",
      "[310/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.49327, val loss: 14.37921, in 0.013s\n",
      "[311/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.48219, val loss: 14.35295, in 0.045s\n",
      "[312/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.47125, val loss: 14.32697, in 0.010s\n",
      "[313/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.46040, val loss: 14.30113, in 0.006s\n",
      "[314/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.45014, val loss: 14.29269, in 0.079s\n",
      "[315/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.43911, val loss: 14.26746, in 0.009s\n",
      "[316/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.42859, val loss: 14.24248, in 0.006s\n",
      "[317/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.41814, val loss: 14.21759, in 0.050s\n",
      "[318/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.40213, val loss: 14.19319, in 0.006s\n",
      "[319/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.39086, val loss: 14.16883, in 0.005s\n",
      "[320/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.37859, val loss: 14.14478, in 0.007s\n",
      "[321/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.36634, val loss: 14.12098, in 0.026s\n",
      "[322/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.35652, val loss: 14.11414, in 0.006s\n",
      "[323/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.34506, val loss: 14.09068, in 0.005s\n",
      "[324/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.33484, val loss: 14.06735, in 0.005s\n",
      "[325/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.32273, val loss: 14.06187, in 0.035s\n",
      "[326/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.31181, val loss: 14.03891, in 0.006s\n",
      "[327/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.29860, val loss: 14.02714, in 0.008s\n",
      "[328/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.28938, val loss: 14.02051, in 0.005s\n",
      "[329/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.27635, val loss: 14.00892, in 0.022s\n",
      "[330/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.24723, val loss: 14.00116, in 0.009s\n",
      "[331/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.22030, val loss: 13.99177, in 0.012s\n",
      "[332/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.20697, val loss: 13.96555, in 0.029s\n",
      "[333/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.19921, val loss: 13.95421, in 0.006s\n",
      "[334/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.19126, val loss: 13.94071, in 0.009s\n",
      "[335/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.18419, val loss: 13.92930, in 0.037s\n",
      "[336/10000] 1 tree, 31 leaves, max depth = 12, train loss: 21.17427, val loss: 13.92865, in 0.009s\n",
      "[337/10000] 1 tree, 31 leaves, max depth = 13, train loss: 21.17195, val loss: 13.92775, in 0.005s\n",
      "[338/10000] 1 tree, 31 leaves, max depth = 13, train loss: 21.17033, val loss: 13.92734, in 0.005s\n",
      "[339/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.15696, val loss: 13.89289, in 0.020s\n",
      "[340/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.14397, val loss: 13.85914, in 0.077s\n",
      "[341/10000] 1 tree, 31 leaves, max depth = 12, train loss: 21.13089, val loss: 13.82536, in 0.061s\n",
      "[342/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.11977, val loss: 13.79216, in 0.006s\n",
      "[343/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.10708, val loss: 13.75932, in 0.015s\n",
      "[344/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.09855, val loss: 13.74848, in 0.071s\n",
      "[345/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.09201, val loss: 13.73738, in 0.007s\n",
      "[346/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.08457, val loss: 13.73305, in 0.011s\n",
      "[347/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.07816, val loss: 13.72261, in 0.042s\n",
      "[348/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.07154, val loss: 13.71137, in 0.009s\n",
      "[349/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.06499, val loss: 13.70024, in 0.060s\n",
      "[350/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.05877, val loss: 13.69012, in 0.220s\n",
      "[351/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.05237, val loss: 13.67909, in 0.017s\n",
      "[352/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.02964, val loss: 13.67425, in 0.031s\n",
      "[353/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.01975, val loss: 13.67023, in 0.013s\n",
      "[354/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.01488, val loss: 13.66552, in 0.007s\n",
      "[355/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.00991, val loss: 13.66041, in 0.034s\n",
      "[356/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.00485, val loss: 13.65510, in 0.018s\n",
      "[357/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.99525, val loss: 13.64512, in 0.028s\n",
      "[358/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.98434, val loss: 13.61293, in 0.007s\n",
      "[359/10000] 1 tree, 31 leaves, max depth = 13, train loss: 20.97917, val loss: 13.61428, in 0.006s\n",
      "[360/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.97040, val loss: 13.60706, in 0.029s\n",
      "[361/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.96632, val loss: 13.60286, in 0.007s\n",
      "[362/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.96111, val loss: 13.59344, in 0.005s\n",
      "[363/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.95596, val loss: 13.58413, in 0.005s\n",
      "[364/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.95086, val loss: 13.57492, in 0.034s\n",
      "[365/10000] 1 tree, 31 leaves, max depth = 13, train loss: 20.94587, val loss: 13.57624, in 0.019s\n",
      "[366/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.94083, val loss: 13.56713, in 0.025s\n",
      "[367/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.93585, val loss: 13.55811, in 0.010s\n",
      "[368/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.93324, val loss: 13.55745, in 0.036s\n",
      "[369/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.92780, val loss: 13.55016, in 0.033s\n",
      "[370/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.92211, val loss: 13.54024, in 0.006s\n",
      "[371/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.91013, val loss: 13.50967, in 0.005s\n",
      "[372/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.89885, val loss: 13.47941, in 0.063s\n",
      "[373/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.88399, val loss: 13.47866, in 0.037s\n",
      "[374/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.88163, val loss: 13.48213, in 0.010s\n",
      "[375/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.88061, val loss: 13.48087, in 0.006s\n",
      "[376/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.87744, val loss: 13.48373, in 0.066s\n",
      "[377/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.87666, val loss: 13.48269, in 0.019s\n",
      "[378/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.87489, val loss: 13.47969, in 0.005s\n",
      "[379/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.86955, val loss: 13.48620, in 0.090s\n",
      "[380/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.86391, val loss: 13.48066, in 0.006s\n",
      "[381/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.86221, val loss: 13.47791, in 0.005s\n",
      "[382/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.85591, val loss: 13.46824, in 0.005s\n",
      "[383/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.84903, val loss: 13.46774, in 0.030s\n",
      "[384/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.84224, val loss: 13.46728, in 0.006s\n",
      "[385/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.83551, val loss: 13.46694, in 0.006s\n",
      "[386/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.82884, val loss: 13.46654, in 0.008s\n",
      "[387/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.82224, val loss: 13.46613, in 0.005s\n",
      "[388/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.81570, val loss: 13.46570, in 0.037s\n",
      "[389/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.80921, val loss: 13.46518, in 0.006s\n",
      "[390/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.80279, val loss: 13.46471, in 0.008s\n",
      "[391/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.79643, val loss: 13.46421, in 0.025s\n",
      "[392/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.79052, val loss: 13.46379, in 0.006s\n",
      "[393/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.78008, val loss: 13.43518, in 0.005s\n",
      "[394/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.76975, val loss: 13.40701, in 0.035s\n",
      "[395/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.76191, val loss: 13.37911, in 0.006s\n",
      "[396/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.75176, val loss: 13.35135, in 0.006s\n",
      "[397/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.73489, val loss: 13.35095, in 0.033s\n",
      "[398/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.72496, val loss: 13.32377, in 0.005s\n",
      "[399/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.71743, val loss: 13.29689, in 0.008s\n",
      "[400/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.70766, val loss: 13.27034, in 0.087s\n",
      "[401/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.70027, val loss: 13.24396, in 0.006s\n",
      "[402/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.69067, val loss: 13.21789, in 0.006s\n",
      "[403/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.68118, val loss: 13.19209, in 0.033s\n",
      "[404/10000] 1 tree, 31 leaves, max depth = 12, train loss: 20.67402, val loss: 13.16652, in 0.006s\n",
      "[405/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.67208, val loss: 13.16639, in 0.008s\n",
      "[406/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.66276, val loss: 13.14114, in 0.005s\n",
      "[407/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.65570, val loss: 13.11619, in 0.005s\n",
      "[408/10000] 1 tree, 31 leaves, max depth = 7, train loss: 20.65372, val loss: 13.11582, in 0.068s\n",
      "[409/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.64614, val loss: 13.09112, in 0.005s\n",
      "[410/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.63973, val loss: 13.06666, in 0.006s\n",
      "[411/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.63395, val loss: 13.06628, in 0.036s\n",
      "[412/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.62823, val loss: 13.06591, in 0.005s\n",
      "[413/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.62258, val loss: 13.06546, in 0.057s\n",
      "[414/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.62168, val loss: 13.06439, in 0.010s\n",
      "[415/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.60509, val loss: 13.06396, in 0.006s\n",
      "[416/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.60347, val loss: 13.06293, in 0.072s\n",
      "[417/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.60307, val loss: 13.06181, in 0.034s\n",
      "[418/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.60267, val loss: 13.06077, in 0.027s\n",
      "[419/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.58860, val loss: 13.06045, in 0.005s\n",
      "[420/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.58834, val loss: 13.06006, in 0.006s\n",
      "[421/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.58665, val loss: 13.06106, in 0.014s\n",
      "[422/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.57266, val loss: 13.06076, in 0.029s\n",
      "[423/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.55879, val loss: 13.06037, in 0.005s\n",
      "[424/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.55782, val loss: 13.05877, in 0.016s\n",
      "[425/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.55758, val loss: 13.05859, in 0.025s\n",
      "[426/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.55724, val loss: 13.05759, in 0.005s\n",
      "[427/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.55690, val loss: 13.05653, in 0.005s\n",
      "[428/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.55668, val loss: 13.05639, in 0.005s\n",
      "[429/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.55646, val loss: 13.05616, in 0.029s\n",
      "[430/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.55624, val loss: 13.05597, in 0.006s\n",
      "[431/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.55603, val loss: 13.05574, in 0.005s\n",
      "[432/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.55224, val loss: 13.05553, in 0.009s\n",
      "[433/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.54850, val loss: 13.05532, in 0.005s\n",
      "[434/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.54829, val loss: 13.05503, in 0.005s\n",
      "[435/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.54458, val loss: 13.05482, in 0.033s\n",
      "[436/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.54091, val loss: 13.05462, in 0.027s\n",
      "[437/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.53727, val loss: 13.05448, in 0.007s\n",
      "[438/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.53708, val loss: 13.05420, in 0.006s\n",
      "[439/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.53688, val loss: 13.05405, in 0.005s\n",
      "[440/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.53669, val loss: 13.05391, in 0.024s\n",
      "[441/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.52344, val loss: 13.05381, in 0.005s\n",
      "[442/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.50516, val loss: 13.05363, in 0.011s\n",
      "[443/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.48707, val loss: 13.05346, in 0.007s\n",
      "[444/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.46919, val loss: 13.05329, in 0.071s\n",
      "[445/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.45146, val loss: 13.05313, in 0.084s\n",
      "[446/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.43390, val loss: 13.05296, in 0.007s\n",
      "[447/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.41656, val loss: 13.05280, in 0.005s\n",
      "[448/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.39962, val loss: 13.05263, in 0.005s\n",
      "[449/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.39913, val loss: 13.05172, in 0.025s\n",
      "[450/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.39875, val loss: 13.05155, in 0.011s\n",
      "[451/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.39859, val loss: 13.05135, in 0.040s\n",
      "[452/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.39831, val loss: 13.05035, in 0.007s\n",
      "[453/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.39815, val loss: 13.05015, in 0.017s\n",
      "[454/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39799, val loss: 13.04996, in 0.034s\n",
      "[455/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39783, val loss: 13.04978, in 0.005s\n",
      "[456/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39768, val loss: 13.04959, in 0.024s\n",
      "[457/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39752, val loss: 13.04941, in 0.005s\n",
      "[458/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.39737, val loss: 13.04924, in 0.010s\n",
      "[459/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39722, val loss: 13.04905, in 0.005s\n",
      "[460/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39707, val loss: 13.04892, in 0.005s\n",
      "[461/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39693, val loss: 13.04875, in 0.022s\n",
      "[462/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.39678, val loss: 13.04851, in 0.005s\n",
      "[463/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39663, val loss: 13.04834, in 0.012s\n",
      "[464/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39650, val loss: 13.04818, in 0.005s\n",
      "[465/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.39626, val loss: 13.04724, in 0.023s\n",
      "[466/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39613, val loss: 13.04706, in 0.007s\n",
      "[467/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39599, val loss: 13.04689, in 0.006s\n",
      "[468/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39586, val loss: 13.04672, in 0.006s\n",
      "[469/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39572, val loss: 13.04655, in 0.033s\n",
      "[470/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39559, val loss: 13.04639, in 0.005s\n",
      "[471/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39546, val loss: 13.04622, in 0.005s\n",
      "[472/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39534, val loss: 13.04607, in 0.008s\n",
      "[473/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39521, val loss: 13.04593, in 0.021s\n",
      "[474/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39509, val loss: 13.04579, in 0.005s\n",
      "[475/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39497, val loss: 13.04565, in 0.047s\n",
      "[476/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.39475, val loss: 13.04473, in 0.005s\n",
      "[477/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.39453, val loss: 13.04382, in 0.009s\n",
      "[478/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.39439, val loss: 13.04348, in 0.006s\n",
      "[479/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.39426, val loss: 13.04335, in 0.026s\n",
      "[480/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.39414, val loss: 13.04322, in 0.005s\n",
      "[481/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.39401, val loss: 13.04308, in 0.005s\n",
      "[482/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.39389, val loss: 13.04295, in 0.010s\n",
      "[483/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.39377, val loss: 13.04281, in 0.006s\n",
      "[484/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.39366, val loss: 13.04267, in 0.005s\n",
      "[485/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.39354, val loss: 13.04254, in 0.022s\n",
      "[486/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.39341, val loss: 13.04253, in 0.005s\n",
      "[487/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.39329, val loss: 13.04240, in 0.010s\n",
      "[488/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.39318, val loss: 13.04227, in 0.006s\n",
      "[489/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.39306, val loss: 13.04216, in 0.005s\n",
      "[490/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.39167, val loss: 13.04171, in 0.069s\n",
      "[491/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.39156, val loss: 13.04146, in 0.006s\n",
      "[492/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.38418, val loss: 13.02099, in 0.006s\n",
      "[493/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.37900, val loss: 13.00045, in 0.077s\n",
      "[494/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.37175, val loss: 12.98038, in 0.070s\n",
      "[495/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.36668, val loss: 12.96025, in 0.006s\n",
      "[496/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.36560, val loss: 12.95721, in 0.006s\n",
      "[497/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.35970, val loss: 12.93739, in 0.033s\n",
      "[498/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.35391, val loss: 12.91778, in 0.005s\n",
      "[499/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.34900, val loss: 12.89836, in 0.006s\n",
      "[500/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.34421, val loss: 12.87914, in 0.008s\n",
      "[501/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.34410, val loss: 12.87914, in 0.005s\n",
      "[502/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.34306, val loss: 12.87629, in 0.005s\n",
      "[503/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.34039, val loss: 12.87615, in 0.086s\n",
      "[504/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.33774, val loss: 12.87602, in 0.075s\n",
      "[505/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.33760, val loss: 12.87590, in 0.007s\n",
      "[506/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.33746, val loss: 12.87579, in 0.006s\n",
      "[507/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.33735, val loss: 12.87566, in 0.005s\n",
      "[508/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.33721, val loss: 12.87554, in 0.093s\n",
      "[509/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.33706, val loss: 12.87542, in 0.009s\n",
      "[510/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.33696, val loss: 12.87530, in 0.006s\n",
      "[511/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.33686, val loss: 12.87530, in 0.006s\n",
      "[512/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.33105, val loss: 12.87519, in 0.027s\n",
      "[513/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.33095, val loss: 12.87519, in 0.005s\n",
      "[514/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.33084, val loss: 12.87521, in 0.007s\n",
      "[515/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.33070, val loss: 12.87498, in 0.008s\n",
      "[516/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.33060, val loss: 12.87498, in 0.051s\n",
      "[517/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.33050, val loss: 12.87498, in 0.012s\n",
      "[518/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.33039, val loss: 12.87500, in 0.006s\n",
      "[519/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.33029, val loss: 12.87501, in 0.015s\n",
      "[520/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.33012, val loss: 12.87540, in 0.005s\n",
      "[521/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.33002, val loss: 12.87541, in 0.011s\n",
      "[522/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.32992, val loss: 12.87542, in 0.006s\n",
      "[523/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.32983, val loss: 12.87544, in 0.005s\n",
      "[524/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.32975, val loss: 12.87539, in 0.024s\n",
      "[525/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.32928, val loss: 12.87459, in 0.006s\n",
      "[526/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.32920, val loss: 12.87452, in 0.005s\n",
      "[527/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.32911, val loss: 12.87444, in 0.007s\n",
      "[528/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.32903, val loss: 12.87437, in 0.007s\n",
      "[529/10000] 1 tree, 31 leaves, max depth = 12, train loss: 20.32896, val loss: 12.87430, in 0.006s\n",
      "[530/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.32888, val loss: 12.87422, in 0.044s\n",
      "[531/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32880, val loss: 12.87415, in 0.009s\n",
      "[532/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.32866, val loss: 12.87390, in 0.006s\n",
      "[533/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.32853, val loss: 12.87365, in 0.076s\n",
      "[534/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.32824, val loss: 12.87263, in 0.016s\n",
      "[535/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.32817, val loss: 12.87256, in 0.037s\n",
      "[536/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.32809, val loss: 12.87249, in 0.007s\n",
      "[537/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.32800, val loss: 12.87236, in 0.108s\n",
      "[538/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.32787, val loss: 12.87211, in 0.006s\n",
      "[539/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.32780, val loss: 12.87204, in 0.005s\n",
      "[540/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32772, val loss: 12.87198, in 0.006s\n",
      "[541/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.32761, val loss: 12.87191, in 0.005s\n",
      "[542/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.32755, val loss: 12.87185, in 0.009s\n",
      "[543/10000] 1 tree, 31 leaves, max depth = 12, train loss: 20.32748, val loss: 12.87176, in 0.029s\n",
      "[544/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.32742, val loss: 12.87168, in 0.006s\n",
      "[545/10000] 1 tree, 31 leaves, max depth = 12, train loss: 20.32733, val loss: 12.87170, in 0.058s\n",
      "[546/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32726, val loss: 12.87161, in 0.060s\n",
      "[547/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.32719, val loss: 12.87152, in 0.006s\n",
      "[548/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.32713, val loss: 12.87143, in 0.005s\n",
      "[549/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32707, val loss: 12.87134, in 0.077s\n",
      "[550/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32700, val loss: 12.87125, in 0.081s\n",
      "[551/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32694, val loss: 12.87116, in 0.007s\n",
      "[552/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32688, val loss: 12.87108, in 0.005s\n",
      "[553/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32682, val loss: 12.87099, in 0.007s\n",
      "[554/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32676, val loss: 12.87091, in 0.038s\n",
      "[555/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32668, val loss: 12.87082, in 0.009s\n",
      "[556/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32662, val loss: 12.87073, in 0.005s\n",
      "[557/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32656, val loss: 12.87065, in 0.061s\n",
      "[558/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32650, val loss: 12.87057, in 0.073s\n",
      "[559/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32644, val loss: 12.87049, in 0.006s\n",
      "[560/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32636, val loss: 12.87040, in 0.005s\n",
      "[561/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32624, val loss: 12.87042, in 0.007s\n",
      "[562/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32617, val loss: 12.87034, in 0.025s\n",
      "[563/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32611, val loss: 12.87026, in 0.005s\n",
      "[564/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32605, val loss: 12.87019, in 0.005s\n",
      "[565/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32596, val loss: 12.87030, in 0.010s\n",
      "[566/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.32588, val loss: 12.87031, in 0.006s\n",
      "[567/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.32582, val loss: 12.87027, in 0.049s\n",
      "[568/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.32575, val loss: 12.87030, in 0.006s\n",
      "[569/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.32567, val loss: 12.87034, in 0.026s\n",
      "[570/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.32560, val loss: 12.87037, in 0.005s\n",
      "[571/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.32553, val loss: 12.87040, in 0.005s\n",
      "[572/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.32547, val loss: 12.87044, in 0.034s\n",
      "[573/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.32533, val loss: 12.87082, in 0.072s\n",
      "[574/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.32527, val loss: 12.87078, in 0.096s\n",
      "Fit 574 trees in 11.525 s, (17794 total leaves)\n",
      "Time spent computing histograms: 2.833s\n",
      "Time spent finding best splits:  1.624s\n",
      "Time spent applying splits:      1.873s\n",
      "Time spent predicting:           0.507s\n",
      "Binning 0.001 GB of training data: 0.012 s\n",
      "Binning 0.000 GB of validation data: 0.001 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/10000] 1 tree, 31 leaves, max depth = 8, train loss: 43.01404, val loss: 23.14040, in 0.025s\n",
      "[2/10000] 1 tree, 31 leaves, max depth = 8, train loss: 42.91370, val loss: 23.04257, in 0.006s\n",
      "[3/10000] 1 tree, 31 leaves, max depth = 9, train loss: 42.81432, val loss: 22.94578, in 0.005s\n",
      "[4/10000] 1 tree, 31 leaves, max depth = 9, train loss: 42.71589, val loss: 22.84982, in 0.015s\n",
      "[5/10000] 1 tree, 31 leaves, max depth = 8, train loss: 42.61830, val loss: 22.75640, in 0.006s\n",
      "[6/10000] 1 tree, 31 leaves, max depth = 8, train loss: 42.52534, val loss: 22.66250, in 0.024s\n",
      "[7/10000] 1 tree, 31 leaves, max depth = 8, train loss: 42.42028, val loss: 22.56587, in 0.013s\n",
      "[8/10000] 1 tree, 31 leaves, max depth = 7, train loss: 42.31641, val loss: 22.46986, in 0.006s\n",
      "[9/10000] 1 tree, 31 leaves, max depth = 8, train loss: 42.21346, val loss: 22.37465, in 0.005s\n",
      "[10/10000] 1 tree, 31 leaves, max depth = 8, train loss: 42.11347, val loss: 22.28164, in 0.068s\n",
      "[11/10000] 1 tree, 31 leaves, max depth = 9, train loss: 42.00781, val loss: 22.18974, in 0.006s\n",
      "[12/10000] 1 tree, 31 leaves, max depth = 10, train loss: 41.90328, val loss: 22.09894, in 0.007s\n",
      "[13/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.79976, val loss: 22.00873, in 0.008s\n",
      "[14/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.69869, val loss: 21.91972, in 0.006s\n",
      "[15/10000] 1 tree, 31 leaves, max depth = 9, train loss: 41.59100, val loss: 21.82091, in 0.028s\n",
      "[16/10000] 1 tree, 31 leaves, max depth = 9, train loss: 41.48514, val loss: 21.72466, in 0.006s\n",
      "[17/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.37975, val loss: 21.62556, in 0.005s\n",
      "[18/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.27610, val loss: 21.52953, in 0.040s\n",
      "[19/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.17357, val loss: 21.43452, in 0.011s\n",
      "[20/10000] 1 tree, 31 leaves, max depth = 9, train loss: 41.07204, val loss: 21.33909, in 0.027s\n",
      "[21/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.96205, val loss: 21.23267, in 0.005s\n",
      "[22/10000] 1 tree, 31 leaves, max depth = 7, train loss: 40.84929, val loss: 21.12609, in 0.005s\n",
      "[23/10000] 1 tree, 31 leaves, max depth = 7, train loss: 40.74259, val loss: 21.02166, in 0.028s\n",
      "[24/10000] 1 tree, 31 leaves, max depth = 9, train loss: 40.63776, val loss: 20.91821, in 0.005s\n",
      "[25/10000] 1 tree, 31 leaves, max depth = 9, train loss: 40.52781, val loss: 20.82029, in 0.027s\n",
      "[26/10000] 1 tree, 31 leaves, max depth = 9, train loss: 40.41998, val loss: 20.72324, in 0.014s\n",
      "[27/10000] 1 tree, 31 leaves, max depth = 9, train loss: 40.30919, val loss: 20.62209, in 0.032s\n",
      "[28/10000] 1 tree, 31 leaves, max depth = 9, train loss: 40.19987, val loss: 20.52183, in 0.016s\n",
      "[29/10000] 1 tree, 31 leaves, max depth = 9, train loss: 40.08604, val loss: 20.42712, in 0.005s\n",
      "[30/10000] 1 tree, 31 leaves, max depth = 9, train loss: 39.97372, val loss: 20.33323, in 0.018s\n",
      "[31/10000] 1 tree, 31 leaves, max depth = 10, train loss: 39.85554, val loss: 20.23599, in 0.039s\n",
      "[32/10000] 1 tree, 31 leaves, max depth = 10, train loss: 39.73861, val loss: 20.13993, in 0.031s\n",
      "[33/10000] 1 tree, 31 leaves, max depth = 10, train loss: 39.62334, val loss: 20.04509, in 0.006s\n",
      "[34/10000] 1 tree, 31 leaves, max depth = 10, train loss: 39.50856, val loss: 19.95117, in 0.005s\n",
      "[35/10000] 1 tree, 31 leaves, max depth = 10, train loss: 39.38955, val loss: 19.85251, in 0.054s\n",
      "[36/10000] 1 tree, 31 leaves, max depth = 10, train loss: 39.27045, val loss: 19.75515, in 0.029s\n",
      "[37/10000] 1 tree, 31 leaves, max depth = 10, train loss: 39.15293, val loss: 19.65883, in 0.006s\n",
      "[38/10000] 1 tree, 31 leaves, max depth = 10, train loss: 39.03718, val loss: 19.56328, in 0.005s\n",
      "[39/10000] 1 tree, 31 leaves, max depth = 9, train loss: 38.91549, val loss: 19.47361, in 0.077s\n",
      "[40/10000] 1 tree, 31 leaves, max depth = 9, train loss: 38.79590, val loss: 19.38419, in 0.060s\n",
      "[41/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.67540, val loss: 19.30618, in 0.008s\n",
      "[42/10000] 1 tree, 31 leaves, max depth = 9, train loss: 38.55108, val loss: 19.23880, in 0.005s\n",
      "[43/10000] 1 tree, 31 leaves, max depth = 9, train loss: 38.43682, val loss: 19.17169, in 0.005s\n",
      "[44/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.31874, val loss: 19.10888, in 0.030s\n",
      "[45/10000] 1 tree, 31 leaves, max depth = 11, train loss: 38.19100, val loss: 19.05271, in 0.006s\n",
      "[46/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.06826, val loss: 18.99714, in 0.009s\n",
      "[47/10000] 1 tree, 31 leaves, max depth = 7, train loss: 37.96137, val loss: 18.93421, in 0.005s\n",
      "[48/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.84704, val loss: 18.86154, in 0.005s\n",
      "[49/10000] 1 tree, 31 leaves, max depth = 9, train loss: 37.73431, val loss: 18.79721, in 0.126s\n",
      "[50/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.62046, val loss: 18.72887, in 0.007s\n",
      "[51/10000] 1 tree, 31 leaves, max depth = 10, train loss: 37.50054, val loss: 18.66175, in 0.006s\n",
      "[52/10000] 1 tree, 31 leaves, max depth = 7, train loss: 37.37866, val loss: 18.59880, in 0.005s\n",
      "[53/10000] 1 tree, 31 leaves, max depth = 7, train loss: 37.25340, val loss: 18.52826, in 0.052s\n",
      "[54/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.12521, val loss: 18.45239, in 0.031s\n",
      "[55/10000] 1 tree, 31 leaves, max depth = 7, train loss: 37.00435, val loss: 18.38774, in 0.006s\n",
      "[56/10000] 1 tree, 31 leaves, max depth = 9, train loss: 36.88048, val loss: 18.31236, in 0.005s\n",
      "[57/10000] 1 tree, 31 leaves, max depth = 11, train loss: 36.75473, val loss: 18.26009, in 0.008s\n",
      "[58/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.62327, val loss: 18.18631, in 0.042s\n",
      "[59/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.48664, val loss: 18.11003, in 0.009s\n",
      "[60/10000] 1 tree, 31 leaves, max depth = 10, train loss: 36.35538, val loss: 18.05125, in 0.128s\n",
      "[61/10000] 1 tree, 31 leaves, max depth = 9, train loss: 36.21813, val loss: 17.98043, in 0.007s\n",
      "[62/10000] 1 tree, 31 leaves, max depth = 10, train loss: 36.09294, val loss: 17.89899, in 0.010s\n",
      "[63/10000] 1 tree, 31 leaves, max depth = 9, train loss: 35.95934, val loss: 17.81761, in 0.044s\n",
      "[64/10000] 1 tree, 31 leaves, max depth = 10, train loss: 35.83060, val loss: 17.76433, in 0.006s\n",
      "[65/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.70507, val loss: 17.70984, in 0.005s\n",
      "[66/10000] 1 tree, 31 leaves, max depth = 9, train loss: 35.57649, val loss: 17.63368, in 0.008s\n",
      "[67/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.45394, val loss: 17.58055, in 0.037s\n",
      "[68/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.33389, val loss: 17.52765, in 0.035s\n",
      "[69/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.20948, val loss: 17.45882, in 0.005s\n",
      "[70/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.08767, val loss: 17.40368, in 0.121s\n",
      "[71/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.96830, val loss: 17.34676, in 0.007s\n",
      "[72/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.84714, val loss: 17.26762, in 0.007s\n",
      "[73/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.71893, val loss: 17.22129, in 0.062s\n",
      "[74/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.60625, val loss: 17.16915, in 0.028s\n",
      "[75/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.47938, val loss: 17.10471, in 0.007s\n",
      "[76/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.35402, val loss: 17.04027, in 0.006s\n",
      "[77/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.23458, val loss: 16.99687, in 0.008s\n",
      "[78/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.11593, val loss: 16.95250, in 0.029s\n",
      "[79/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.99812, val loss: 16.90667, in 0.006s\n",
      "[80/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.88270, val loss: 16.85955, in 0.010s\n",
      "[81/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.78186, val loss: 16.81395, in 0.006s\n",
      "[82/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.67393, val loss: 16.76179, in 0.005s\n",
      "[83/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.56734, val loss: 16.71031, in 0.039s\n",
      "[84/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.45037, val loss: 16.65831, in 0.006s\n",
      "[85/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.32817, val loss: 16.59396, in 0.005s\n",
      "[86/10000] 1 tree, 31 leaves, max depth = 9, train loss: 33.21413, val loss: 16.53184, in 0.029s\n",
      "[87/10000] 1 tree, 31 leaves, max depth = 9, train loss: 33.11509, val loss: 16.48486, in 0.006s\n",
      "[88/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.00599, val loss: 16.42926, in 0.026s\n",
      "[89/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.89301, val loss: 16.37945, in 0.008s\n",
      "[90/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.77467, val loss: 16.33813, in 0.006s\n",
      "[91/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.65847, val loss: 16.29666, in 0.009s\n",
      "[92/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.54541, val loss: 16.25581, in 0.006s\n",
      "[93/10000] 1 tree, 31 leaves, max depth = 9, train loss: 32.42605, val loss: 16.21346, in 0.025s\n",
      "[94/10000] 1 tree, 31 leaves, max depth = 10, train loss: 32.30840, val loss: 16.16552, in 0.006s\n",
      "[95/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.19147, val loss: 16.12765, in 0.007s\n",
      "[96/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.08186, val loss: 16.09742, in 0.005s\n",
      "[97/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.95343, val loss: 16.04692, in 0.050s\n",
      "[98/10000] 1 tree, 31 leaves, max depth = 10, train loss: 31.84791, val loss: 16.00856, in 0.009s\n",
      "[99/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.73903, val loss: 15.97305, in 0.031s\n",
      "[100/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.62904, val loss: 15.93089, in 0.071s\n",
      "[101/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.51595, val loss: 15.89307, in 0.007s\n",
      "[102/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.41240, val loss: 15.85809, in 0.005s\n",
      "[103/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.29176, val loss: 15.80075, in 0.010s\n",
      "[104/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.16778, val loss: 15.75699, in 0.080s\n",
      "[105/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.04819, val loss: 15.71329, in 0.009s\n",
      "[106/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.94572, val loss: 15.67740, in 0.007s\n",
      "[107/10000] 1 tree, 31 leaves, max depth = 9, train loss: 30.84036, val loss: 15.63879, in 0.066s\n",
      "[108/10000] 1 tree, 31 leaves, max depth = 7, train loss: 30.73357, val loss: 15.60019, in 0.027s\n",
      "[109/10000] 1 tree, 31 leaves, max depth = 9, train loss: 30.62763, val loss: 15.56065, in 0.006s\n",
      "[110/10000] 1 tree, 31 leaves, max depth = 10, train loss: 30.52299, val loss: 15.52580, in 0.047s\n",
      "[111/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.44162, val loss: 15.49983, in 0.038s\n",
      "[112/10000] 1 tree, 31 leaves, max depth = 10, train loss: 30.35508, val loss: 15.47094, in 0.005s\n",
      "[113/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.25393, val loss: 15.43514, in 0.078s\n",
      "[114/10000] 1 tree, 31 leaves, max depth = 7, train loss: 30.15577, val loss: 15.40222, in 0.104s\n",
      "[115/10000] 1 tree, 31 leaves, max depth = 9, train loss: 30.05948, val loss: 15.37079, in 0.009s\n",
      "[116/10000] 1 tree, 31 leaves, max depth = 9, train loss: 29.96365, val loss: 15.33781, in 0.005s\n",
      "[117/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.87767, val loss: 15.30953, in 0.005s\n",
      "[118/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.79766, val loss: 15.28414, in 0.036s\n",
      "[119/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.70463, val loss: 15.25328, in 0.006s\n",
      "[120/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.62329, val loss: 15.22354, in 0.081s\n",
      "[121/10000] 1 tree, 31 leaves, max depth = 10, train loss: 29.53092, val loss: 15.19049, in 0.007s\n",
      "[122/10000] 1 tree, 31 leaves, max depth = 10, train loss: 29.44327, val loss: 15.16086, in 0.010s\n",
      "[123/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.34924, val loss: 15.13289, in 0.031s\n",
      "[124/10000] 1 tree, 31 leaves, max depth = 9, train loss: 29.26116, val loss: 15.09419, in 0.009s\n",
      "[125/10000] 1 tree, 31 leaves, max depth = 7, train loss: 29.19056, val loss: 15.06600, in 0.006s\n",
      "[126/10000] 1 tree, 31 leaves, max depth = 7, train loss: 29.10877, val loss: 15.03485, in 0.007s\n",
      "[127/10000] 1 tree, 31 leaves, max depth = 9, train loss: 29.02125, val loss: 14.99235, in 0.009s\n",
      "[128/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.93756, val loss: 14.96198, in 0.007s\n",
      "[129/10000] 1 tree, 31 leaves, max depth = 11, train loss: 28.85566, val loss: 14.92112, in 0.029s\n",
      "[130/10000] 1 tree, 31 leaves, max depth = 7, train loss: 28.79213, val loss: 14.91086, in 0.008s\n",
      "[131/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.71303, val loss: 14.86913, in 0.011s\n",
      "[132/10000] 1 tree, 31 leaves, max depth = 7, train loss: 28.63614, val loss: 14.83934, in 0.006s\n",
      "[133/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.55547, val loss: 14.80804, in 0.031s\n",
      "[134/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.47318, val loss: 14.79105, in 0.074s\n",
      "[135/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.39376, val loss: 14.76101, in 0.082s\n",
      "[136/10000] 1 tree, 31 leaves, max depth = 7, train loss: 28.31581, val loss: 14.73140, in 0.010s\n",
      "[137/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.23892, val loss: 14.70131, in 0.006s\n",
      "[138/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.16831, val loss: 14.67237, in 0.005s\n",
      "[139/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.10134, val loss: 14.63591, in 0.023s\n",
      "[140/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.04428, val loss: 14.61491, in 0.009s\n",
      "[141/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.96792, val loss: 14.58402, in 0.006s\n",
      "[142/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.90329, val loss: 14.55666, in 0.005s\n",
      "[143/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.83438, val loss: 14.52699, in 0.029s\n",
      "[144/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.76014, val loss: 14.49688, in 0.007s\n",
      "[145/10000] 1 tree, 31 leaves, max depth = 10, train loss: 27.69634, val loss: 14.46782, in 0.011s\n",
      "[146/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.61779, val loss: 14.45344, in 0.025s\n",
      "[147/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.53909, val loss: 14.43692, in 0.016s\n",
      "[148/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.47658, val loss: 14.40799, in 0.006s\n",
      "[149/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.41461, val loss: 14.38155, in 0.005s\n",
      "[150/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.35602, val loss: 14.35573, in 0.025s\n",
      "[151/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.28319, val loss: 14.34476, in 0.010s\n",
      "[152/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.21895, val loss: 14.33319, in 0.006s\n",
      "[153/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.15297, val loss: 14.33136, in 0.005s\n",
      "[154/10000] 1 tree, 31 leaves, max depth = 11, train loss: 27.09138, val loss: 14.31962, in 0.025s\n",
      "[155/10000] 1 tree, 31 leaves, max depth = 12, train loss: 27.03077, val loss: 14.30802, in 0.022s\n",
      "[156/10000] 1 tree, 31 leaves, max depth = 7, train loss: 26.98420, val loss: 14.29602, in 0.025s\n",
      "[157/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.92468, val loss: 14.28677, in 0.011s\n",
      "[158/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.86385, val loss: 14.27562, in 0.007s\n",
      "[159/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.79139, val loss: 14.26323, in 0.030s\n",
      "[160/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.73980, val loss: 14.25467, in 0.006s\n",
      "[161/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.68888, val loss: 14.24370, in 0.010s\n",
      "[162/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.63522, val loss: 14.23315, in 0.006s\n",
      "[163/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.58354, val loss: 14.22339, in 0.006s\n",
      "[164/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.53691, val loss: 14.19738, in 0.034s\n",
      "[165/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.47120, val loss: 14.18975, in 0.006s\n",
      "[166/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.42316, val loss: 14.16746, in 0.014s\n",
      "[167/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.37720, val loss: 14.14308, in 0.006s\n",
      "[168/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.31298, val loss: 14.13039, in 0.029s\n",
      "[169/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.27003, val loss: 14.10753, in 0.013s\n",
      "[170/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.21135, val loss: 14.09768, in 0.030s\n",
      "[171/10000] 1 tree, 31 leaves, max depth = 11, train loss: 26.16489, val loss: 14.09419, in 0.007s\n",
      "[172/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.12085, val loss: 14.08675, in 0.040s\n",
      "[173/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.07742, val loss: 14.08178, in 0.011s\n",
      "[174/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.03254, val loss: 14.07911, in 0.007s\n",
      "[175/10000] 1 tree, 31 leaves, max depth = 11, train loss: 25.98365, val loss: 14.07418, in 0.033s\n",
      "[176/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.94081, val loss: 14.06749, in 0.006s\n",
      "[177/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.90064, val loss: 14.05378, in 0.005s\n",
      "[178/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.85185, val loss: 14.04720, in 0.009s\n",
      "[179/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.80510, val loss: 14.04092, in 0.006s\n",
      "[180/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.75895, val loss: 14.03369, in 0.030s\n",
      "[181/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.71747, val loss: 14.02306, in 0.006s\n",
      "[182/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.69694, val loss: 14.02288, in 0.006s\n",
      "[183/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.65882, val loss: 14.01152, in 0.030s\n",
      "[184/10000] 1 tree, 31 leaves, max depth = 11, train loss: 25.62044, val loss: 14.00612, in 0.010s\n",
      "[185/10000] 1 tree, 31 leaves, max depth = 11, train loss: 25.60439, val loss: 13.99986, in 0.007s\n",
      "[186/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.58693, val loss: 13.99380, in 0.032s\n",
      "[187/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.56920, val loss: 13.98689, in 0.006s\n",
      "[188/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.55116, val loss: 13.98572, in 0.005s\n",
      "[189/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.53029, val loss: 13.98652, in 0.013s\n",
      "[190/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.48484, val loss: 13.97892, in 0.006s\n",
      "[191/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.44485, val loss: 13.97247, in 0.038s\n",
      "[192/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.42681, val loss: 13.96966, in 0.006s\n",
      "[193/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.38154, val loss: 13.96386, in 0.006s\n",
      "[194/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.33690, val loss: 13.95834, in 0.030s\n",
      "[195/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.31480, val loss: 13.94543, in 0.006s\n",
      "[196/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.27318, val loss: 13.94005, in 0.010s\n",
      "[197/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.25155, val loss: 13.93133, in 0.006s\n",
      "[198/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.23617, val loss: 13.92385, in 0.005s\n",
      "[199/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.22028, val loss: 13.91408, in 0.040s\n",
      "[200/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.18361, val loss: 13.90943, in 0.012s\n",
      "[201/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.14144, val loss: 13.90302, in 0.005s\n",
      "[202/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.10996, val loss: 13.89516, in 0.024s\n",
      "[203/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.09487, val loss: 13.89377, in 0.009s\n",
      "[204/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.07993, val loss: 13.89306, in 0.006s\n",
      "[205/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.04738, val loss: 13.88924, in 0.041s\n",
      "[206/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.00914, val loss: 13.88850, in 0.007s\n",
      "[207/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.99385, val loss: 13.88596, in 0.032s\n",
      "[208/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.98010, val loss: 13.88345, in 0.021s\n",
      "[209/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.96580, val loss: 13.88126, in 0.006s\n",
      "[210/10000] 1 tree, 31 leaves, max depth = 11, train loss: 24.95217, val loss: 13.87991, in 0.032s\n",
      "[211/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.92181, val loss: 13.87765, in 0.006s\n",
      "[212/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.90218, val loss: 13.86069, in 0.021s\n",
      "[213/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.88376, val loss: 13.84426, in 0.017s\n",
      "[214/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.84442, val loss: 13.84206, in 0.006s\n",
      "[215/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.82231, val loss: 13.82653, in 0.037s\n",
      "[216/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.79939, val loss: 13.81153, in 0.065s\n",
      "[217/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.77551, val loss: 13.79706, in 0.013s\n",
      "[218/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.76584, val loss: 13.79423, in 0.039s\n",
      "[219/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.73785, val loss: 13.79114, in 0.006s\n",
      "[220/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.69957, val loss: 13.79094, in 0.005s\n",
      "[221/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.67625, val loss: 13.77652, in 0.036s\n",
      "[222/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.63976, val loss: 13.77480, in 0.006s\n",
      "[223/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.61789, val loss: 13.76048, in 0.034s\n",
      "[224/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.59727, val loss: 13.75705, in 0.009s\n",
      "[225/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.58310, val loss: 13.75401, in 0.017s\n",
      "[226/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.56219, val loss: 13.74121, in 0.030s\n",
      "[227/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.54079, val loss: 13.72736, in 0.006s\n",
      "[228/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.51904, val loss: 13.71247, in 0.040s\n",
      "[229/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.50968, val loss: 13.71205, in 0.030s\n",
      "[230/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.49429, val loss: 13.69725, in 0.007s\n",
      "[231/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.48520, val loss: 13.69682, in 0.006s\n",
      "[232/10000] 1 tree, 31 leaves, max depth = 11, train loss: 24.46989, val loss: 13.68183, in 0.085s\n",
      "[233/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.44187, val loss: 13.67563, in 0.007s\n",
      "[234/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.41350, val loss: 13.66934, in 0.040s\n",
      "[235/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.39681, val loss: 13.66706, in 0.008s\n",
      "[236/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.37919, val loss: 13.66498, in 0.006s\n",
      "[237/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.34799, val loss: 13.66250, in 0.005s\n",
      "[238/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.33747, val loss: 13.65543, in 0.034s\n",
      "[239/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.30542, val loss: 13.65012, in 0.006s\n",
      "[240/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.28436, val loss: 13.64830, in 0.007s\n",
      "[241/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.26214, val loss: 13.64587, in 0.032s\n",
      "[242/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.21586, val loss: 13.63880, in 0.006s\n",
      "[243/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.18438, val loss: 13.63747, in 0.005s\n",
      "[244/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.16263, val loss: 13.63744, in 0.036s\n",
      "[245/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.13229, val loss: 13.63914, in 0.006s\n",
      "[246/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.10112, val loss: 13.63354, in 0.005s\n",
      "[247/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.06965, val loss: 13.62729, in 0.039s\n",
      "[248/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.05135, val loss: 13.60118, in 0.042s\n",
      "[249/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.03306, val loss: 13.57488, in 0.014s\n",
      "[250/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.01428, val loss: 13.54988, in 0.031s\n",
      "[251/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.99909, val loss: 13.52388, in 0.006s\n",
      "[252/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.97523, val loss: 13.52183, in 0.005s\n",
      "[253/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.94621, val loss: 13.51696, in 0.009s\n",
      "[254/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.91738, val loss: 13.51170, in 0.032s\n",
      "[255/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.87510, val loss: 13.50537, in 0.006s\n",
      "[256/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.85994, val loss: 13.47991, in 0.009s\n",
      "[257/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.84532, val loss: 13.45500, in 0.033s\n",
      "[258/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.83086, val loss: 13.43015, in 0.006s\n",
      "[259/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.81673, val loss: 13.40538, in 0.010s\n",
      "[260/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.80293, val loss: 13.38054, in 0.029s\n",
      "[261/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.78953, val loss: 13.35604, in 0.007s\n",
      "[262/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.77467, val loss: 13.33405, in 0.015s\n",
      "[263/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.76226, val loss: 13.31248, in 0.031s\n",
      "[264/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.75004, val loss: 13.29098, in 0.006s\n",
      "[265/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.73554, val loss: 13.26988, in 0.006s\n",
      "[266/10000] 1 tree, 31 leaves, max depth = 12, train loss: 23.72188, val loss: 13.24827, in 0.041s\n",
      "[267/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.70793, val loss: 13.22496, in 0.006s\n",
      "[268/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.67934, val loss: 13.22105, in 0.005s\n",
      "[269/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.65116, val loss: 13.21685, in 0.071s\n",
      "[270/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.62343, val loss: 13.21291, in 0.007s\n",
      "[271/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.61196, val loss: 13.19515, in 0.006s\n",
      "[272/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.57550, val loss: 13.18620, in 0.036s\n",
      "[273/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.54007, val loss: 13.17865, in 0.009s\n",
      "[274/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.51949, val loss: 13.17695, in 0.006s\n",
      "[275/10000] 1 tree, 31 leaves, max depth = 7, train loss: 23.49334, val loss: 13.17317, in 0.005s\n",
      "[276/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.47539, val loss: 13.17083, in 0.042s\n",
      "[277/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.45740, val loss: 13.16773, in 0.005s\n",
      "[278/10000] 1 tree, 31 leaves, max depth = 12, train loss: 23.44514, val loss: 13.14960, in 0.005s\n",
      "[279/10000] 1 tree, 31 leaves, max depth = 12, train loss: 23.43328, val loss: 13.13165, in 0.032s\n",
      "[280/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.41614, val loss: 13.12882, in 0.006s\n",
      "[281/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.39923, val loss: 13.12514, in 0.006s\n",
      "[282/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.39017, val loss: 13.12454, in 0.029s\n",
      "[283/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.38242, val loss: 13.12134, in 0.006s\n",
      "[284/10000] 1 tree, 31 leaves, max depth = 13, train loss: 23.37288, val loss: 13.11574, in 0.006s\n",
      "[285/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.36513, val loss: 13.11226, in 0.028s\n",
      "[286/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.35760, val loss: 13.10807, in 0.039s\n",
      "[287/10000] 1 tree, 31 leaves, max depth = 13, train loss: 23.34912, val loss: 13.10314, in 0.006s\n",
      "[288/10000] 1 tree, 31 leaves, max depth = 13, train loss: 23.34072, val loss: 13.09823, in 0.005s\n",
      "[289/10000] 1 tree, 31 leaves, max depth = 13, train loss: 23.33240, val loss: 13.09340, in 0.030s\n",
      "[290/10000] 1 tree, 31 leaves, max depth = 14, train loss: 23.32641, val loss: 13.09165, in 0.007s\n",
      "[291/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.31236, val loss: 13.08976, in 0.005s\n",
      "[292/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.29856, val loss: 13.08781, in 0.009s\n",
      "[293/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.28835, val loss: 13.08281, in 0.031s\n",
      "[294/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.28065, val loss: 13.07787, in 0.006s\n",
      "[295/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.27059, val loss: 13.07998, in 0.006s\n",
      "[296/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.25752, val loss: 13.07907, in 0.034s\n",
      "[297/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.24465, val loss: 13.07819, in 0.005s\n",
      "[298/10000] 1 tree, 31 leaves, max depth = 12, train loss: 23.23006, val loss: 13.07664, in 0.005s\n",
      "[299/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.21669, val loss: 13.07642, in 0.009s\n",
      "[300/10000] 1 tree, 31 leaves, max depth = 14, train loss: 23.20294, val loss: 13.07650, in 0.005s\n",
      "[301/10000] 1 tree, 31 leaves, max depth = 12, train loss: 23.19106, val loss: 13.07624, in 0.005s\n",
      "[302/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.18036, val loss: 13.07545, in 0.035s\n",
      "[303/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.16879, val loss: 13.07400, in 0.005s\n",
      "[304/10000] 1 tree, 31 leaves, max depth = 12, train loss: 23.15584, val loss: 13.07238, in 0.007s\n",
      "[305/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.14541, val loss: 13.07152, in 0.030s\n",
      "[306/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.13488, val loss: 13.07093, in 0.005s\n",
      "[307/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.12281, val loss: 13.07010, in 0.005s\n",
      "[308/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.11138, val loss: 13.06926, in 0.030s\n",
      "[309/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.10439, val loss: 13.06884, in 0.007s\n",
      "[310/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.07361, val loss: 13.06831, in 0.006s\n",
      "[311/10000] 1 tree, 31 leaves, max depth = 7, train loss: 23.05423, val loss: 13.06678, in 0.078s\n",
      "[312/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.04731, val loss: 13.06702, in 0.008s\n",
      "[313/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.02900, val loss: 13.06638, in 0.006s\n",
      "[314/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.00976, val loss: 13.06574, in 0.005s\n",
      "[315/10000] 1 tree, 31 leaves, max depth = 13, train loss: 23.00286, val loss: 13.06530, in 0.033s\n",
      "[316/10000] 1 tree, 31 leaves, max depth = 13, train loss: 22.99599, val loss: 13.06486, in 0.007s\n",
      "[317/10000] 1 tree, 31 leaves, max depth = 13, train loss: 22.98936, val loss: 13.06446, in 0.008s\n",
      "[318/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.97653, val loss: 13.04594, in 0.006s\n",
      "[319/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.97022, val loss: 13.04671, in 0.025s\n",
      "[320/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.96064, val loss: 13.02844, in 0.005s\n",
      "[321/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.94955, val loss: 13.01006, in 0.012s\n",
      "[322/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.94358, val loss: 13.00676, in 0.006s\n",
      "[323/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.93833, val loss: 13.00637, in 0.005s\n",
      "[324/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.92947, val loss: 13.00579, in 0.025s\n",
      "[325/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.92070, val loss: 13.00515, in 0.005s\n",
      "[326/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.91277, val loss: 13.00452, in 0.010s\n",
      "[327/10000] 1 tree, 31 leaves, max depth = 7, train loss: 22.90747, val loss: 13.00584, in 0.006s\n",
      "[328/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.90379, val loss: 13.00558, in 0.005s\n",
      "[329/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.89433, val loss: 13.00515, in 0.034s\n",
      "[330/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.88677, val loss: 13.00463, in 0.007s\n",
      "[331/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.88182, val loss: 13.00381, in 0.027s\n",
      "[332/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.86912, val loss: 13.00313, in 0.006s\n",
      "[333/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.85295, val loss: 13.00254, in 0.010s\n",
      "[334/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.83096, val loss: 13.00186, in 0.007s\n",
      "[335/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.82387, val loss: 13.00193, in 0.005s\n",
      "[336/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.81722, val loss: 13.00139, in 0.008s\n",
      "[337/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.81002, val loss: 12.99775, in 0.026s\n",
      "[338/10000] 1 tree, 31 leaves, max depth = 14, train loss: 22.80348, val loss: 12.99260, in 0.005s\n",
      "[339/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.78270, val loss: 12.99204, in 0.010s\n",
      "[340/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.75522, val loss: 12.99131, in 0.037s\n",
      "[341/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.75045, val loss: 12.99310, in 0.006s\n",
      "[342/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.74538, val loss: 12.99466, in 0.011s\n",
      "[343/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.73936, val loss: 12.99414, in 0.005s\n",
      "[344/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.73887, val loss: 12.99354, in 0.026s\n",
      "[345/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.73838, val loss: 12.99295, in 0.005s\n",
      "[346/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.73607, val loss: 12.99217, in 0.005s\n",
      "[347/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.73560, val loss: 12.99160, in 0.058s\n",
      "[348/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.73514, val loss: 12.99114, in 0.006s\n",
      "[349/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.73469, val loss: 12.99070, in 0.089s\n",
      "[350/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.73424, val loss: 12.99029, in 0.006s\n",
      "[351/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.73379, val loss: 12.98989, in 0.005s\n",
      "[352/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.73335, val loss: 12.98949, in 0.005s\n",
      "[353/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.72748, val loss: 12.98914, in 0.024s\n",
      "[354/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.71719, val loss: 12.98860, in 0.005s\n",
      "[355/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.70706, val loss: 12.98800, in 0.009s\n",
      "[356/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.70662, val loss: 12.98757, in 0.005s\n",
      "[357/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.70326, val loss: 12.98683, in 0.005s\n",
      "[358/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.70282, val loss: 12.98645, in 0.032s\n",
      "[359/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69986, val loss: 12.98573, in 0.006s\n",
      "[360/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69944, val loss: 12.98531, in 0.037s\n",
      "[361/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69903, val loss: 12.98497, in 0.005s\n",
      "[362/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69862, val loss: 12.98463, in 0.006s\n",
      "[363/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69820, val loss: 12.98415, in 0.008s\n",
      "[364/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69780, val loss: 12.98382, in 0.005s\n",
      "[365/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69741, val loss: 12.98349, in 0.036s\n",
      "[366/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69702, val loss: 12.98317, in 0.005s\n",
      "[367/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69665, val loss: 12.98283, in 0.050s\n",
      "[368/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69628, val loss: 12.98250, in 0.033s\n",
      "[369/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69590, val loss: 12.98216, in 0.006s\n",
      "[370/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69549, val loss: 12.98184, in 0.005s\n",
      "[371/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69509, val loss: 12.98152, in 0.008s\n",
      "[372/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69472, val loss: 12.98119, in 0.032s\n",
      "[373/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69435, val loss: 12.98086, in 0.005s\n",
      "[374/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69399, val loss: 12.98053, in 0.053s\n",
      "[375/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69363, val loss: 12.98021, in 0.075s\n",
      "[376/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69328, val loss: 12.97989, in 0.009s\n",
      "[377/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69292, val loss: 12.97958, in 0.005s\n",
      "[378/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69257, val loss: 12.97926, in 0.005s\n",
      "[379/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.69223, val loss: 12.97895, in 0.031s\n",
      "[380/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.68891, val loss: 12.97859, in 0.005s\n",
      "[381/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.68560, val loss: 12.97829, in 0.006s\n",
      "[382/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.68526, val loss: 12.97799, in 0.028s\n",
      "[383/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.68493, val loss: 12.97769, in 0.005s\n",
      "[384/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.68441, val loss: 12.97768, in 0.024s\n",
      "[385/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.68409, val loss: 12.97739, in 0.036s\n",
      "[386/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.68376, val loss: 12.97710, in 0.005s\n",
      "[387/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.68344, val loss: 12.97681, in 0.034s\n",
      "[388/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.68313, val loss: 12.97655, in 0.005s\n",
      "[389/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.68282, val loss: 12.97628, in 0.006s\n",
      "[390/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.68251, val loss: 12.97600, in 0.025s\n",
      "[391/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.68221, val loss: 12.97574, in 0.005s\n",
      "[392/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.68191, val loss: 12.97549, in 0.005s\n",
      "[393/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.68161, val loss: 12.97523, in 0.010s\n",
      "[394/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.68132, val loss: 12.97498, in 0.005s\n",
      "[395/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.68104, val loss: 12.97473, in 0.005s\n",
      "[396/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.68075, val loss: 12.97447, in 0.037s\n",
      "[397/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.68046, val loss: 12.97422, in 0.005s\n",
      "[398/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.68017, val loss: 12.97396, in 0.005s\n",
      "[399/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.67988, val loss: 12.97365, in 0.054s\n",
      "[400/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.67960, val loss: 12.97334, in 0.005s\n",
      "[401/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.67835, val loss: 12.97082, in 0.006s\n",
      "[402/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.67524, val loss: 12.97064, in 0.041s\n",
      "[403/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.67496, val loss: 12.97041, in 0.012s\n",
      "[404/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.67465, val loss: 12.97005, in 0.005s\n",
      "[405/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.67433, val loss: 12.96956, in 0.005s\n",
      "[406/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.67234, val loss: 12.96640, in 0.034s\n",
      "[407/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.67037, val loss: 12.96328, in 0.012s\n",
      "[408/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.66823, val loss: 12.96117, in 0.033s\n",
      "[409/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.66606, val loss: 12.95905, in 0.006s\n",
      "[410/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.66396, val loss: 12.95698, in 0.036s\n",
      "[411/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.66149, val loss: 12.95672, in 0.005s\n",
      "[412/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.65377, val loss: 12.95641, in 0.006s\n",
      "[413/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.65081, val loss: 12.95619, in 0.008s\n",
      "[414/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.64788, val loss: 12.95596, in 0.005s\n",
      "[415/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.64711, val loss: 12.95459, in 0.030s\n",
      "[416/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.64688, val loss: 12.95432, in 0.006s\n",
      "[417/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.64665, val loss: 12.95413, in 0.005s\n",
      "[418/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.64642, val loss: 12.95393, in 0.009s\n",
      "[419/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.64619, val loss: 12.95375, in 0.041s\n",
      "[420/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.64597, val loss: 12.95349, in 0.041s\n",
      "[421/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.64281, val loss: 12.95245, in 0.005s\n",
      "[422/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.64259, val loss: 12.95223, in 0.006s\n",
      "[423/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.64237, val loss: 12.95198, in 0.008s\n",
      "[424/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.64214, val loss: 12.95172, in 0.005s\n",
      "[425/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.64192, val loss: 12.95147, in 0.005s\n",
      "[426/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.64171, val loss: 12.95124, in 0.096s\n",
      "[427/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.64149, val loss: 12.95099, in 0.074s\n",
      "[428/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.64128, val loss: 12.95075, in 0.012s\n",
      "[429/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.64107, val loss: 12.95052, in 0.005s\n",
      "[430/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.64041, val loss: 12.94926, in 0.133s\n",
      "[431/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.63326, val loss: 12.94728, in 0.009s\n",
      "[432/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.62308, val loss: 12.94576, in 0.006s\n",
      "[433/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.61305, val loss: 12.94426, in 0.006s\n",
      "[434/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.60523, val loss: 12.94407, in 0.152s\n",
      "[435/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.59750, val loss: 12.94387, in 0.008s\n",
      "[436/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.58984, val loss: 12.94368, in 0.006s\n",
      "[437/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.58225, val loss: 12.94349, in 0.005s\n",
      "[438/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.57475, val loss: 12.94330, in 0.033s\n",
      "[439/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.57212, val loss: 12.94321, in 0.046s\n",
      "[440/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.57193, val loss: 12.94306, in 0.007s\n",
      "[441/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.57174, val loss: 12.94285, in 0.089s\n",
      "[442/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.57155, val loss: 12.94264, in 0.007s\n",
      "[443/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.57136, val loss: 12.94243, in 0.005s\n",
      "[444/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.57119, val loss: 12.94222, in 0.040s\n",
      "[445/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.57100, val loss: 12.94201, in 0.011s\n",
      "[446/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.57083, val loss: 12.94180, in 0.032s\n",
      "[447/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.57032, val loss: 12.94155, in 0.006s\n",
      "[448/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.56626, val loss: 12.94118, in 0.005s\n",
      "[449/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.56388, val loss: 12.94103, in 0.098s\n",
      "[450/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.55254, val loss: 12.94091, in 0.007s\n",
      "[451/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.54131, val loss: 12.94079, in 0.009s\n",
      "[452/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.53019, val loss: 12.94067, in 0.071s\n",
      "[453/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.52019, val loss: 12.94056, in 0.079s\n",
      "[454/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.51992, val loss: 12.94057, in 0.007s\n",
      "[455/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.51279, val loss: 12.94042, in 0.005s\n",
      "[456/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.51261, val loss: 12.94026, in 0.005s\n",
      "[457/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.50562, val loss: 12.94009, in 0.025s\n",
      "[458/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.50540, val loss: 12.93997, in 0.014s\n",
      "[459/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.50524, val loss: 12.93986, in 0.006s\n",
      "[460/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.50502, val loss: 12.94006, in 0.093s\n",
      "[461/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.50486, val loss: 12.93992, in 0.007s\n",
      "[462/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.49542, val loss: 12.93991, in 0.008s\n",
      "[463/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.48721, val loss: 12.91687, in 0.005s\n",
      "[464/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.48703, val loss: 12.91649, in 0.198s\n",
      "[465/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.47998, val loss: 12.91635, in 0.234s\n",
      "[466/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.47978, val loss: 12.91624, in 0.011s\n",
      "[467/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.47963, val loss: 12.91601, in 0.006s\n",
      "[468/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.47494, val loss: 12.91591, in 0.034s\n",
      "[469/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.47470, val loss: 12.91564, in 0.006s\n",
      "[470/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.47451, val loss: 12.91553, in 0.006s\n",
      "[471/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.47429, val loss: 12.91553, in 0.007s\n",
      "[472/10000] 1 tree, 31 leaves, max depth = 7, train loss: 22.46758, val loss: 12.91535, in 0.027s\n",
      "[473/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.46737, val loss: 12.91518, in 0.005s\n",
      "[474/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.46724, val loss: 12.91507, in 0.011s\n",
      "[475/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.46709, val loss: 12.91494, in 0.006s\n",
      "[476/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.44614, val loss: 12.91485, in 0.026s\n",
      "[477/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.42540, val loss: 12.91476, in 0.011s\n",
      "[478/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.42526, val loss: 12.91473, in 0.006s\n",
      "[479/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.40473, val loss: 12.91464, in 0.006s\n",
      "[480/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.38440, val loss: 12.91456, in 0.032s\n",
      "[481/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.36428, val loss: 12.91447, in 0.006s\n",
      "[482/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.36414, val loss: 12.91444, in 0.008s\n",
      "[483/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34563, val loss: 12.91436, in 0.005s\n",
      "[484/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34544, val loss: 12.91428, in 0.026s\n",
      "[485/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34525, val loss: 12.91420, in 0.016s\n",
      "[486/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34506, val loss: 12.91412, in 0.005s\n",
      "[487/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34493, val loss: 12.91409, in 0.029s\n",
      "[488/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34480, val loss: 12.91401, in 0.009s\n",
      "[489/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34468, val loss: 12.91393, in 0.009s\n",
      "[490/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34455, val loss: 12.91385, in 0.005s\n",
      "[491/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34444, val loss: 12.91378, in 0.033s\n",
      "[492/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34431, val loss: 12.91370, in 0.005s\n",
      "[493/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34419, val loss: 12.91362, in 0.005s\n",
      "[494/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34407, val loss: 12.91355, in 0.039s\n",
      "[495/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34396, val loss: 12.91347, in 0.005s\n",
      "[496/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34384, val loss: 12.91340, in 0.005s\n",
      "[497/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34372, val loss: 12.91333, in 0.032s\n",
      "[498/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34361, val loss: 12.91325, in 0.005s\n",
      "[499/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34349, val loss: 12.91318, in 0.032s\n",
      "[500/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34338, val loss: 12.91311, in 0.060s\n",
      "[501/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34327, val loss: 12.91304, in 0.006s\n",
      "[502/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34316, val loss: 12.91297, in 0.005s\n",
      "[503/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34305, val loss: 12.91282, in 0.036s\n",
      "[504/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34295, val loss: 12.91275, in 0.045s\n",
      "[505/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34284, val loss: 12.91269, in 0.005s\n",
      "[506/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34273, val loss: 12.91262, in 0.006s\n",
      "[507/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34263, val loss: 12.91255, in 0.076s\n",
      "[508/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34253, val loss: 12.91249, in 0.005s\n",
      "[509/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34243, val loss: 12.91243, in 0.008s\n",
      "[510/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34233, val loss: 12.91233, in 0.005s\n",
      "[511/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34222, val loss: 12.91218, in 0.074s\n",
      "[512/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34212, val loss: 12.91206, in 0.078s\n",
      "[513/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34202, val loss: 12.91195, in 0.006s\n",
      "[514/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34192, val loss: 12.91183, in 0.139s\n",
      "[515/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34181, val loss: 12.91173, in 0.006s\n",
      "[516/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34172, val loss: 12.91167, in 0.005s\n",
      "[517/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34163, val loss: 12.91156, in 0.007s\n",
      "[518/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.34154, val loss: 12.91145, in 0.085s\n",
      "[519/10000] 1 tree, 31 leaves, max depth = 7, train loss: 22.34137, val loss: 12.91142, in 0.006s\n",
      "[520/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.32700, val loss: 12.91131, in 0.008s\n",
      "[521/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.32691, val loss: 12.91122, in 0.006s\n",
      "[522/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.32682, val loss: 12.91112, in 0.059s\n",
      "[523/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.32665, val loss: 12.91102, in 0.100s\n",
      "[524/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.32634, val loss: 12.91117, in 0.006s\n",
      "[525/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.32594, val loss: 12.91126, in 0.005s\n",
      "[526/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.32563, val loss: 12.91104, in 0.039s\n",
      "[527/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.32529, val loss: 12.91095, in 0.016s\n",
      "[528/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.32276, val loss: 12.91097, in 0.028s\n",
      "[529/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.32267, val loss: 12.91087, in 0.009s\n",
      "[530/10000] 1 tree, 31 leaves, max depth = 7, train loss: 22.32258, val loss: 12.91084, in 0.005s\n",
      "[531/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.32244, val loss: 12.91101, in 0.006s\n",
      "[532/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.32236, val loss: 12.91092, in 0.087s\n",
      "[533/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.32227, val loss: 12.91083, in 0.010s\n",
      "[534/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.32219, val loss: 12.91073, in 0.006s\n",
      "[535/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.32210, val loss: 12.91064, in 0.033s\n",
      "[536/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.32202, val loss: 12.91056, in 0.006s\n",
      "[537/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.32193, val loss: 12.91047, in 0.005s\n",
      "[538/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.32186, val loss: 12.91040, in 0.009s\n",
      "[539/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.32178, val loss: 12.91033, in 0.005s\n",
      "[540/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.32171, val loss: 12.91026, in 0.122s\n",
      "[541/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.32164, val loss: 12.91019, in 0.006s\n",
      "[542/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.32156, val loss: 12.91013, in 0.006s\n",
      "[543/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.32149, val loss: 12.91006, in 0.008s\n",
      "[544/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.32141, val loss: 12.90997, in 0.121s\n",
      "[545/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.32134, val loss: 12.90991, in 0.006s\n",
      "[546/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.32127, val loss: 12.90984, in 0.006s\n",
      "[547/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.32120, val loss: 12.90978, in 0.072s\n",
      "[548/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.32114, val loss: 12.90971, in 0.074s\n",
      "[549/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.32105, val loss: 12.90962, in 0.006s\n",
      "[550/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.32096, val loss: 12.90954, in 0.007s\n",
      "[551/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.32088, val loss: 12.90947, in 0.006s\n",
      "[552/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.32079, val loss: 12.90937, in 0.270s\n",
      "[553/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.32070, val loss: 12.90928, in 0.007s\n",
      "[554/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.32061, val loss: 12.90918, in 0.010s\n",
      "[555/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.32053, val loss: 12.90909, in 0.034s\n",
      "[556/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.32045, val loss: 12.90900, in 0.005s\n",
      "[557/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.32037, val loss: 12.90890, in 0.005s\n",
      "[558/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.32029, val loss: 12.90881, in 0.010s\n",
      "[559/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.32022, val loss: 12.90872, in 0.007s\n",
      "[560/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.32014, val loss: 12.90863, in 0.170s\n",
      "[561/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.32007, val loss: 12.90854, in 0.008s\n",
      "[562/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.32000, val loss: 12.90846, in 0.007s\n",
      "[563/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31991, val loss: 12.90837, in 0.006s\n",
      "[564/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.31984, val loss: 12.90829, in 0.101s\n",
      "[565/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31977, val loss: 12.90820, in 0.007s\n",
      "[566/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31971, val loss: 12.90811, in 0.010s\n",
      "[567/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31964, val loss: 12.90803, in 0.085s\n",
      "[568/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31958, val loss: 12.90795, in 0.007s\n",
      "[569/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31953, val loss: 12.90788, in 0.005s\n",
      "[570/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31946, val loss: 12.90780, in 0.073s\n",
      "[571/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31940, val loss: 12.90773, in 0.085s\n",
      "[572/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31933, val loss: 12.90765, in 0.007s\n",
      "[573/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31928, val loss: 12.90758, in 0.123s\n",
      "[574/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31923, val loss: 12.90753, in 0.009s\n",
      "[575/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31918, val loss: 12.90748, in 0.005s\n",
      "[576/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31913, val loss: 12.90743, in 0.005s\n",
      "[577/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31908, val loss: 12.90738, in 0.142s\n",
      "[578/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31903, val loss: 12.90733, in 0.006s\n",
      "[579/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31898, val loss: 12.90728, in 0.006s\n",
      "[580/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31893, val loss: 12.90723, in 0.005s\n",
      "[581/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31888, val loss: 12.90718, in 0.005s\n",
      "[582/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31883, val loss: 12.90713, in 0.005s\n",
      "[583/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31878, val loss: 12.90709, in 0.032s\n",
      "[584/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31874, val loss: 12.90704, in 0.006s\n",
      "[585/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31869, val loss: 12.90699, in 0.005s\n",
      "[586/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31865, val loss: 12.90695, in 0.035s\n",
      "[587/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31860, val loss: 12.90690, in 0.006s\n",
      "[588/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31856, val loss: 12.90686, in 0.066s\n",
      "[589/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.31851, val loss: 12.90682, in 0.007s\n",
      "[590/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31845, val loss: 12.90677, in 0.091s\n",
      "[591/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31839, val loss: 12.90673, in 0.051s\n",
      "[592/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31833, val loss: 12.90669, in 0.007s\n",
      "[593/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31828, val loss: 12.90665, in 0.006s\n",
      "[594/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31822, val loss: 12.90661, in 0.034s\n",
      "[595/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31816, val loss: 12.90657, in 0.006s\n",
      "[596/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31811, val loss: 12.90653, in 0.007s\n",
      "[597/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31805, val loss: 12.90649, in 0.008s\n",
      "[598/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31800, val loss: 12.90645, in 0.006s\n",
      "[599/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31795, val loss: 12.90641, in 0.032s\n",
      "[600/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31790, val loss: 12.90637, in 0.007s\n",
      "[601/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31784, val loss: 12.90633, in 0.006s\n",
      "[602/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31779, val loss: 12.90629, in 0.043s\n",
      "[603/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31774, val loss: 12.90625, in 0.037s\n",
      "[604/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31769, val loss: 12.90622, in 0.007s\n",
      "[605/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31765, val loss: 12.90618, in 0.010s\n",
      "[606/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31761, val loss: 12.90614, in 0.034s\n",
      "[607/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31757, val loss: 12.90611, in 0.013s\n",
      "[608/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31753, val loss: 12.90607, in 0.100s\n",
      "[609/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31750, val loss: 12.90604, in 0.021s\n",
      "[610/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31746, val loss: 12.90600, in 0.132s\n",
      "[611/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31742, val loss: 12.90597, in 0.010s\n",
      "[612/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31739, val loss: 12.90593, in 0.006s\n",
      "[613/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31735, val loss: 12.90590, in 0.005s\n",
      "[614/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31731, val loss: 12.90584, in 0.140s\n",
      "[615/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31728, val loss: 12.90580, in 0.008s\n",
      "[616/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31725, val loss: 12.90576, in 0.012s\n",
      "[617/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31721, val loss: 12.90572, in 0.118s\n",
      "[618/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31718, val loss: 12.90568, in 0.006s\n",
      "[619/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31715, val loss: 12.90564, in 0.005s\n",
      "[620/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31712, val loss: 12.90560, in 0.005s\n",
      "[621/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31709, val loss: 12.90557, in 0.071s\n",
      "[622/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31706, val loss: 12.90553, in 0.100s\n",
      "[623/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31703, val loss: 12.90549, in 0.010s\n",
      "[624/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31700, val loss: 12.90546, in 0.005s\n",
      "[625/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31697, val loss: 12.90542, in 0.005s\n",
      "[626/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31694, val loss: 12.90539, in 0.076s\n",
      "[627/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31691, val loss: 12.90535, in 0.007s\n",
      "[628/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31688, val loss: 12.90532, in 0.007s\n",
      "[629/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31686, val loss: 12.90528, in 0.033s\n",
      "[630/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31683, val loss: 12.90525, in 0.010s\n",
      "[631/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31680, val loss: 12.90522, in 0.005s\n",
      "[632/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31677, val loss: 12.90518, in 0.005s\n",
      "[633/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31673, val loss: 12.90515, in 0.065s\n",
      "[634/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31670, val loss: 12.90512, in 0.024s\n",
      "[635/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31668, val loss: 12.90509, in 0.036s\n",
      "[636/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31665, val loss: 12.90505, in 0.006s\n",
      "[637/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31662, val loss: 12.90502, in 0.006s\n",
      "[638/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31659, val loss: 12.90499, in 0.009s\n",
      "[639/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31656, val loss: 12.90496, in 0.006s\n",
      "[640/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31654, val loss: 12.90493, in 0.041s\n",
      "[641/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31651, val loss: 12.90490, in 0.008s\n",
      "[642/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31640, val loss: 12.90488, in 0.043s\n",
      "[643/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31637, val loss: 12.90485, in 0.072s\n",
      "[644/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31635, val loss: 12.90482, in 0.024s\n",
      "[645/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31624, val loss: 12.90479, in 0.067s\n",
      "[646/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31622, val loss: 12.90477, in 0.012s\n",
      "[647/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31619, val loss: 12.90474, in 0.005s\n",
      "[648/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31617, val loss: 12.90471, in 0.071s\n",
      "[649/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31606, val loss: 12.90469, in 0.006s\n",
      "[650/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31603, val loss: 12.90466, in 0.005s\n",
      "[651/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31600, val loss: 12.90463, in 0.013s\n",
      "[652/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31597, val loss: 12.90460, in 0.005s\n",
      "[653/10000] 1 tree, 31 leaves, max depth = 7, train loss: 22.31574, val loss: 12.90462, in 0.029s\n",
      "[654/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31570, val loss: 12.90459, in 0.011s\n",
      "[655/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31567, val loss: 12.90456, in 0.006s\n",
      "[656/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31563, val loss: 12.90456, in 0.005s\n",
      "[657/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31560, val loss: 12.90454, in 0.033s\n",
      "[658/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31557, val loss: 12.90451, in 0.006s\n",
      "[659/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31553, val loss: 12.90448, in 0.030s\n",
      "[660/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31550, val loss: 12.90446, in 0.006s\n",
      "[661/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31547, val loss: 12.90443, in 0.009s\n",
      "[662/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31544, val loss: 12.90441, in 0.006s\n",
      "[663/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31541, val loss: 12.90439, in 0.005s\n",
      "[664/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31538, val loss: 12.90436, in 0.067s\n",
      "[665/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31535, val loss: 12.90434, in 0.082s\n",
      "[666/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31532, val loss: 12.90431, in 0.006s\n",
      "[667/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31529, val loss: 12.90429, in 0.016s\n",
      "[668/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31526, val loss: 12.90427, in 0.006s\n",
      "[669/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31523, val loss: 12.90425, in 0.078s\n",
      "[670/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31520, val loss: 12.90422, in 0.007s\n",
      "[671/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31518, val loss: 12.90420, in 0.007s\n",
      "[672/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31515, val loss: 12.90418, in 0.041s\n",
      "[673/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31512, val loss: 12.90416, in 0.006s\n",
      "[674/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31509, val loss: 12.90413, in 0.005s\n",
      "[675/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31507, val loss: 12.90411, in 0.037s\n",
      "[676/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31504, val loss: 12.90409, in 0.006s\n",
      "[677/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31501, val loss: 12.90407, in 0.009s\n",
      "[678/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31498, val loss: 12.90405, in 0.006s\n",
      "[679/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31495, val loss: 12.90393, in 0.005s\n",
      "[680/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31492, val loss: 12.90391, in 0.097s\n",
      "[681/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31490, val loss: 12.90389, in 0.007s\n",
      "[682/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31487, val loss: 12.90387, in 0.011s\n",
      "[683/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31485, val loss: 12.90386, in 0.033s\n",
      "[684/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31482, val loss: 12.90384, in 0.006s\n",
      "[685/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31479, val loss: 12.90383, in 0.057s\n",
      "[686/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31477, val loss: 12.90381, in 0.037s\n",
      "[687/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31474, val loss: 12.90380, in 0.007s\n",
      "[688/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31472, val loss: 12.90378, in 0.005s\n",
      "[689/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31469, val loss: 12.90376, in 0.009s\n",
      "[690/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31466, val loss: 12.90375, in 0.075s\n",
      "[691/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31464, val loss: 12.90374, in 0.012s\n",
      "[692/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31462, val loss: 12.90372, in 0.006s\n",
      "[693/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31459, val loss: 12.90371, in 0.033s\n",
      "[694/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31457, val loss: 12.90369, in 0.007s\n",
      "[695/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31455, val loss: 12.90368, in 0.005s\n",
      "[696/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31453, val loss: 12.90366, in 0.008s\n",
      "[697/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31450, val loss: 12.90365, in 0.037s\n",
      "[698/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31448, val loss: 12.90364, in 0.006s\n",
      "[699/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31445, val loss: 12.90362, in 0.040s\n",
      "[700/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31443, val loss: 12.90361, in 0.006s\n",
      "[701/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31440, val loss: 12.90359, in 0.005s\n",
      "[702/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31438, val loss: 12.90358, in 0.097s\n",
      "[703/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31436, val loss: 12.90357, in 0.006s\n",
      "[704/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31434, val loss: 12.90355, in 0.005s\n",
      "[705/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31432, val loss: 12.90354, in 0.008s\n",
      "[706/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31430, val loss: 12.90353, in 0.089s\n",
      "[707/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31428, val loss: 12.90351, in 0.007s\n",
      "[708/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31426, val loss: 12.90350, in 0.044s\n",
      "[709/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31424, val loss: 12.90349, in 0.009s\n",
      "[710/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31422, val loss: 12.90347, in 0.006s\n",
      "[711/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31420, val loss: 12.90346, in 0.005s\n",
      "[712/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31418, val loss: 12.90345, in 0.036s\n",
      "[713/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31416, val loss: 12.90343, in 0.006s\n",
      "[714/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31414, val loss: 12.90342, in 0.034s\n",
      "[715/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31412, val loss: 12.90341, in 0.006s\n",
      "[716/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31411, val loss: 12.90340, in 0.006s\n",
      "[717/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31409, val loss: 12.90339, in 0.030s\n",
      "[718/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31407, val loss: 12.90338, in 0.006s\n",
      "[719/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31406, val loss: 12.90336, in 0.009s\n",
      "[720/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31404, val loss: 12.90335, in 0.005s\n",
      "[721/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.31359, val loss: 12.90263, in 0.035s\n",
      "[722/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.31316, val loss: 12.90221, in 0.011s\n",
      "[723/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31294, val loss: 12.90213, in 0.059s\n",
      "[724/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31277, val loss: 12.90215, in 0.035s\n",
      "[725/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31256, val loss: 12.90214, in 0.006s\n",
      "[726/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31248, val loss: 12.90220, in 0.038s\n",
      "[727/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31232, val loss: 12.90219, in 0.008s\n",
      "[728/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31202, val loss: 12.90218, in 0.005s\n",
      "[729/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31200, val loss: 12.90216, in 0.006s\n",
      "[730/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31193, val loss: 12.90215, in 0.070s\n",
      "[731/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31191, val loss: 12.90214, in 0.011s\n",
      "[732/10000] 1 tree, 31 leaves, max depth = 7, train loss: 22.31177, val loss: 12.90196, in 0.036s\n",
      "[733/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31176, val loss: 12.90195, in 0.029s\n",
      "[734/10000] 1 tree, 31 leaves, max depth = 7, train loss: 22.31161, val loss: 12.90153, in 0.042s\n",
      "[735/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31158, val loss: 12.90152, in 0.006s\n",
      "[736/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31155, val loss: 12.90140, in 0.036s\n",
      "[737/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31154, val loss: 12.90140, in 0.006s\n",
      "[738/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31151, val loss: 12.90139, in 0.007s\n",
      "[739/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31149, val loss: 12.90137, in 0.035s\n",
      "[740/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31147, val loss: 12.90136, in 0.006s\n",
      "[741/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31145, val loss: 12.90134, in 0.005s\n",
      "[742/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31143, val loss: 12.90133, in 0.090s\n",
      "[743/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31141, val loss: 12.90132, in 0.009s\n",
      "[744/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31139, val loss: 12.90130, in 0.007s\n",
      "[745/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31136, val loss: 12.90140, in 0.032s\n",
      "[746/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31134, val loss: 12.90149, in 0.008s\n",
      "[747/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31131, val loss: 12.90159, in 0.054s\n",
      "[748/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31129, val loss: 12.90168, in 0.042s\n",
      "[749/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31126, val loss: 12.90183, in 0.009s\n",
      "[750/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31124, val loss: 12.90182, in 0.041s\n",
      "[751/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31122, val loss: 12.90191, in 0.006s\n",
      "[752/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31120, val loss: 12.90188, in 0.005s\n",
      "[753/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31117, val loss: 12.90184, in 0.034s\n",
      "[754/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.31114, val loss: 12.90179, in 0.044s\n",
      "Fit 754 trees in 17.106 s, (23374 total leaves)\n",
      "Time spent computing histograms: 4.070s\n",
      "Time spent finding best splits:  2.504s\n",
      "Time spent applying splits:      3.347s\n",
      "Time spent predicting:           0.790s\n",
      "Binning 0.001 GB of training data: 0.012 s\n",
      "Binning 0.000 GB of validation data: 0.001 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/10000] 1 tree, 31 leaves, max depth = 10, train loss: 40.43646, val loss: 31.24389, in 0.006s\n",
      "[2/10000] 1 tree, 31 leaves, max depth = 11, train loss: 40.33603, val loss: 31.14510, in 0.030s\n",
      "[3/10000] 1 tree, 31 leaves, max depth = 9, train loss: 40.23645, val loss: 31.04823, in 0.014s\n",
      "[4/10000] 1 tree, 31 leaves, max depth = 9, train loss: 40.13797, val loss: 30.95150, in 0.005s\n",
      "[5/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.04041, val loss: 30.85640, in 0.005s\n",
      "[6/10000] 1 tree, 31 leaves, max depth = 11, train loss: 39.94745, val loss: 30.76155, in 0.039s\n",
      "[7/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.84224, val loss: 30.66288, in 0.006s\n",
      "[8/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.73816, val loss: 30.56438, in 0.036s\n",
      "[9/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.63514, val loss: 30.46701, in 0.005s\n",
      "[10/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.53472, val loss: 30.37070, in 0.035s\n",
      "[11/10000] 1 tree, 31 leaves, max depth = 9, train loss: 39.42801, val loss: 30.27059, in 0.006s\n",
      "[12/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.32255, val loss: 30.17065, in 0.005s\n",
      "[13/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.21814, val loss: 30.07183, in 0.005s\n",
      "[14/10000] 1 tree, 31 leaves, max depth = 10, train loss: 39.11605, val loss: 29.97460, in 0.005s\n",
      "[15/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.00437, val loss: 29.86544, in 0.070s\n",
      "[16/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.89403, val loss: 29.75762, in 0.128s\n",
      "[17/10000] 1 tree, 31 leaves, max depth = 7, train loss: 38.78565, val loss: 29.65004, in 0.006s\n",
      "[18/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.68153, val loss: 29.54741, in 0.009s\n",
      "[19/10000] 1 tree, 31 leaves, max depth = 9, train loss: 38.57853, val loss: 29.44636, in 0.005s\n",
      "[20/10000] 1 tree, 31 leaves, max depth = 7, train loss: 38.47763, val loss: 29.34576, in 0.083s\n",
      "[21/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.36770, val loss: 29.23421, in 0.009s\n",
      "[22/10000] 1 tree, 31 leaves, max depth = 9, train loss: 38.25893, val loss: 29.12371, in 0.009s\n",
      "[23/10000] 1 tree, 31 leaves, max depth = 7, train loss: 38.15182, val loss: 29.01339, in 0.051s\n",
      "[24/10000] 1 tree, 31 leaves, max depth = 7, train loss: 38.04168, val loss: 28.91547, in 0.035s\n",
      "[25/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.93271, val loss: 28.81990, in 0.006s\n",
      "[26/10000] 1 tree, 31 leaves, max depth = 7, train loss: 37.82576, val loss: 28.72401, in 0.005s\n",
      "[27/10000] 1 tree, 31 leaves, max depth = 7, train loss: 37.72002, val loss: 28.62945, in 0.035s\n",
      "[28/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.61608, val loss: 28.53595, in 0.005s\n",
      "[29/10000] 1 tree, 31 leaves, max depth = 9, train loss: 37.50363, val loss: 28.44965, in 0.005s\n",
      "[30/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.39423, val loss: 28.36458, in 0.077s\n",
      "[31/10000] 1 tree, 31 leaves, max depth = 9, train loss: 37.28073, val loss: 28.27530, in 0.069s\n",
      "[32/10000] 1 tree, 31 leaves, max depth = 10, train loss: 37.16844, val loss: 28.18724, in 0.007s\n",
      "[33/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.04922, val loss: 28.09500, in 0.005s\n",
      "[34/10000] 1 tree, 31 leaves, max depth = 7, train loss: 36.93118, val loss: 28.00290, in 0.005s\n",
      "[35/10000] 1 tree, 31 leaves, max depth = 11, train loss: 36.81600, val loss: 27.91202, in 0.091s\n",
      "[36/10000] 1 tree, 31 leaves, max depth = 9, train loss: 36.70055, val loss: 27.82057, in 0.007s\n",
      "[37/10000] 1 tree, 31 leaves, max depth = 10, train loss: 36.58254, val loss: 27.73013, in 0.009s\n",
      "[38/10000] 1 tree, 31 leaves, max depth = 9, train loss: 36.46590, val loss: 27.64127, in 0.037s\n",
      "[39/10000] 1 tree, 31 leaves, max depth = 9, train loss: 36.35066, val loss: 27.55354, in 0.006s\n",
      "[40/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.23737, val loss: 27.46568, in 0.006s\n",
      "[41/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.12487, val loss: 27.38025, in 0.009s\n",
      "[42/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.01397, val loss: 27.30436, in 0.131s\n",
      "[43/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.90063, val loss: 27.22465, in 0.008s\n",
      "[44/10000] 1 tree, 31 leaves, max depth = 9, train loss: 35.78134, val loss: 27.14506, in 0.088s\n",
      "[45/10000] 1 tree, 31 leaves, max depth = 9, train loss: 35.65768, val loss: 27.07089, in 0.005s\n",
      "[46/10000] 1 tree, 31 leaves, max depth = 9, train loss: 35.54396, val loss: 26.98821, in 0.006s\n",
      "[47/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.43717, val loss: 26.91691, in 0.005s\n",
      "[48/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.31904, val loss: 26.84660, in 0.373s\n",
      "[49/10000] 1 tree, 31 leaves, max depth = 10, train loss: 35.20445, val loss: 26.76460, in 0.007s\n",
      "[50/10000] 1 tree, 31 leaves, max depth = 10, train loss: 35.09421, val loss: 26.69005, in 0.006s\n",
      "[51/10000] 1 tree, 31 leaves, max depth = 10, train loss: 34.97566, val loss: 26.61042, in 0.009s\n",
      "[52/10000] 1 tree, 31 leaves, max depth = 9, train loss: 34.86059, val loss: 26.54047, in 0.034s\n",
      "[53/10000] 1 tree, 31 leaves, max depth = 9, train loss: 34.75583, val loss: 26.46083, in 0.006s\n",
      "[54/10000] 1 tree, 31 leaves, max depth = 9, train loss: 34.64303, val loss: 26.40159, in 0.031s\n",
      "[55/10000] 1 tree, 31 leaves, max depth = 10, train loss: 34.51610, val loss: 26.33451, in 0.006s\n",
      "[56/10000] 1 tree, 31 leaves, max depth = 10, train loss: 34.39342, val loss: 26.26955, in 0.006s\n",
      "[57/10000] 1 tree, 31 leaves, max depth = 11, train loss: 34.27621, val loss: 26.20455, in 0.009s\n",
      "[58/10000] 1 tree, 31 leaves, max depth = 10, train loss: 34.15592, val loss: 26.13729, in 0.046s\n",
      "[59/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.05153, val loss: 26.05648, in 0.080s\n",
      "[60/10000] 1 tree, 31 leaves, max depth = 9, train loss: 33.92905, val loss: 25.97098, in 0.005s\n",
      "[61/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.82359, val loss: 25.87861, in 0.009s\n",
      "[62/10000] 1 tree, 31 leaves, max depth = 10, train loss: 33.71069, val loss: 25.80103, in 0.006s\n",
      "[63/10000] 1 tree, 31 leaves, max depth = 9, train loss: 33.59033, val loss: 25.73404, in 0.006s\n",
      "[64/10000] 1 tree, 31 leaves, max depth = 9, train loss: 33.46720, val loss: 25.65216, in 0.028s\n",
      "[65/10000] 1 tree, 31 leaves, max depth = 9, train loss: 33.33825, val loss: 25.56434, in 0.011s\n",
      "[66/10000] 1 tree, 31 leaves, max depth = 7, train loss: 33.21999, val loss: 25.47562, in 0.005s\n",
      "[67/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.10550, val loss: 25.40594, in 0.005s\n",
      "[68/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.99235, val loss: 25.33627, in 0.075s\n",
      "[69/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.87015, val loss: 25.26858, in 0.013s\n",
      "[70/10000] 1 tree, 31 leaves, max depth = 7, train loss: 32.74894, val loss: 25.20090, in 0.006s\n",
      "[71/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.62328, val loss: 25.13892, in 0.005s\n",
      "[72/10000] 1 tree, 31 leaves, max depth = 9, train loss: 32.51591, val loss: 25.05615, in 0.110s\n",
      "[73/10000] 1 tree, 31 leaves, max depth = 9, train loss: 32.39684, val loss: 24.98011, in 0.006s\n",
      "[74/10000] 1 tree, 31 leaves, max depth = 9, train loss: 32.27865, val loss: 24.91690, in 0.009s\n",
      "[75/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.16969, val loss: 24.85674, in 0.006s\n",
      "[76/10000] 1 tree, 31 leaves, max depth = 9, train loss: 32.04779, val loss: 24.80220, in 0.032s\n",
      "[77/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.93437, val loss: 24.74199, in 0.005s\n",
      "[78/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.82332, val loss: 24.67944, in 0.006s\n",
      "[79/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.71408, val loss: 24.59918, in 0.005s\n",
      "[80/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.58896, val loss: 24.53841, in 0.009s\n",
      "[81/10000] 1 tree, 31 leaves, max depth = 11, train loss: 31.47499, val loss: 24.47044, in 0.041s\n",
      "[82/10000] 1 tree, 31 leaves, max depth = 10, train loss: 31.36315, val loss: 24.40325, in 0.005s\n",
      "[83/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.23999, val loss: 24.31325, in 0.050s\n",
      "[84/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.12096, val loss: 24.25605, in 0.007s\n",
      "[85/10000] 1 tree, 31 leaves, max depth = 10, train loss: 31.00459, val loss: 24.19674, in 0.035s\n",
      "[86/10000] 1 tree, 31 leaves, max depth = 11, train loss: 30.89001, val loss: 24.13892, in 0.005s\n",
      "[87/10000] 1 tree, 31 leaves, max depth = 9, train loss: 30.78357, val loss: 24.07839, in 0.006s\n",
      "[88/10000] 1 tree, 31 leaves, max depth = 9, train loss: 30.67891, val loss: 24.01841, in 0.008s\n",
      "[89/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.55606, val loss: 23.95405, in 0.005s\n",
      "[90/10000] 1 tree, 31 leaves, max depth = 10, train loss: 30.43501, val loss: 23.89120, in 0.130s\n",
      "[91/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.32618, val loss: 23.84252, in 0.009s\n",
      "[92/10000] 1 tree, 31 leaves, max depth = 9, train loss: 30.20874, val loss: 23.78402, in 0.007s\n",
      "[93/10000] 1 tree, 31 leaves, max depth = 9, train loss: 30.09230, val loss: 23.72240, in 0.006s\n",
      "[94/10000] 1 tree, 31 leaves, max depth = 9, train loss: 29.97560, val loss: 23.65962, in 0.066s\n",
      "[95/10000] 1 tree, 31 leaves, max depth = 10, train loss: 29.85802, val loss: 23.60189, in 0.123s\n",
      "[96/10000] 1 tree, 31 leaves, max depth = 10, train loss: 29.74028, val loss: 23.53736, in 0.007s\n",
      "[97/10000] 1 tree, 31 leaves, max depth = 10, train loss: 29.62342, val loss: 23.48171, in 0.006s\n",
      "[98/10000] 1 tree, 31 leaves, max depth = 10, train loss: 29.51673, val loss: 23.43234, in 0.069s\n",
      "[99/10000] 1 tree, 31 leaves, max depth = 9, train loss: 29.41400, val loss: 23.39045, in 0.091s\n",
      "[100/10000] 1 tree, 31 leaves, max depth = 9, train loss: 29.29836, val loss: 23.33717, in 0.010s\n",
      "[101/10000] 1 tree, 31 leaves, max depth = 9, train loss: 29.18206, val loss: 23.28470, in 0.006s\n",
      "[102/10000] 1 tree, 31 leaves, max depth = 9, train loss: 29.07291, val loss: 23.22740, in 0.005s\n",
      "[103/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.96871, val loss: 23.18336, in 0.036s\n",
      "[104/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.83990, val loss: 23.11772, in 0.005s\n",
      "[105/10000] 1 tree, 31 leaves, max depth = 10, train loss: 28.71795, val loss: 23.05412, in 0.035s\n",
      "[106/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.62159, val loss: 23.01347, in 0.006s\n",
      "[107/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.50796, val loss: 22.95200, in 0.006s\n",
      "[108/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.42149, val loss: 22.91288, in 0.038s\n",
      "[109/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.29714, val loss: 22.84234, in 0.006s\n",
      "[110/10000] 1 tree, 31 leaves, max depth = 10, train loss: 28.20407, val loss: 22.79783, in 0.005s\n",
      "[111/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.08263, val loss: 22.72743, in 0.009s\n",
      "[112/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.96326, val loss: 22.65812, in 0.033s\n",
      "[113/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.84558, val loss: 22.58890, in 0.008s\n",
      "[114/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.74721, val loss: 22.53719, in 0.006s\n",
      "[115/10000] 1 tree, 31 leaves, max depth = 10, train loss: 27.66170, val loss: 22.49546, in 0.036s\n",
      "[116/10000] 1 tree, 31 leaves, max depth = 7, train loss: 27.56172, val loss: 22.44385, in 0.051s\n",
      "[117/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.47447, val loss: 22.40176, in 0.007s\n",
      "[118/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.38107, val loss: 22.35027, in 0.006s\n",
      "[119/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.27778, val loss: 22.28925, in 0.042s\n",
      "[120/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.17616, val loss: 22.23667, in 0.009s\n",
      "[121/10000] 1 tree, 31 leaves, max depth = 10, train loss: 27.08441, val loss: 22.19083, in 0.006s\n",
      "[122/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.98425, val loss: 22.12739, in 0.005s\n",
      "[123/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.90364, val loss: 22.09228, in 0.083s\n",
      "[124/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.81181, val loss: 22.03071, in 0.007s\n",
      "[125/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.70571, val loss: 21.98167, in 0.006s\n",
      "[126/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.60985, val loss: 21.94154, in 0.136s\n",
      "[127/10000] 1 tree, 31 leaves, max depth = 10, train loss: 26.51737, val loss: 21.88009, in 0.011s\n",
      "[128/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.44741, val loss: 21.83952, in 0.006s\n",
      "[129/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.35834, val loss: 21.79346, in 0.040s\n",
      "[130/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.27045, val loss: 21.74596, in 0.006s\n",
      "[131/10000] 1 tree, 31 leaves, max depth = 10, train loss: 26.17957, val loss: 21.69362, in 0.084s\n",
      "[132/10000] 1 tree, 31 leaves, max depth = 7, train loss: 26.09782, val loss: 21.65198, in 0.006s\n",
      "[133/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.01401, val loss: 21.60490, in 0.025s\n",
      "[134/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.93680, val loss: 21.55685, in 0.037s\n",
      "[135/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.85569, val loss: 21.51246, in 0.006s\n",
      "[136/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.77412, val loss: 21.46463, in 0.048s\n",
      "[137/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.70312, val loss: 21.41114, in 0.009s\n",
      "[138/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.62406, val loss: 21.36831, in 0.006s\n",
      "[139/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.54634, val loss: 21.33712, in 0.057s\n",
      "[140/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.46349, val loss: 21.30627, in 0.006s\n",
      "[141/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.37929, val loss: 21.25369, in 0.005s\n",
      "[142/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.30351, val loss: 21.19865, in 0.085s\n",
      "[143/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.22747, val loss: 21.14380, in 0.006s\n",
      "[144/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.14502, val loss: 21.08927, in 0.006s\n",
      "[145/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.06338, val loss: 21.05810, in 0.039s\n",
      "[146/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.99139, val loss: 21.00436, in 0.006s\n",
      "[147/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.91093, val loss: 20.94583, in 0.005s\n",
      "[148/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.83994, val loss: 20.89318, in 0.009s\n",
      "[149/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.77794, val loss: 20.84031, in 0.029s\n",
      "[150/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.69825, val loss: 20.79964, in 0.005s\n",
      "[151/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.62365, val loss: 20.76006, in 0.014s\n",
      "[152/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.54521, val loss: 20.72161, in 0.006s\n",
      "[153/10000] 1 tree, 31 leaves, max depth = 11, train loss: 24.46828, val loss: 20.68153, in 0.036s\n",
      "[154/10000] 1 tree, 31 leaves, max depth = 11, train loss: 24.40187, val loss: 20.65004, in 0.007s\n",
      "[155/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.33673, val loss: 20.61362, in 0.005s\n",
      "[156/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.27019, val loss: 20.58036, in 0.034s\n",
      "[157/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.19951, val loss: 20.54273, in 0.006s\n",
      "[158/10000] 1 tree, 31 leaves, max depth = 11, train loss: 24.12713, val loss: 20.50890, in 0.059s\n",
      "[159/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.07915, val loss: 20.48090, in 0.012s\n",
      "[160/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.01950, val loss: 20.44916, in 0.005s\n",
      "[161/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.95710, val loss: 20.41738, in 0.103s\n",
      "[162/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.89351, val loss: 20.38553, in 0.007s\n",
      "[163/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.84098, val loss: 20.34987, in 0.117s\n",
      "[164/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.77807, val loss: 20.31460, in 0.009s\n",
      "[165/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.71636, val loss: 20.27952, in 0.005s\n",
      "[166/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.66126, val loss: 20.25140, in 0.005s\n",
      "[167/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.60948, val loss: 20.24177, in 0.087s\n",
      "[168/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.56475, val loss: 20.23567, in 0.006s\n",
      "[169/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.52249, val loss: 20.22870, in 0.007s\n",
      "[170/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.46791, val loss: 20.19298, in 0.011s\n",
      "[171/10000] 1 tree, 31 leaves, max depth = 7, train loss: 23.42839, val loss: 20.18590, in 0.077s\n",
      "[172/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.38214, val loss: 20.16653, in 0.101s\n",
      "[173/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.34157, val loss: 20.16339, in 0.007s\n",
      "[174/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.30158, val loss: 20.15809, in 0.008s\n",
      "[175/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.26636, val loss: 20.15155, in 0.005s\n",
      "[176/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.21541, val loss: 20.12589, in 0.092s\n",
      "[177/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.17060, val loss: 20.11635, in 0.006s\n",
      "[178/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.12357, val loss: 20.08361, in 0.012s\n",
      "[179/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.07516, val loss: 20.05901, in 0.006s\n",
      "[180/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.03196, val loss: 20.04640, in 0.102s\n",
      "[181/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.99600, val loss: 20.03292, in 0.012s\n",
      "[182/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.95967, val loss: 20.02004, in 0.005s\n",
      "[183/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.92132, val loss: 20.00793, in 0.039s\n",
      "[184/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.87537, val loss: 19.98220, in 0.005s\n",
      "[185/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.83070, val loss: 19.96279, in 0.082s\n",
      "[186/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.78515, val loss: 19.94083, in 0.008s\n",
      "[187/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.74555, val loss: 19.92044, in 0.011s\n",
      "[188/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.71152, val loss: 19.88556, in 0.034s\n",
      "[189/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.66938, val loss: 19.86582, in 0.013s\n",
      "[190/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.62816, val loss: 19.84347, in 0.057s\n",
      "[191/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.61046, val loss: 19.82388, in 0.044s\n",
      "[192/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.58620, val loss: 19.81025, in 0.006s\n",
      "[193/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.55995, val loss: 19.78410, in 0.146s\n",
      "[194/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.53352, val loss: 19.75784, in 0.008s\n",
      "[195/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.49910, val loss: 19.72071, in 0.005s\n",
      "[196/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.46524, val loss: 19.68355, in 0.005s\n",
      "[197/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.44623, val loss: 19.67542, in 0.121s\n",
      "[198/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.42994, val loss: 19.64965, in 0.005s\n",
      "[199/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.41364, val loss: 19.64810, in 0.006s\n",
      "[200/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.38123, val loss: 19.62500, in 0.009s\n",
      "[201/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.36023, val loss: 19.62116, in 0.006s\n",
      "[202/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.32855, val loss: 19.59791, in 0.124s\n",
      "[203/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.30897, val loss: 19.59188, in 0.007s\n",
      "[204/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.29314, val loss: 19.58004, in 0.005s\n",
      "[205/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.27486, val loss: 19.55177, in 0.006s\n",
      "[206/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.25618, val loss: 19.54480, in 0.037s\n",
      "[207/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.23932, val loss: 19.51488, in 0.005s\n",
      "[208/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.22207, val loss: 19.48418, in 0.005s\n",
      "[209/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.19157, val loss: 19.46899, in 0.045s\n",
      "[210/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.15968, val loss: 19.45127, in 0.040s\n",
      "[211/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.14949, val loss: 19.44422, in 0.005s\n",
      "[212/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.13763, val loss: 19.43925, in 0.005s\n",
      "[213/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.12202, val loss: 19.42407, in 0.141s\n",
      "[214/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.09694, val loss: 19.40278, in 0.006s\n",
      "[215/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.07272, val loss: 19.38176, in 0.012s\n",
      "[216/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.04237, val loss: 19.36588, in 0.100s\n",
      "[217/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.01354, val loss: 19.32646, in 0.009s\n",
      "[218/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.98520, val loss: 19.28743, in 0.005s\n",
      "[219/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.95124, val loss: 19.26505, in 0.005s\n",
      "[220/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.91850, val loss: 19.24136, in 0.091s\n",
      "[221/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.90163, val loss: 19.23784, in 0.007s\n",
      "[222/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.87895, val loss: 19.22038, in 0.010s\n",
      "[223/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.86066, val loss: 19.19588, in 0.073s\n",
      "[224/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.84208, val loss: 19.17591, in 0.015s\n",
      "[225/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.81690, val loss: 19.17289, in 0.005s\n",
      "[226/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.79844, val loss: 19.15222, in 0.032s\n",
      "[227/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.77396, val loss: 19.12215, in 0.010s\n",
      "[228/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.75450, val loss: 19.09362, in 0.005s\n",
      "[229/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.73124, val loss: 19.09110, in 0.005s\n",
      "[230/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.70337, val loss: 19.08882, in 0.035s\n",
      "[231/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.68098, val loss: 19.08183, in 0.061s\n",
      "[232/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.65334, val loss: 19.06096, in 0.007s\n",
      "[233/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.63157, val loss: 19.05867, in 0.005s\n",
      "[234/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.60372, val loss: 19.04795, in 0.005s\n",
      "[235/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.57840, val loss: 19.04039, in 0.005s\n",
      "[236/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.55404, val loss: 19.03425, in 0.036s\n",
      "[237/10000] 1 tree, 31 leaves, max depth = 13, train loss: 21.52874, val loss: 19.02734, in 0.005s\n",
      "[238/10000] 1 tree, 31 leaves, max depth = 13, train loss: 21.50383, val loss: 19.02063, in 0.030s\n",
      "[239/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.48220, val loss: 18.98847, in 0.012s\n",
      "[240/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.45527, val loss: 18.97537, in 0.005s\n",
      "[241/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.42851, val loss: 18.95196, in 0.035s\n",
      "[242/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.40282, val loss: 18.92917, in 0.011s\n",
      "[243/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.38305, val loss: 18.90268, in 0.008s\n",
      "[244/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.36416, val loss: 18.90050, in 0.037s\n",
      "[245/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.33819, val loss: 18.89536, in 0.012s\n",
      "[246/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.31794, val loss: 18.86817, in 0.089s\n",
      "[247/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.29846, val loss: 18.84149, in 0.008s\n",
      "[248/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.27813, val loss: 18.83882, in 0.007s\n",
      "[249/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.26327, val loss: 18.83667, in 0.005s\n",
      "[250/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.24435, val loss: 18.81312, in 0.038s\n",
      "[251/10000] 1 tree, 31 leaves, max depth = 12, train loss: 21.22428, val loss: 18.79674, in 0.015s\n",
      "[252/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.20491, val loss: 18.77283, in 0.037s\n",
      "[253/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.18269, val loss: 18.77123, in 0.005s\n",
      "[254/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.16485, val loss: 18.74787, in 0.005s\n",
      "[255/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.14064, val loss: 18.72598, in 0.039s\n",
      "[256/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.12126, val loss: 18.70140, in 0.005s\n",
      "[257/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.10218, val loss: 18.67700, in 0.037s\n",
      "[258/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.08440, val loss: 18.65248, in 0.006s\n",
      "[259/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.06106, val loss: 18.63355, in 0.006s\n",
      "[260/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.04385, val loss: 18.60978, in 0.041s\n",
      "[261/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.02536, val loss: 18.57890, in 0.006s\n",
      "[262/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.00665, val loss: 18.54798, in 0.006s\n",
      "[263/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.99019, val loss: 18.54307, in 0.008s\n",
      "[264/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.97215, val loss: 18.51272, in 0.037s\n",
      "[265/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.95248, val loss: 18.48482, in 0.006s\n",
      "[266/10000] 1 tree, 31 leaves, max depth = 12, train loss: 20.93760, val loss: 18.48106, in 0.036s\n",
      "[267/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.92057, val loss: 18.45250, in 0.007s\n",
      "[268/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.91232, val loss: 18.44930, in 0.058s\n",
      "[269/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.90433, val loss: 18.44612, in 0.007s\n",
      "[270/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.88777, val loss: 18.41789, in 0.009s\n",
      "[271/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.87539, val loss: 18.39883, in 0.042s\n",
      "[272/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.86342, val loss: 18.38111, in 0.006s\n",
      "[273/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.84286, val loss: 18.37394, in 0.075s\n",
      "[274/10000] 1 tree, 31 leaves, max depth = 12, train loss: 20.82622, val loss: 18.36664, in 0.086s\n",
      "[275/10000] 1 tree, 31 leaves, max depth = 12, train loss: 20.80942, val loss: 18.35929, in 0.020s\n",
      "[276/10000] 1 tree, 31 leaves, max depth = 12, train loss: 20.79293, val loss: 18.35209, in 0.042s\n",
      "[277/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.77322, val loss: 18.34974, in 0.007s\n",
      "[278/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.75400, val loss: 18.34559, in 0.054s\n",
      "[279/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.73719, val loss: 18.34096, in 0.007s\n",
      "[280/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.72073, val loss: 18.33630, in 0.040s\n",
      "[281/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.71403, val loss: 18.33214, in 0.006s\n",
      "[282/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.69623, val loss: 18.32806, in 0.005s\n",
      "[283/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.68446, val loss: 18.32662, in 0.069s\n",
      "[284/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.67321, val loss: 18.32459, in 0.139s\n",
      "[285/10000] 1 tree, 31 leaves, max depth = 12, train loss: 20.65595, val loss: 18.31870, in 0.007s\n",
      "[286/10000] 1 tree, 31 leaves, max depth = 12, train loss: 20.64090, val loss: 18.31181, in 0.078s\n",
      "[287/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.62989, val loss: 18.31044, in 0.006s\n",
      "[288/10000] 1 tree, 31 leaves, max depth = 13, train loss: 20.62619, val loss: 18.30439, in 0.005s\n",
      "[289/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.61981, val loss: 18.30463, in 0.005s\n",
      "[290/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.59552, val loss: 18.30114, in 0.070s\n",
      "[291/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.57129, val loss: 18.29732, in 0.084s\n",
      "[292/10000] 1 tree, 31 leaves, max depth = 7, train loss: 20.54763, val loss: 18.29401, in 0.121s\n",
      "[293/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.53473, val loss: 18.28723, in 0.010s\n",
      "[294/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.52126, val loss: 18.27958, in 0.007s\n",
      "[295/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.50840, val loss: 18.27006, in 0.108s\n",
      "[296/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.49565, val loss: 18.26902, in 0.010s\n",
      "[297/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.48534, val loss: 18.25945, in 0.007s\n",
      "[298/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.47097, val loss: 18.23329, in 0.033s\n",
      "[299/10000] 1 tree, 31 leaves, max depth = 13, train loss: 20.45854, val loss: 18.22487, in 0.006s\n",
      "[300/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.44690, val loss: 18.21868, in 0.005s\n",
      "[301/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.43513, val loss: 18.21186, in 0.010s\n",
      "[302/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.42537, val loss: 18.21104, in 0.006s\n",
      "[303/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.41709, val loss: 18.21014, in 0.045s\n",
      "[304/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.40755, val loss: 18.20877, in 0.006s\n",
      "[305/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.39820, val loss: 18.20765, in 0.041s\n",
      "[306/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.38844, val loss: 18.20629, in 0.048s\n",
      "[307/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.37046, val loss: 18.20496, in 0.007s\n",
      "[308/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.35289, val loss: 18.20365, in 0.008s\n",
      "[309/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.33922, val loss: 18.20229, in 0.005s\n",
      "[310/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.32574, val loss: 18.20091, in 0.138s\n",
      "[311/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.31311, val loss: 18.19984, in 0.019s\n",
      "[312/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.29925, val loss: 18.19709, in 0.042s\n",
      "[313/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.28720, val loss: 18.19392, in 0.007s\n",
      "[314/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.27274, val loss: 18.19084, in 0.055s\n",
      "[315/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.25342, val loss: 18.19029, in 0.006s\n",
      "[316/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.23730, val loss: 18.18091, in 0.040s\n",
      "[317/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.22961, val loss: 18.17970, in 0.005s\n",
      "[318/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.21955, val loss: 18.17353, in 0.053s\n",
      "[319/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.20819, val loss: 18.17180, in 0.040s\n",
      "[320/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.19759, val loss: 18.16774, in 0.008s\n",
      "[321/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.17599, val loss: 18.16682, in 0.039s\n",
      "[322/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.16915, val loss: 18.15927, in 0.005s\n",
      "[323/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.15937, val loss: 18.15756, in 0.005s\n",
      "[324/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.15257, val loss: 18.14988, in 0.010s\n",
      "[325/10000] 1 tree, 31 leaves, max depth = 7, train loss: 20.13230, val loss: 18.14913, in 0.039s\n",
      "[326/10000] 1 tree, 31 leaves, max depth = 7, train loss: 20.12663, val loss: 18.14802, in 0.006s\n",
      "[327/10000] 1 tree, 31 leaves, max depth = 11, train loss: 20.11643, val loss: 18.13980, in 0.005s\n",
      "[328/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.10667, val loss: 18.13783, in 0.185s\n",
      "[329/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.09976, val loss: 18.13517, in 0.008s\n",
      "[330/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.09360, val loss: 18.13190, in 0.043s\n",
      "[331/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.08973, val loss: 18.12950, in 0.013s\n",
      "[332/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.07264, val loss: 18.13017, in 0.006s\n",
      "[333/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.06577, val loss: 18.12716, in 0.122s\n",
      "[334/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.05885, val loss: 18.12408, in 0.006s\n",
      "[335/10000] 1 tree, 31 leaves, max depth = 10, train loss: 20.05213, val loss: 18.12123, in 0.005s\n",
      "[336/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.03535, val loss: 18.12212, in 0.075s\n",
      "[337/10000] 1 tree, 31 leaves, max depth = 8, train loss: 20.01849, val loss: 18.12162, in 0.120s\n",
      "[338/10000] 1 tree, 31 leaves, max depth = 9, train loss: 20.00909, val loss: 18.11387, in 0.006s\n",
      "[339/10000] 1 tree, 31 leaves, max depth = 7, train loss: 20.00151, val loss: 18.11305, in 0.012s\n",
      "[340/10000] 1 tree, 31 leaves, max depth = 11, train loss: 19.99020, val loss: 18.11031, in 0.005s\n",
      "[341/10000] 1 tree, 31 leaves, max depth = 7, train loss: 19.97513, val loss: 18.10969, in 0.005s\n",
      "[342/10000] 1 tree, 31 leaves, max depth = 7, train loss: 19.95856, val loss: 18.10956, in 0.046s\n",
      "[343/10000] 1 tree, 31 leaves, max depth = 7, train loss: 19.95121, val loss: 18.10899, in 0.039s\n",
      "[344/10000] 1 tree, 31 leaves, max depth = 8, train loss: 19.93657, val loss: 18.10852, in 0.316s\n",
      "[345/10000] 1 tree, 31 leaves, max depth = 7, train loss: 19.92159, val loss: 18.10913, in 0.020s\n",
      "[346/10000] 1 tree, 31 leaves, max depth = 8, train loss: 19.90727, val loss: 18.10866, in 0.044s\n",
      "[347/10000] 1 tree, 31 leaves, max depth = 8, train loss: 19.89311, val loss: 18.10815, in 0.005s\n",
      "[348/10000] 1 tree, 31 leaves, max depth = 8, train loss: 19.88012, val loss: 18.10767, in 0.010s\n",
      "[349/10000] 1 tree, 31 leaves, max depth = 9, train loss: 19.87174, val loss: 18.10721, in 0.006s\n",
      "[350/10000] 1 tree, 31 leaves, max depth = 9, train loss: 19.86139, val loss: 18.10675, in 0.040s\n",
      "[351/10000] 1 tree, 31 leaves, max depth = 7, train loss: 19.85075, val loss: 18.10632, in 0.007s\n",
      "[352/10000] 1 tree, 31 leaves, max depth = 10, train loss: 19.84659, val loss: 18.11021, in 0.050s\n",
      "[353/10000] 1 tree, 31 leaves, max depth = 8, train loss: 19.83605, val loss: 18.10976, in 0.007s\n",
      "[354/10000] 1 tree, 31 leaves, max depth = 8, train loss: 19.82564, val loss: 18.10932, in 0.006s\n",
      "[355/10000] 1 tree, 31 leaves, max depth = 8, train loss: 19.81569, val loss: 18.10870, in 0.042s\n",
      "[356/10000] 1 tree, 31 leaves, max depth = 8, train loss: 19.80587, val loss: 18.10827, in 0.006s\n",
      "[357/10000] 1 tree, 31 leaves, max depth = 7, train loss: 19.79578, val loss: 18.10786, in 0.006s\n",
      "[358/10000] 1 tree, 31 leaves, max depth = 8, train loss: 19.78615, val loss: 18.10744, in 0.082s\n",
      "[359/10000] 1 tree, 31 leaves, max depth = 8, train loss: 19.77665, val loss: 18.10702, in 0.006s\n",
      "[360/10000] 1 tree, 31 leaves, max depth = 8, train loss: 19.76268, val loss: 18.10802, in 0.006s\n",
      "[361/10000] 1 tree, 31 leaves, max depth = 9, train loss: 19.74868, val loss: 18.10815, in 0.071s\n",
      "Fit 361 trees in 10.616 s, (11191 total leaves)\n",
      "Time spent computing histograms: 2.791s\n",
      "Time spent finding best splits:  1.648s\n",
      "Time spent applying splits:      2.101s\n",
      "Time spent predicting:           0.432s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of 100 | elapsed:    6.3s remaining:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of 100 | elapsed:    6.4s remaining:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of 100 | elapsed:    6.4s remaining:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of 100 | elapsed:    6.4s remaining:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of 100 | elapsed:    6.4s remaining:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of 100 | elapsed:    6.4s remaining:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of 100 | elapsed:    6.4s remaining:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of 100 | elapsed:    6.4s remaining:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of 100 | elapsed:    6.4s remaining:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of 100 | elapsed:    6.4s remaining:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of 100 | elapsed:    6.4s remaining:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of 100 | elapsed:    6.5s remaining:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of 100 | elapsed:    6.5s remaining:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of 100 | elapsed:    6.5s remaining:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of 100 | elapsed:    6.5s remaining:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of 100 | elapsed:    6.6s remaining:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of 100 | elapsed:    6.6s remaining:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of 100 | elapsed:    6.6s remaining:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of 100 | elapsed:    6.6s remaining:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of 100 | elapsed:    6.6s remaining:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of 100 | elapsed:    6.8s remaining:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of 100 | elapsed:    6.8s remaining:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of 100 | elapsed:    6.8s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of 100 | elapsed:    6.9s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of 100 | elapsed:    6.9s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  63 out of 100 | elapsed:    6.9s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of 100 | elapsed:    7.0s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  65 out of 100 | elapsed:    9.4s remaining:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of 100 | elapsed:    9.4s remaining:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  67 out of 100 | elapsed:    9.4s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of 100 | elapsed:    9.5s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of 100 | elapsed:    9.5s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of 100 | elapsed:    9.5s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  71 out of 100 | elapsed:    9.6s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of 100 | elapsed:    9.6s remaining:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  73 out of 100 | elapsed:    9.6s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of 100 | elapsed:    9.6s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of 100 | elapsed:    9.6s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of 100 | elapsed:    9.6s remaining:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  77 out of 100 | elapsed:    9.6s remaining:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  78 out of 100 | elapsed:    9.6s remaining:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  79 out of 100 | elapsed:    9.7s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of 100 | elapsed:    9.7s remaining:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of 100 | elapsed:    9.7s remaining:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  82 out of 100 | elapsed:    9.7s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  83 out of 100 | elapsed:    9.7s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of 100 | elapsed:    9.8s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of 100 | elapsed:    9.8s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  86 out of 100 | elapsed:    9.8s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  87 out of 100 | elapsed:    9.8s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  88 out of 100 | elapsed:    9.8s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  89 out of 100 | elapsed:    9.9s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of 100 | elapsed:    9.9s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  91 out of 100 | elapsed:    9.9s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  92 out of 100 | elapsed:   10.0s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:   10.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  94 out of 100 | elapsed:   10.0s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  95 out of 100 | elapsed:   10.0s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of 100 | elapsed:   10.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  97 out of 100 | elapsed:   11.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  98 out of 100 | elapsed:   11.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   11.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   11.8s finished\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   7 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  11 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  13 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  14 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  15 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  19 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  20 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  22 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  23 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  24 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  25 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  31 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  32 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  33 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  35 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  36 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  37 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  38 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  39 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  40 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  41 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  42 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  43 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  44 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  45 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  46 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  47 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  48 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  49 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  50 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  51 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  52 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  53 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  54 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  55 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  56 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  57 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  58 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  59 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  60 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  61 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  62 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  63 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  64 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  65 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  66 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  67 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  68 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  69 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  70 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  71 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  72 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  73 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  75 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  76 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  77 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  78 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  79 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  80 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  81 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  82 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  83 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  84 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  85 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  86 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  87 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  88 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  89 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  90 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  91 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  92 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  93 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  94 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  95 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  96 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  97 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  98 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of 100 | elapsed:    6.4s remaining:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of 100 | elapsed:    6.4s remaining:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of 100 | elapsed:    6.4s remaining:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of 100 | elapsed:    6.4s remaining:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of 100 | elapsed:    6.5s remaining:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of 100 | elapsed:    6.5s remaining:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of 100 | elapsed:    6.5s remaining:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of 100 | elapsed:    6.5s remaining:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of 100 | elapsed:    6.5s remaining:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of 100 | elapsed:    6.5s remaining:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of 100 | elapsed:    6.5s remaining:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of 100 | elapsed:    6.5s remaining:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of 100 | elapsed:    6.6s remaining:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of 100 | elapsed:    6.6s remaining:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of 100 | elapsed:    6.6s remaining:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of 100 | elapsed:    6.6s remaining:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of 100 | elapsed:    6.6s remaining:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of 100 | elapsed:    6.7s remaining:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of 100 | elapsed:    6.7s remaining:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of 100 | elapsed:    6.7s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of 100 | elapsed:    6.8s remaining:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of 100 | elapsed:    6.8s remaining:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of 100 | elapsed:    6.8s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of 100 | elapsed:    6.9s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of 100 | elapsed:    6.9s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  63 out of 100 | elapsed:    6.9s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of 100 | elapsed:    7.1s remaining:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  65 out of 100 | elapsed:    9.5s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of 100 | elapsed:    9.5s remaining:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  67 out of 100 | elapsed:    9.6s remaining:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of 100 | elapsed:    9.6s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of 100 | elapsed:    9.6s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of 100 | elapsed:    9.6s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  71 out of 100 | elapsed:    9.6s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of 100 | elapsed:    9.7s remaining:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  73 out of 100 | elapsed:    9.7s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of 100 | elapsed:    9.7s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of 100 | elapsed:    9.7s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of 100 | elapsed:    9.7s remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  77 out of 100 | elapsed:    9.7s remaining:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  78 out of 100 | elapsed:    9.8s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  79 out of 100 | elapsed:    9.8s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of 100 | elapsed:    9.8s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of 100 | elapsed:    9.8s remaining:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  82 out of 100 | elapsed:    9.8s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  83 out of 100 | elapsed:    9.9s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of 100 | elapsed:    9.9s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of 100 | elapsed:    9.9s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  86 out of 100 | elapsed:    9.9s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  87 out of 100 | elapsed:    9.9s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  88 out of 100 | elapsed:    9.9s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  89 out of 100 | elapsed:    9.9s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of 100 | elapsed:   10.0s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  91 out of 100 | elapsed:   10.0s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  92 out of 100 | elapsed:   10.0s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:   10.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  94 out of 100 | elapsed:   10.0s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  95 out of 100 | elapsed:   10.1s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of 100 | elapsed:   10.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  97 out of 100 | elapsed:   11.6s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  98 out of 100 | elapsed:   11.7s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   11.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   11.8s finished\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   7 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  11 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  13 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  14 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  15 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  19 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  20 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  22 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  23 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  24 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  25 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  31 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  32 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  33 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  35 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  36 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  37 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  38 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  39 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  40 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  41 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  42 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  43 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  44 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  45 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  46 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  47 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  48 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  49 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  50 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  51 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  52 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  53 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  54 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  55 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  56 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  57 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  58 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  59 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  60 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  61 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  62 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  63 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  64 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  65 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  66 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  67 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  68 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  69 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  70 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  71 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  72 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  73 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  75 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  76 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  77 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  78 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  79 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  80 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  81 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  82 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  83 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  84 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  85 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  86 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  87 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  88 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  89 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  90 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  91 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  92 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  93 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  94 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  95 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  96 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  97 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  98 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of 100 | elapsed:    6.6s remaining:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of 100 | elapsed:    6.6s remaining:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of 100 | elapsed:    6.6s remaining:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of 100 | elapsed:    6.6s remaining:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of 100 | elapsed:    6.6s remaining:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of 100 | elapsed:    6.6s remaining:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of 100 | elapsed:    6.6s remaining:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of 100 | elapsed:    6.7s remaining:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of 100 | elapsed:    6.7s remaining:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of 100 | elapsed:    6.7s remaining:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of 100 | elapsed:    6.7s remaining:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of 100 | elapsed:    6.8s remaining:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of 100 | elapsed:    6.8s remaining:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of 100 | elapsed:    6.8s remaining:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of 100 | elapsed:    6.8s remaining:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of 100 | elapsed:    6.8s remaining:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of 100 | elapsed:    6.8s remaining:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of 100 | elapsed:    6.9s remaining:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of 100 | elapsed:    6.9s remaining:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of 100 | elapsed:    6.9s remaining:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of 100 | elapsed:    6.9s remaining:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of 100 | elapsed:    7.0s remaining:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of 100 | elapsed:    7.0s remaining:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of 100 | elapsed:    7.1s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of 100 | elapsed:    7.1s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  63 out of 100 | elapsed:    7.3s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of 100 | elapsed:    7.6s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  65 out of 100 | elapsed:    9.6s remaining:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of 100 | elapsed:    9.7s remaining:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  67 out of 100 | elapsed:    9.7s remaining:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of 100 | elapsed:    9.8s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of 100 | elapsed:    9.8s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of 100 | elapsed:    9.8s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  71 out of 100 | elapsed:    9.8s remaining:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of 100 | elapsed:    9.8s remaining:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  73 out of 100 | elapsed:    9.8s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of 100 | elapsed:    9.9s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of 100 | elapsed:    9.9s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of 100 | elapsed:   10.0s remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  77 out of 100 | elapsed:   10.0s remaining:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  78 out of 100 | elapsed:   10.0s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  79 out of 100 | elapsed:   10.0s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of 100 | elapsed:   10.0s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of 100 | elapsed:   10.0s remaining:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  82 out of 100 | elapsed:   10.0s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  83 out of 100 | elapsed:   10.0s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of 100 | elapsed:   10.0s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of 100 | elapsed:   10.1s remaining:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  86 out of 100 | elapsed:   10.1s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  87 out of 100 | elapsed:   10.1s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  88 out of 100 | elapsed:   10.1s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  89 out of 100 | elapsed:   10.1s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of 100 | elapsed:   10.1s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  91 out of 100 | elapsed:   10.2s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  92 out of 100 | elapsed:   10.3s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:   10.3s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  94 out of 100 | elapsed:   10.4s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  95 out of 100 | elapsed:   10.5s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of 100 | elapsed:   10.7s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  97 out of 100 | elapsed:   11.8s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  98 out of 100 | elapsed:   11.8s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   12.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   12.0s finished\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   7 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  11 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  13 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  14 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  15 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  19 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  20 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  22 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  23 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  24 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  25 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  31 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  32 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  33 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  35 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  36 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  37 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  38 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  39 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  40 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  41 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  42 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  43 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  44 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  45 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  46 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  47 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  48 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  49 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  50 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  51 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  52 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  53 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  54 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  55 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  56 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  57 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  58 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  59 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  60 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  61 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  62 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  63 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  64 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  65 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  66 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  67 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  68 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  69 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  70 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  71 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  72 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  73 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  75 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  76 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  77 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  78 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  79 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  80 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  81 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  82 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  83 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  84 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  85 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  86 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  87 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  88 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  89 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  90 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  91 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  92 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  93 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  94 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  95 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  96 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  97 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  98 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of 100 | elapsed:    6.3s remaining:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of 100 | elapsed:    6.3s remaining:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of 100 | elapsed:    6.3s remaining:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of 100 | elapsed:    6.4s remaining:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of 100 | elapsed:    6.4s remaining:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of 100 | elapsed:    6.4s remaining:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of 100 | elapsed:    6.4s remaining:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of 100 | elapsed:    6.4s remaining:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of 100 | elapsed:    6.4s remaining:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of 100 | elapsed:    6.4s remaining:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of 100 | elapsed:    6.5s remaining:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of 100 | elapsed:    6.5s remaining:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of 100 | elapsed:    6.5s remaining:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of 100 | elapsed:    6.5s remaining:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of 100 | elapsed:    6.5s remaining:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of 100 | elapsed:    6.6s remaining:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of 100 | elapsed:    6.6s remaining:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of 100 | elapsed:    6.6s remaining:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of 100 | elapsed:    6.6s remaining:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of 100 | elapsed:    6.6s remaining:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of 100 | elapsed:    6.7s remaining:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of 100 | elapsed:    6.7s remaining:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of 100 | elapsed:    6.8s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of 100 | elapsed:    6.8s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of 100 | elapsed:    6.9s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  63 out of 100 | elapsed:    7.0s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of 100 | elapsed:    7.0s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  65 out of 100 | elapsed:    9.4s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of 100 | elapsed:    9.4s remaining:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  67 out of 100 | elapsed:    9.5s remaining:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of 100 | elapsed:    9.5s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of 100 | elapsed:    9.5s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of 100 | elapsed:    9.5s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  71 out of 100 | elapsed:    9.6s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of 100 | elapsed:    9.6s remaining:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  73 out of 100 | elapsed:    9.6s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of 100 | elapsed:    9.6s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of 100 | elapsed:    9.6s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of 100 | elapsed:    9.6s remaining:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  77 out of 100 | elapsed:    9.6s remaining:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  78 out of 100 | elapsed:    9.6s remaining:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  79 out of 100 | elapsed:    9.7s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of 100 | elapsed:    9.7s remaining:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of 100 | elapsed:    9.7s remaining:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  82 out of 100 | elapsed:    9.7s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  83 out of 100 | elapsed:    9.7s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of 100 | elapsed:    9.8s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of 100 | elapsed:    9.8s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  86 out of 100 | elapsed:    9.8s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  87 out of 100 | elapsed:    9.8s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  88 out of 100 | elapsed:    9.8s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  89 out of 100 | elapsed:    9.8s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of 100 | elapsed:    9.8s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  91 out of 100 | elapsed:    9.9s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  92 out of 100 | elapsed:    9.9s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    9.9s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  94 out of 100 | elapsed:    9.9s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  95 out of 100 | elapsed:   10.1s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of 100 | elapsed:   10.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  97 out of 100 | elapsed:   11.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  98 out of 100 | elapsed:   11.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   11.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   11.6s finished\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   7 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  11 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  13 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  14 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  15 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  19 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  20 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  22 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  23 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  24 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  25 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  31 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  32 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  33 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  35 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  36 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  37 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  38 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  39 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  40 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  41 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  42 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  43 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  44 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  45 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  46 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  47 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  48 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  49 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  50 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  51 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  52 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  53 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  54 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  55 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  56 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  57 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  58 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  59 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  60 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  61 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  62 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  63 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  64 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  65 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  66 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  67 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  68 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  69 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  70 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  71 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  72 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  73 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  75 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  76 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  77 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  78 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  79 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  80 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  81 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  82 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  83 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  84 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  85 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  86 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  87 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  88 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  89 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  90 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  91 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  92 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  93 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  94 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  95 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  96 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  97 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  98 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of 100 | elapsed:    6.4s remaining:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of 100 | elapsed:    6.4s remaining:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of 100 | elapsed:    6.5s remaining:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of 100 | elapsed:    6.5s remaining:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of 100 | elapsed:    6.5s remaining:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of 100 | elapsed:    6.5s remaining:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of 100 | elapsed:    6.5s remaining:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of 100 | elapsed:    6.5s remaining:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of 100 | elapsed:    6.6s remaining:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of 100 | elapsed:    6.6s remaining:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of 100 | elapsed:    6.6s remaining:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of 100 | elapsed:    6.6s remaining:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of 100 | elapsed:    6.7s remaining:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of 100 | elapsed:    6.7s remaining:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of 100 | elapsed:    6.7s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of 100 | elapsed:    6.7s remaining:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of 100 | elapsed:    6.7s remaining:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of 100 | elapsed:    6.7s remaining:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of 100 | elapsed:    6.8s remaining:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of 100 | elapsed:    6.8s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of 100 | elapsed:    6.8s remaining:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of 100 | elapsed:    6.8s remaining:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of 100 | elapsed:    6.8s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of 100 | elapsed:    6.8s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of 100 | elapsed:    6.9s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  63 out of 100 | elapsed:    6.9s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of 100 | elapsed:    7.1s remaining:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  65 out of 100 | elapsed:    9.4s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of 100 | elapsed:    9.5s remaining:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  67 out of 100 | elapsed:    9.5s remaining:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of 100 | elapsed:    9.6s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of 100 | elapsed:    9.6s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of 100 | elapsed:    9.6s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  71 out of 100 | elapsed:    9.7s remaining:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of 100 | elapsed:    9.7s remaining:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  73 out of 100 | elapsed:    9.8s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of 100 | elapsed:    9.8s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of 100 | elapsed:    9.8s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of 100 | elapsed:    9.8s remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  77 out of 100 | elapsed:    9.8s remaining:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  78 out of 100 | elapsed:    9.9s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  79 out of 100 | elapsed:    9.9s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of 100 | elapsed:    9.9s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of 100 | elapsed:    9.9s remaining:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  82 out of 100 | elapsed:    9.9s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  83 out of 100 | elapsed:    9.9s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of 100 | elapsed:    9.9s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of 100 | elapsed:    9.9s remaining:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  86 out of 100 | elapsed:    9.9s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  87 out of 100 | elapsed:    9.9s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  88 out of 100 | elapsed:   10.0s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  89 out of 100 | elapsed:   10.0s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of 100 | elapsed:   10.0s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  91 out of 100 | elapsed:   10.0s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  92 out of 100 | elapsed:   10.0s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:   10.1s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  94 out of 100 | elapsed:   10.2s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  95 out of 100 | elapsed:   10.2s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of 100 | elapsed:   10.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  97 out of 100 | elapsed:   11.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  98 out of 100 | elapsed:   11.6s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   11.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   11.9s finished\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   7 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  11 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  13 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  14 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  15 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  19 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  20 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  22 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  23 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  24 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  25 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  31 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  32 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  33 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  35 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  36 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  37 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  38 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  39 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  40 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  41 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  42 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  43 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  44 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  45 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  46 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  47 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  48 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  49 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  50 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  51 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  52 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  53 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  54 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  55 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  56 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  57 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  58 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  59 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  60 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  61 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  62 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  63 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  64 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  65 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  66 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  67 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  68 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  69 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  70 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  71 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  72 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  73 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  75 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  76 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  77 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  78 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  79 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  80 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  81 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  82 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  83 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  84 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  85 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  86 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  87 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  88 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  89 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  90 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  91 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  92 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  93 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  94 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  95 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  96 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  97 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  98 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": "StackingRegressor(estimators=[('1',\n                               HistGradientBoostingRegressor(l2_regularization=0.02,\n                                                             learning_rate=0.01,\n                                                             loss='absolute_error',\n                                                             max_bins=100,\n                                                             max_iter=10000,\n                                                             min_samples_leaf=4,\n                                                             random_state=46,\n                                                             validation_fraction=0.01,\n                                                             verbose=999)),\n                              ('2',\n                               RandomForestRegressor(criterion='absolute_error',\n                                                     min_samples_leaf=20,\n                                                     min_samples_split=20,\n                                                     n_jobs=-1, verbose=999))],\n                  final_estimator=HistGradientBoostingRegressor(random_state=42))",
      "text/html": "<style>#sk-container-id-100 {color: black;background-color: white;}#sk-container-id-100 pre{padding: 0;}#sk-container-id-100 div.sk-toggleable {background-color: white;}#sk-container-id-100 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-100 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-100 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-100 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-100 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-100 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-100 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-100 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-100 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-100 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-100 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-100 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-100 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-100 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-100 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-100 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-100 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-100 div.sk-item {position: relative;z-index: 1;}#sk-container-id-100 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-100 div.sk-item::before, #sk-container-id-100 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-100 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-100 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-100 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-100 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-100 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-100 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-100 div.sk-label-container {text-align: center;}#sk-container-id-100 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-100 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-100\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(estimators=[(&#x27;1&#x27;,\n                               HistGradientBoostingRegressor(l2_regularization=0.02,\n                                                             learning_rate=0.01,\n                                                             loss=&#x27;absolute_error&#x27;,\n                                                             max_bins=100,\n                                                             max_iter=10000,\n                                                             min_samples_leaf=4,\n                                                             random_state=46,\n                                                             validation_fraction=0.01,\n                                                             verbose=999)),\n                              (&#x27;2&#x27;,\n                               RandomForestRegressor(criterion=&#x27;absolute_error&#x27;,\n                                                     min_samples_leaf=20,\n                                                     min_samples_split=20,\n                                                     n_jobs=-1, verbose=999))],\n                  final_estimator=HistGradientBoostingRegressor(random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-129\" type=\"checkbox\" ><label for=\"sk-estimator-id-129\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(estimators=[(&#x27;1&#x27;,\n                               HistGradientBoostingRegressor(l2_regularization=0.02,\n                                                             learning_rate=0.01,\n                                                             loss=&#x27;absolute_error&#x27;,\n                                                             max_bins=100,\n                                                             max_iter=10000,\n                                                             min_samples_leaf=4,\n                                                             random_state=46,\n                                                             validation_fraction=0.01,\n                                                             verbose=999)),\n                              (&#x27;2&#x27;,\n                               RandomForestRegressor(criterion=&#x27;absolute_error&#x27;,\n                                                     min_samples_leaf=20,\n                                                     min_samples_split=20,\n                                                     n_jobs=-1, verbose=999))],\n                  final_estimator=HistGradientBoostingRegressor(random_state=42))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-130\" type=\"checkbox\" ><label for=\"sk-estimator-id-130\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingRegressor(l2_regularization=0.02, learning_rate=0.01,\n                              loss=&#x27;absolute_error&#x27;, max_bins=100,\n                              max_iter=10000, min_samples_leaf=4,\n                              random_state=46, validation_fraction=0.01,\n                              verbose=999)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-131\" type=\"checkbox\" ><label for=\"sk-estimator-id-131\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(criterion=&#x27;absolute_error&#x27;, min_samples_leaf=20,\n                      min_samples_split=20, n_jobs=-1, verbose=999)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-132\" type=\"checkbox\" ><label for=\"sk-estimator-id-132\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingRegressor(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "hist_boost_model = lambda: HistGradientBoostingRegressor(learning_rate=0.01, verbose=999, max_depth=None, min_samples_leaf=4,\n",
    "                                                 max_iter=10000, loss='absolute_error', l2_regularization=0.02,\n",
    "                                                 max_bins=100,\n",
    "                                                 validation_fraction=0.01, random_state=46)\n",
    "\n",
    "# hist_boost_model.fit(X_train, y_train)\n",
    "estimators = [('1', hist_boost_model()), ('2', RandomForestRegressor(n_estimators=100, criterion='absolute_error', verbose=999, min_samples_leaf=20,\n",
    "                                     min_samples_split=20, n_jobs=-1))]\n",
    "stack = StackingRegressor(estimators=estimators, final_estimator=HistGradientBoostingRegressor(random_state=42))\n",
    "\n",
    "stack.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "outputs": [],
   "source": [
    "# SelectKBest(mutual_info_regression, k=9).fit_transform(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "outputs": [],
   "source": [
    "def score(predicted: np.ndarray, expected: np.ndarray):\n",
    "    def smape(A, F):\n",
    "        return 100 / len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))\n",
    "\n",
    "    print(f'Smape: {smape(expected, predicted)}')\n",
    "    print(f'R2: {r2_score(expected, predicted)}')\n",
    "    print(f'RMSE: {mean_squared_error(expected, predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "outputs": [],
   "source": [
    "def postprocess(output: np.ndarray) -> np.ndarray:\n",
    "    squarer = lambda t: round(t)\n",
    "    vfunc = np.vectorize(squarer)\n",
    "    return vfunc(output)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[219  18   0 ...   0  69   1]\n",
      "3075     238.0\n",
      "8178      24.0\n",
      "22716      0.0\n",
      "13250      5.0\n",
      "24489      0.0\n",
      "         ...  \n",
      "12803      4.0\n",
      "23571      8.0\n",
      "6940       0.0\n",
      "1429      63.0\n",
      "21605      1.0\n",
      "Name: Sales, Length: 7702, dtype: float64\n",
      "Smape: 25.176322859634226\n",
      "R2: 0.5474992588790644\n",
      "RMSE: 21332.98260192158\n"
     ]
    }
   ],
   "source": [
    "predicted = postprocess(stack.predict(X_test))\n",
    "print(predicted)\n",
    "print(y_test)\n",
    "score(predicted, y_test)\n",
    "# 20.727624784060993"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.003 GB of training data: 0.059 s\n",
      "Binning 0.000 GB of validation data: 0.001 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/10000] 1 tree, 31 leaves, max depth = 9, train loss: 41.16588, val loss: 40.20222, in 0.006s\n",
      "[2/10000] 1 tree, 31 leaves, max depth = 8, train loss: 41.07549, val loss: 40.11764, in 0.044s\n",
      "[3/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.98600, val loss: 40.03394, in 0.013s\n",
      "[4/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.89742, val loss: 39.95107, in 0.007s\n",
      "[5/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.80972, val loss: 39.86908, in 0.016s\n",
      "[6/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.72334, val loss: 39.78812, in 0.030s\n",
      "[7/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.62823, val loss: 39.69665, in 0.006s\n",
      "[8/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.53407, val loss: 39.60609, in 0.006s\n",
      "[9/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.44224, val loss: 39.51777, in 0.015s\n",
      "[10/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.35133, val loss: 39.43033, in 0.007s\n",
      "[11/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.26210, val loss: 39.34414, in 0.018s\n",
      "[12/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.16658, val loss: 39.25099, in 0.011s\n",
      "[13/10000] 1 tree, 31 leaves, max depth = 8, train loss: 40.07202, val loss: 39.15878, in 0.018s\n",
      "[14/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.97840, val loss: 39.06749, in 0.009s\n",
      "[15/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.88572, val loss: 38.97712, in 0.009s\n",
      "[16/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.79616, val loss: 38.88765, in 0.018s\n",
      "[17/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.69576, val loss: 38.78882, in 0.006s\n",
      "[18/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.59637, val loss: 38.69098, in 0.014s\n",
      "[19/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.49823, val loss: 38.59449, in 0.009s\n",
      "[20/10000] 1 tree, 31 leaves, max depth = 7, train loss: 39.39413, val loss: 38.49171, in 0.016s\n",
      "[21/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.29135, val loss: 38.39010, in 0.063s\n",
      "[22/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.18959, val loss: 38.28951, in 0.025s\n",
      "[23/10000] 1 tree, 31 leaves, max depth = 8, train loss: 39.08977, val loss: 38.18992, in 0.009s\n",
      "[24/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.98810, val loss: 38.09155, in 0.006s\n",
      "[25/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.88746, val loss: 37.99416, in 0.006s\n",
      "[26/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.78842, val loss: 37.89714, in 0.013s\n",
      "[27/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.68709, val loss: 37.80053, in 0.006s\n",
      "[28/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.58678, val loss: 37.70489, in 0.011s\n",
      "[29/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.48905, val loss: 37.61020, in 0.006s\n",
      "[30/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.38355, val loss: 37.51487, in 0.005s\n",
      "[31/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.27971, val loss: 37.42185, in 0.012s\n",
      "[32/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.17309, val loss: 37.32063, in 0.006s\n",
      "[33/10000] 1 tree, 31 leaves, max depth = 8, train loss: 38.06705, val loss: 37.21984, in 0.005s\n",
      "[34/10000] 1 tree, 31 leaves, max depth = 7, train loss: 37.96274, val loss: 37.11999, in 0.013s\n",
      "[35/10000] 1 tree, 31 leaves, max depth = 7, train loss: 37.86082, val loss: 37.02331, in 0.006s\n",
      "[36/10000] 1 tree, 31 leaves, max depth = 7, train loss: 37.76080, val loss: 36.92759, in 0.005s\n",
      "[37/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.65446, val loss: 36.82154, in 0.012s\n",
      "[38/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.54948, val loss: 36.71667, in 0.006s\n",
      "[39/10000] 1 tree, 31 leaves, max depth = 7, train loss: 37.43991, val loss: 36.60589, in 0.070s\n",
      "[40/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.33179, val loss: 36.49634, in 0.009s\n",
      "[41/10000] 1 tree, 31 leaves, max depth = 8, train loss: 37.22131, val loss: 36.38284, in 0.017s\n",
      "[42/10000] 1 tree, 31 leaves, max depth = 7, train loss: 37.11268, val loss: 36.27089, in 0.006s\n",
      "[43/10000] 1 tree, 31 leaves, max depth = 7, train loss: 37.00202, val loss: 36.15947, in 0.008s\n",
      "[44/10000] 1 tree, 31 leaves, max depth = 7, train loss: 36.89192, val loss: 36.04759, in 0.006s\n",
      "[45/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.78592, val loss: 35.93668, in 0.011s\n",
      "[46/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.68208, val loss: 35.83037, in 0.006s\n",
      "[47/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.57340, val loss: 35.71606, in 0.005s\n",
      "[48/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.46086, val loss: 35.59876, in 0.014s\n",
      "[49/10000] 1 tree, 31 leaves, max depth = 9, train loss: 36.35016, val loss: 35.48695, in 0.006s\n",
      "[50/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.24075, val loss: 35.37464, in 0.051s\n",
      "[51/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.12741, val loss: 35.25993, in 0.023s\n",
      "[52/10000] 1 tree, 31 leaves, max depth = 8, train loss: 36.01384, val loss: 35.14691, in 0.006s\n",
      "[53/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.89426, val loss: 35.02416, in 0.013s\n",
      "[54/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.77420, val loss: 34.89743, in 0.006s\n",
      "[55/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.67314, val loss: 34.79389, in 0.009s\n",
      "[56/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.55463, val loss: 34.67590, in 0.006s\n",
      "[57/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.43306, val loss: 34.55446, in 0.006s\n",
      "[58/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.31937, val loss: 34.43306, in 0.012s\n",
      "[59/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.21184, val loss: 34.33062, in 0.006s\n",
      "[60/10000] 1 tree, 31 leaves, max depth = 8, train loss: 35.09362, val loss: 34.21382, in 0.017s\n",
      "[61/10000] 1 tree, 31 leaves, max depth = 7, train loss: 34.97656, val loss: 34.09715, in 0.006s\n",
      "[62/10000] 1 tree, 31 leaves, max depth = 7, train loss: 34.85191, val loss: 33.97803, in 0.010s\n",
      "[63/10000] 1 tree, 31 leaves, max depth = 7, train loss: 34.73226, val loss: 33.84698, in 0.008s\n",
      "[64/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.60971, val loss: 33.71325, in 0.014s\n",
      "[65/10000] 1 tree, 31 leaves, max depth = 9, train loss: 34.48620, val loss: 33.59138, in 0.006s\n",
      "[66/10000] 1 tree, 31 leaves, max depth = 9, train loss: 34.36077, val loss: 33.48157, in 0.008s\n",
      "[67/10000] 1 tree, 31 leaves, max depth = 7, train loss: 34.25121, val loss: 33.37433, in 0.006s\n",
      "[68/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.14372, val loss: 33.26821, in 0.005s\n",
      "[69/10000] 1 tree, 31 leaves, max depth = 8, train loss: 34.01882, val loss: 33.16368, in 0.010s\n",
      "[70/10000] 1 tree, 31 leaves, max depth = 7, train loss: 33.90457, val loss: 33.05477, in 0.006s\n",
      "[71/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.78521, val loss: 32.93511, in 0.006s\n",
      "[72/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.66602, val loss: 32.83106, in 0.011s\n",
      "[73/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.54524, val loss: 32.71907, in 0.006s\n",
      "[74/10000] 1 tree, 31 leaves, max depth = 9, train loss: 33.42976, val loss: 32.60240, in 0.006s\n",
      "[75/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.30841, val loss: 32.48636, in 0.078s\n",
      "[76/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.18866, val loss: 32.37151, in 0.009s\n",
      "[77/10000] 1 tree, 31 leaves, max depth = 8, train loss: 33.08495, val loss: 32.27348, in 0.012s\n",
      "[78/10000] 1 tree, 31 leaves, max depth = 7, train loss: 32.95870, val loss: 32.14991, in 0.009s\n",
      "[79/10000] 1 tree, 31 leaves, max depth = 9, train loss: 32.84455, val loss: 32.03841, in 0.011s\n",
      "[80/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.73835, val loss: 31.94209, in 0.006s\n",
      "[81/10000] 1 tree, 31 leaves, max depth = 7, train loss: 32.62675, val loss: 31.83712, in 0.009s\n",
      "[82/10000] 1 tree, 31 leaves, max depth = 7, train loss: 32.50830, val loss: 31.73184, in 0.007s\n",
      "[83/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.41190, val loss: 31.63665, in 0.006s\n",
      "[84/10000] 1 tree, 31 leaves, max depth = 7, train loss: 32.30504, val loss: 31.54365, in 0.011s\n",
      "[85/10000] 1 tree, 31 leaves, max depth = 8, train loss: 32.19221, val loss: 31.43667, in 0.006s\n",
      "[86/10000] 1 tree, 31 leaves, max depth = 9, train loss: 32.09271, val loss: 31.34964, in 0.006s\n",
      "[87/10000] 1 tree, 31 leaves, max depth = 7, train loss: 31.98362, val loss: 31.24754, in 0.006s\n",
      "[88/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.88690, val loss: 31.16224, in 0.015s\n",
      "[89/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.78005, val loss: 31.07106, in 0.006s\n",
      "[90/10000] 1 tree, 31 leaves, max depth = 7, train loss: 31.67161, val loss: 30.98147, in 0.012s\n",
      "[91/10000] 1 tree, 31 leaves, max depth = 7, train loss: 31.56100, val loss: 30.89811, in 0.006s\n",
      "[92/10000] 1 tree, 31 leaves, max depth = 7, train loss: 31.45244, val loss: 30.81594, in 0.006s\n",
      "[93/10000] 1 tree, 31 leaves, max depth = 7, train loss: 31.34345, val loss: 30.71342, in 0.009s\n",
      "[94/10000] 1 tree, 31 leaves, max depth = 9, train loss: 31.24256, val loss: 30.61977, in 0.008s\n",
      "[95/10000] 1 tree, 31 leaves, max depth = 7, train loss: 31.14114, val loss: 30.53174, in 0.021s\n",
      "[96/10000] 1 tree, 31 leaves, max depth = 8, train loss: 31.03297, val loss: 30.44311, in 0.017s\n",
      "[97/10000] 1 tree, 31 leaves, max depth = 7, train loss: 30.91855, val loss: 30.34332, in 0.006s\n",
      "[98/10000] 1 tree, 31 leaves, max depth = 7, train loss: 30.81396, val loss: 30.26425, in 0.007s\n",
      "[99/10000] 1 tree, 31 leaves, max depth = 7, train loss: 30.70360, val loss: 30.17707, in 0.009s\n",
      "[100/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.59538, val loss: 30.09193, in 0.009s\n",
      "[101/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.47945, val loss: 30.00162, in 0.006s\n",
      "[102/10000] 1 tree, 31 leaves, max depth = 7, train loss: 30.36156, val loss: 29.89885, in 0.012s\n",
      "[103/10000] 1 tree, 31 leaves, max depth = 8, train loss: 30.27529, val loss: 29.82281, in 0.006s\n",
      "[104/10000] 1 tree, 31 leaves, max depth = 7, train loss: 30.15598, val loss: 29.72327, in 0.006s\n",
      "[105/10000] 1 tree, 31 leaves, max depth = 7, train loss: 30.05083, val loss: 29.63695, in 0.020s\n",
      "[106/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.94841, val loss: 29.55547, in 0.018s\n",
      "[107/10000] 1 tree, 31 leaves, max depth = 7, train loss: 29.83262, val loss: 29.45632, in 0.013s\n",
      "[108/10000] 1 tree, 31 leaves, max depth = 7, train loss: 29.71714, val loss: 29.35841, in 0.008s\n",
      "[109/10000] 1 tree, 31 leaves, max depth = 7, train loss: 29.61724, val loss: 29.26487, in 0.011s\n",
      "[110/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.51608, val loss: 29.17474, in 0.010s\n",
      "[111/10000] 1 tree, 31 leaves, max depth = 9, train loss: 29.42141, val loss: 29.09363, in 0.009s\n",
      "[112/10000] 1 tree, 31 leaves, max depth = 8, train loss: 29.31343, val loss: 29.00030, in 0.006s\n",
      "[113/10000] 1 tree, 31 leaves, max depth = 7, train loss: 29.21770, val loss: 28.91313, in 0.006s\n",
      "[114/10000] 1 tree, 31 leaves, max depth = 7, train loss: 29.11138, val loss: 28.80401, in 0.009s\n",
      "[115/10000] 1 tree, 31 leaves, max depth = 7, train loss: 29.02717, val loss: 28.72624, in 0.006s\n",
      "[116/10000] 1 tree, 31 leaves, max depth = 9, train loss: 28.92415, val loss: 28.63717, in 0.006s\n",
      "[117/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.82276, val loss: 28.55233, in 0.013s\n",
      "[118/10000] 1 tree, 31 leaves, max depth = 7, train loss: 28.72390, val loss: 28.46078, in 0.006s\n",
      "[119/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.62724, val loss: 28.36910, in 0.013s\n",
      "[120/10000] 1 tree, 31 leaves, max depth = 7, train loss: 28.52472, val loss: 28.26181, in 0.006s\n",
      "[121/10000] 1 tree, 31 leaves, max depth = 7, train loss: 28.42315, val loss: 28.15618, in 0.138s\n",
      "[122/10000] 1 tree, 31 leaves, max depth = 7, train loss: 28.33704, val loss: 28.08724, in 0.015s\n",
      "[123/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.26909, val loss: 28.02608, in 0.023s\n",
      "[124/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.18363, val loss: 27.93780, in 0.006s\n",
      "[125/10000] 1 tree, 31 leaves, max depth = 10, train loss: 28.10586, val loss: 27.85850, in 0.006s\n",
      "[126/10000] 1 tree, 31 leaves, max depth = 8, train loss: 28.04164, val loss: 27.79908, in 0.007s\n",
      "[127/10000] 1 tree, 31 leaves, max depth = 7, train loss: 27.95844, val loss: 27.71107, in 0.010s\n",
      "[128/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.85717, val loss: 27.60325, in 0.006s\n",
      "[129/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.79025, val loss: 27.53782, in 0.015s\n",
      "[130/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.70213, val loss: 27.44857, in 0.010s\n",
      "[131/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.60327, val loss: 27.34322, in 0.022s\n",
      "[132/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.50747, val loss: 27.24098, in 0.018s\n",
      "[133/10000] 1 tree, 31 leaves, max depth = 7, train loss: 27.43373, val loss: 27.16257, in 0.010s\n",
      "[134/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.35426, val loss: 27.07348, in 0.011s\n",
      "[135/10000] 1 tree, 31 leaves, max depth = 9, train loss: 27.26539, val loss: 26.97395, in 0.010s\n",
      "[136/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.18646, val loss: 26.87643, in 0.009s\n",
      "[137/10000] 1 tree, 31 leaves, max depth = 8, train loss: 27.10256, val loss: 26.77906, in 0.010s\n",
      "[138/10000] 1 tree, 31 leaves, max depth = 10, train loss: 27.02248, val loss: 26.68228, in 0.073s\n",
      "[139/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.94878, val loss: 26.60748, in 0.009s\n",
      "[140/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.86797, val loss: 26.49922, in 0.010s\n",
      "[141/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.80982, val loss: 26.43593, in 0.027s\n",
      "[142/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.74155, val loss: 26.36332, in 0.008s\n",
      "[143/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.67321, val loss: 26.29251, in 0.006s\n",
      "[144/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.60571, val loss: 26.22289, in 0.014s\n",
      "[145/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.53632, val loss: 26.12664, in 0.006s\n",
      "[146/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.46372, val loss: 26.04333, in 0.006s\n",
      "[147/10000] 1 tree, 31 leaves, max depth = 9, train loss: 26.40323, val loss: 25.98545, in 0.114s\n",
      "[148/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.31435, val loss: 25.88496, in 0.008s\n",
      "[149/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.24648, val loss: 25.80046, in 0.017s\n",
      "[150/10000] 1 tree, 31 leaves, max depth = 10, train loss: 26.17689, val loss: 25.70833, in 0.008s\n",
      "[151/10000] 1 tree, 31 leaves, max depth = 7, train loss: 26.10874, val loss: 25.63922, in 0.006s\n",
      "[152/10000] 1 tree, 31 leaves, max depth = 8, train loss: 26.05095, val loss: 25.56577, in 0.006s\n",
      "[153/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.99454, val loss: 25.51391, in 0.006s\n",
      "[154/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.93436, val loss: 25.44032, in 0.014s\n",
      "[155/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.86853, val loss: 25.36243, in 0.012s\n",
      "[156/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.81057, val loss: 25.28085, in 0.006s\n",
      "[157/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.75682, val loss: 25.21527, in 0.008s\n",
      "[158/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.70087, val loss: 25.13475, in 0.010s\n",
      "[159/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.63888, val loss: 25.03269, in 0.006s\n",
      "[160/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.58795, val loss: 24.98266, in 0.014s\n",
      "[161/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.53278, val loss: 24.89651, in 0.006s\n",
      "[162/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.47690, val loss: 24.81564, in 0.009s\n",
      "[163/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.43094, val loss: 24.76998, in 0.022s\n",
      "[164/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.36992, val loss: 24.66889, in 0.009s\n",
      "[165/10000] 1 tree, 31 leaves, max depth = 10, train loss: 25.31605, val loss: 24.58889, in 0.009s\n",
      "[166/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.26007, val loss: 24.51529, in 0.006s\n",
      "[167/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.21015, val loss: 24.43784, in 0.011s\n",
      "[168/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.16188, val loss: 24.36134, in 0.008s\n",
      "[169/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.11341, val loss: 24.28867, in 0.013s\n",
      "[170/10000] 1 tree, 31 leaves, max depth = 8, train loss: 25.05677, val loss: 24.20293, in 0.013s\n",
      "[171/10000] 1 tree, 31 leaves, max depth = 9, train loss: 25.01289, val loss: 24.12248, in 0.006s\n",
      "[172/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.96562, val loss: 24.04122, in 0.010s\n",
      "[173/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.90462, val loss: 23.92344, in 0.007s\n",
      "[174/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.85875, val loss: 23.85306, in 0.007s\n",
      "[175/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.80923, val loss: 23.79159, in 0.011s\n",
      "[176/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.76599, val loss: 23.71846, in 0.018s\n",
      "[177/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.72939, val loss: 23.64904, in 0.011s\n",
      "[178/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.67352, val loss: 23.56180, in 0.022s\n",
      "[179/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.62205, val loss: 23.48608, in 0.006s\n",
      "[180/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.58793, val loss: 23.41928, in 0.008s\n",
      "[181/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.54461, val loss: 23.34240, in 0.008s\n",
      "[182/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.51374, val loss: 23.30062, in 0.008s\n",
      "[183/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.47869, val loss: 23.26733, in 0.012s\n",
      "[184/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.42968, val loss: 23.16985, in 0.006s\n",
      "[185/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.39769, val loss: 23.12198, in 0.009s\n",
      "[186/10000] 1 tree, 31 leaves, max depth = 10, train loss: 24.36658, val loss: 23.07444, in 0.006s\n",
      "[187/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.31954, val loss: 22.97637, in 0.006s\n",
      "[188/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.27283, val loss: 22.89857, in 0.011s\n",
      "[189/10000] 1 tree, 31 leaves, max depth = 8, train loss: 24.22903, val loss: 22.81872, in 0.006s\n",
      "[190/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.19661, val loss: 22.75890, in 0.006s\n",
      "[191/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.15280, val loss: 22.68405, in 0.010s\n",
      "[192/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.10957, val loss: 22.60903, in 0.006s\n",
      "[193/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.07007, val loss: 22.53253, in 0.009s\n",
      "[194/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.05565, val loss: 22.52084, in 0.010s\n",
      "[195/10000] 1 tree, 31 leaves, max depth = 9, train loss: 24.01478, val loss: 22.43512, in 0.007s\n",
      "[196/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.97471, val loss: 22.36233, in 0.006s\n",
      "[197/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.95749, val loss: 22.34114, in 0.009s\n",
      "[198/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.92002, val loss: 22.30488, in 0.021s\n",
      "[199/10000] 1 tree, 31 leaves, max depth = 11, train loss: 23.89157, val loss: 22.26816, in 0.008s\n",
      "[200/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.86802, val loss: 22.24400, in 0.006s\n",
      "[201/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.82866, val loss: 22.16302, in 0.006s\n",
      "[202/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.80431, val loss: 22.11303, in 0.008s\n",
      "[203/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.76668, val loss: 22.03524, in 0.009s\n",
      "[204/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.72965, val loss: 21.95853, in 0.009s\n",
      "[205/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.69100, val loss: 21.88159, in 0.006s\n",
      "[206/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.66830, val loss: 21.85847, in 0.016s\n",
      "[207/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.63298, val loss: 21.78794, in 0.011s\n",
      "[208/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.60963, val loss: 21.77411, in 0.015s\n",
      "[209/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.59433, val loss: 21.75679, in 0.008s\n",
      "[210/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.57479, val loss: 21.73165, in 0.006s\n",
      "[211/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.55531, val loss: 21.70984, in 0.015s\n",
      "[212/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.51392, val loss: 21.62328, in 0.006s\n",
      "[213/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.49699, val loss: 21.59964, in 0.014s\n",
      "[214/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.46443, val loss: 21.54889, in 0.081s\n",
      "[215/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.42780, val loss: 21.53022, in 0.012s\n",
      "[216/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.40939, val loss: 21.51169, in 0.007s\n",
      "[217/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.37195, val loss: 21.48194, in 0.014s\n",
      "[218/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.34797, val loss: 21.46170, in 0.006s\n",
      "[219/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.32008, val loss: 21.41854, in 0.006s\n",
      "[220/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.28715, val loss: 21.38368, in 0.014s\n",
      "[221/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.24261, val loss: 21.31842, in 0.020s\n",
      "[222/10000] 1 tree, 31 leaves, max depth = 10, train loss: 23.21611, val loss: 21.27743, in 0.006s\n",
      "[223/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.19029, val loss: 21.23685, in 0.011s\n",
      "[224/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.16684, val loss: 21.19125, in 0.010s\n",
      "[225/10000] 1 tree, 31 leaves, max depth = 8, train loss: 23.13679, val loss: 21.15942, in 0.030s\n",
      "[226/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.10434, val loss: 21.13463, in 0.006s\n",
      "[227/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.08124, val loss: 21.09453, in 0.014s\n",
      "[228/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.04445, val loss: 21.05796, in 0.006s\n",
      "[229/10000] 1 tree, 31 leaves, max depth = 9, train loss: 23.01331, val loss: 21.03178, in 0.006s\n",
      "[230/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.98275, val loss: 20.99860, in 0.013s\n",
      "[231/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.95962, val loss: 20.98067, in 0.006s\n",
      "[232/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.92891, val loss: 20.95481, in 0.012s\n",
      "[233/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.90097, val loss: 20.92841, in 0.006s\n",
      "[234/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.87081, val loss: 20.90480, in 0.015s\n",
      "[235/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.84107, val loss: 20.88122, in 0.096s\n",
      "[236/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.80897, val loss: 20.85399, in 0.009s\n",
      "[237/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.78256, val loss: 20.82835, in 0.021s\n",
      "[238/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.75070, val loss: 20.79990, in 0.009s\n",
      "[239/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.71986, val loss: 20.76018, in 0.006s\n",
      "[240/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.68940, val loss: 20.71975, in 0.036s\n",
      "[241/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.67567, val loss: 20.70854, in 0.006s\n",
      "[242/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.65634, val loss: 20.67157, in 0.011s\n",
      "[243/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.63538, val loss: 20.65572, in 0.009s\n",
      "[244/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.61817, val loss: 20.63533, in 0.021s\n",
      "[245/10000] 1 tree, 31 leaves, max depth = 12, train loss: 22.59229, val loss: 20.61797, in 0.013s\n",
      "[246/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.55858, val loss: 20.61289, in 0.016s\n",
      "[247/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.52957, val loss: 20.57492, in 0.010s\n",
      "[248/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.51265, val loss: 20.54540, in 0.010s\n",
      "[249/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.49568, val loss: 20.51959, in 0.011s\n",
      "[250/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.47762, val loss: 20.48304, in 0.009s\n",
      "[251/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.46123, val loss: 20.45058, in 0.009s\n",
      "[252/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.43275, val loss: 20.43122, in 0.010s\n",
      "[253/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.41087, val loss: 20.39884, in 0.009s\n",
      "[254/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.38002, val loss: 20.37867, in 0.108s\n",
      "[255/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.35791, val loss: 20.36749, in 0.009s\n",
      "[256/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.33161, val loss: 20.32890, in 0.018s\n",
      "[257/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.31464, val loss: 20.29708, in 0.008s\n",
      "[258/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.29092, val loss: 20.27488, in 0.006s\n",
      "[259/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.26094, val loss: 20.25673, in 0.006s\n",
      "[260/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.25062, val loss: 20.24739, in 0.007s\n",
      "[261/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.24148, val loss: 20.23898, in 0.009s\n",
      "[262/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.22751, val loss: 20.21994, in 0.006s\n",
      "[263/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.20940, val loss: 20.21183, in 0.014s\n",
      "[264/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.18647, val loss: 20.20843, in 0.006s\n",
      "[265/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.16523, val loss: 20.18649, in 0.006s\n",
      "[266/10000] 1 tree, 31 leaves, max depth = 8, train loss: 22.13887, val loss: 20.15125, in 0.010s\n",
      "[267/10000] 1 tree, 31 leaves, max depth = 11, train loss: 22.12136, val loss: 20.14748, in 0.006s\n",
      "[268/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.09962, val loss: 20.12608, in 0.013s\n",
      "[269/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.08112, val loss: 20.11502, in 0.006s\n",
      "[270/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.06089, val loss: 20.09332, in 0.006s\n",
      "[271/10000] 1 tree, 31 leaves, max depth = 9, train loss: 22.04126, val loss: 20.07188, in 0.010s\n",
      "[272/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.03111, val loss: 20.06404, in 0.009s\n",
      "[273/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.02183, val loss: 20.05815, in 0.074s\n",
      "[274/10000] 1 tree, 31 leaves, max depth = 10, train loss: 22.01262, val loss: 20.05318, in 0.009s\n",
      "[275/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.99720, val loss: 20.02998, in 0.006s\n",
      "[276/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.98277, val loss: 20.00545, in 0.006s\n",
      "[277/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.97384, val loss: 20.00102, in 0.022s\n",
      "[278/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.95117, val loss: 19.99519, in 0.017s\n",
      "[279/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.93911, val loss: 19.97346, in 0.013s\n",
      "[280/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.93301, val loss: 19.96904, in 0.006s\n",
      "[281/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.92701, val loss: 19.96474, in 0.010s\n",
      "[282/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.91905, val loss: 19.95884, in 0.006s\n",
      "[283/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.90499, val loss: 19.93651, in 0.006s\n",
      "[284/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.89103, val loss: 19.91714, in 0.013s\n",
      "[285/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.87673, val loss: 19.89696, in 0.006s\n",
      "[286/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.86214, val loss: 19.87525, in 0.008s\n",
      "[287/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.84772, val loss: 19.85376, in 0.009s\n",
      "[288/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.84057, val loss: 19.84427, in 0.006s\n",
      "[289/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.83431, val loss: 19.83956, in 0.017s\n",
      "[290/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.82709, val loss: 19.83567, in 0.008s\n",
      "[291/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.81393, val loss: 19.81761, in 0.007s\n",
      "[292/10000] 1 tree, 31 leaves, max depth = 12, train loss: 21.79891, val loss: 19.79741, in 0.007s\n",
      "[293/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.79177, val loss: 19.79107, in 0.017s\n",
      "[294/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.77864, val loss: 19.77401, in 0.012s\n",
      "[295/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.77171, val loss: 19.76761, in 0.008s\n",
      "[296/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.76429, val loss: 19.75944, in 0.014s\n",
      "[297/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.75657, val loss: 19.75100, in 0.008s\n",
      "[298/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.74948, val loss: 19.74140, in 0.011s\n",
      "[299/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.74315, val loss: 19.73471, in 0.015s\n",
      "[300/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.72409, val loss: 19.73078, in 0.019s\n",
      "[301/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.70536, val loss: 19.72652, in 0.138s\n",
      "[302/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.68692, val loss: 19.72230, in 0.007s\n",
      "[303/10000] 1 tree, 31 leaves, max depth = 12, train loss: 21.67538, val loss: 19.70002, in 0.006s\n",
      "[304/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.65003, val loss: 19.64098, in 0.022s\n",
      "[305/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.63224, val loss: 19.62034, in 0.017s\n",
      "[306/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.61366, val loss: 19.58872, in 0.020s\n",
      "[307/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.60200, val loss: 19.57165, in 0.009s\n",
      "[308/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.59250, val loss: 19.55979, in 0.006s\n",
      "[309/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.56438, val loss: 19.55768, in 0.048s\n",
      "[310/10000] 1 tree, 31 leaves, max depth = 12, train loss: 21.55244, val loss: 19.55399, in 0.015s\n",
      "[311/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.54040, val loss: 19.55220, in 0.054s\n",
      "[312/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.51243, val loss: 19.54441, in 0.006s\n",
      "[313/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.50623, val loss: 19.54086, in 0.010s\n",
      "[314/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.49642, val loss: 19.52483, in 0.006s\n",
      "[315/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.48486, val loss: 19.50779, in 0.019s\n",
      "[316/10000] 1 tree, 31 leaves, max depth = 12, train loss: 21.47639, val loss: 19.48887, in 0.059s\n",
      "[317/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.46487, val loss: 19.47113, in 0.009s\n",
      "[318/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.46007, val loss: 19.46888, in 0.011s\n",
      "[319/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.45174, val loss: 19.46952, in 0.015s\n",
      "[320/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.42533, val loss: 19.46439, in 0.007s\n",
      "[321/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.40040, val loss: 19.46296, in 0.009s\n",
      "[322/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.39275, val loss: 19.45431, in 0.010s\n",
      "[323/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.38681, val loss: 19.44740, in 0.006s\n",
      "[324/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.37248, val loss: 19.44411, in 0.015s\n",
      "[325/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.36638, val loss: 19.42935, in 0.006s\n",
      "[326/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.35414, val loss: 19.40671, in 0.009s\n",
      "[327/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.34213, val loss: 19.38438, in 0.011s\n",
      "[328/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.32947, val loss: 19.32780, in 0.098s\n",
      "[329/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.32295, val loss: 19.31099, in 0.013s\n",
      "[330/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.30830, val loss: 19.25378, in 0.006s\n",
      "[331/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.29710, val loss: 19.23127, in 0.014s\n",
      "[332/10000] 1 tree, 31 leaves, max depth = 12, train loss: 21.28896, val loss: 19.21402, in 0.006s\n",
      "[333/10000] 1 tree, 31 leaves, max depth = 13, train loss: 21.28345, val loss: 19.19989, in 0.013s\n",
      "[334/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.26958, val loss: 19.14369, in 0.006s\n",
      "[335/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.26178, val loss: 19.14424, in 0.035s\n",
      "[336/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.25128, val loss: 19.14155, in 0.058s\n",
      "[337/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.24535, val loss: 19.12450, in 0.008s\n",
      "[338/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.24140, val loss: 19.11321, in 0.022s\n",
      "[339/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.22365, val loss: 19.09930, in 0.014s\n",
      "[340/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.21986, val loss: 19.08785, in 0.022s\n",
      "[341/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.20626, val loss: 19.03295, in 0.021s\n",
      "[342/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.19235, val loss: 18.98061, in 0.019s\n",
      "[343/10000] 1 tree, 31 leaves, max depth = 11, train loss: 21.18525, val loss: 18.97150, in 0.015s\n",
      "[344/10000] 1 tree, 31 leaves, max depth = 12, train loss: 21.17928, val loss: 18.95807, in 0.009s\n",
      "[345/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.16621, val loss: 18.98690, in 0.006s\n",
      "[346/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.15897, val loss: 18.98983, in 0.006s\n",
      "[347/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.13976, val loss: 19.01425, in 0.015s\n",
      "[348/10000] 1 tree, 31 leaves, max depth = 14, train loss: 21.13188, val loss: 19.04378, in 0.008s\n",
      "[349/10000] 1 tree, 31 leaves, max depth = 7, train loss: 21.12811, val loss: 19.04303, in 0.005s\n",
      "[350/10000] 1 tree, 31 leaves, max depth = 8, train loss: 21.12410, val loss: 19.04179, in 0.006s\n",
      "[351/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.09791, val loss: 19.03200, in 0.016s\n",
      "[352/10000] 1 tree, 31 leaves, max depth = 9, train loss: 21.09275, val loss: 19.03146, in 0.008s\n",
      "[353/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.07416, val loss: 19.01755, in 0.101s\n",
      "[354/10000] 1 tree, 31 leaves, max depth = 10, train loss: 21.05652, val loss: 19.00263, in 0.010s\n",
      "Fit 354 trees in 5.095 s, (10974 total leaves)\n",
      "Time spent computing histograms: 1.180s\n",
      "Time spent finding best splits:  0.784s\n",
      "Time spent applying splits:      0.955s\n",
      "Time spent predicting:           0.210s\n"
     ]
    },
    {
     "data": {
      "text/plain": "HistGradientBoostingRegressor(l2_regularization=0.02, learning_rate=0.01,\n                              loss='absolute_error', max_bins=100,\n                              max_iter=10000, min_samples_leaf=4,\n                              random_state=46, validation_fraction=0.01,\n                              verbose=999)",
      "text/html": "<style>#sk-container-id-83 {color: black;background-color: white;}#sk-container-id-83 pre{padding: 0;}#sk-container-id-83 div.sk-toggleable {background-color: white;}#sk-container-id-83 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-83 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-83 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-83 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-83 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-83 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-83 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-83 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-83 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-83 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-83 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-83 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-83 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-83 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-83 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-83 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-83 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-83 div.sk-item {position: relative;z-index: 1;}#sk-container-id-83 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-83 div.sk-item::before, #sk-container-id-83 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-83 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-83 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-83 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-83 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-83 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-83 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-83 div.sk-label-container {text-align: center;}#sk-container-id-83 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-83 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-83\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingRegressor(l2_regularization=0.02, learning_rate=0.01,\n                              loss=&#x27;absolute_error&#x27;, max_bins=100,\n                              max_iter=10000, min_samples_leaf=4,\n                              random_state=46, validation_fraction=0.01,\n                              verbose=999)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-95\" type=\"checkbox\" checked><label for=\"sk-estimator-id-95\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingRegressor(l2_regularization=0.02, learning_rate=0.01,\n                              loss=&#x27;absolute_error&#x27;, max_bins=100,\n                              max_iter=10000, min_samples_leaf=4,\n                              random_state=46, validation_fraction=0.01,\n                              verbose=999)</pre></div></div></div></div></div>"
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_model = HistGradientBoostingRegressor(learning_rate=0.01, verbose=999, max_depth=None, min_samples_leaf=4,\n",
    "                                            max_iter=10000, loss='absolute_error', l2_regularization=0.02, max_bins=100,\n",
    "                                            validation_fraction=0.01, random_state=46)\n",
    "\n",
    "boost_model.fit(origin_train.drop(['Sales'], axis=1).values, origin_train['Sales'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "outputs": [],
   "source": [
    "predicted = postprocess(boost_model.predict(origin_test.values))\n",
    "df_inference = pd.DataFrame(data=predicted, index=range(0, len(predicted)), columns=['Expected'])\n",
    "df_inference.index.name = 'Id'\n",
    "\n",
    "df_inference.to_csv('../submissions/inference.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "origin_test.to_csv('../processed-datasets/processed_test-19.61.csv')\n",
    "origin_train.to_csv('../processed-datasets/processed_train-19.61.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
